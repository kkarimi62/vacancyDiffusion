{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parsing configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "confParser = configparser.ConfigParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf. file sections: ['parameters', 'flags', 'MsdAnalysis', 'EnergyBarrier', 'SroAnalysis', 'Defect Analysis', 'input files', 'Atomic Radius']\n"
     ]
    }
   ],
   "source": [
    "#--- parse conf. file\n",
    "confParser.read('configuration.ini')\n",
    "print('conf. file sections:',confParser.sections())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'LammpsPostProcess' from '../../HeaDef/postprocess/LammpsPostProcess.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(confParser['input files']['lib_path'])\n",
    "\n",
    "#--- system libraries\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "import traceback\n",
    "import os\n",
    "import scipy.interpolate as scp_int\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "import warnings\n",
    "import matplotlib\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "from matplotlib import patches\n",
    "import sys\n",
    "import sklearn\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "import patsy\n",
    "from sklearn import linear_model, mixture\n",
    "import sklearn.mixture as skm\n",
    "from scipy import optimize\n",
    "import scipy\n",
    "import re\n",
    "from functools import reduce\n",
    "import time\n",
    "import fnmatch\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "#\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#--- user modules\n",
    "import LammpsPostProcess as lp\n",
    "#import LammpsPostProcess2nd as lpp\n",
    "#import utilityy as utll\n",
    "import utility as utl\n",
    "#from utility import *\n",
    "import imp\n",
    "#imp.reload(lpp)\n",
    "imp.reload(utl)\n",
    "imp.reload(lp)\n",
    "#imp.reload(utll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Symbols:\n",
    "    def __init__(self,\n",
    "                markersizes=[10,10,10,12,12,12,10],\n",
    "                ):\n",
    "        self.colors = ['black','red','green','blue','cyan','brown','grey','magenta','orange','yellow']\n",
    "        self.fillstyles=['white',None,'white',None,'white',None,'white',None,'white',None,'white',None,'white',None,'white',None]\n",
    "        self.markers=['o','s','D','^','<','>','v']\n",
    "        self.markersizes=markersizes\n",
    "        self.nmax=7\n",
    "        \n",
    "    def GetAttrs(self,count=0,label='',nevery=1,fmt='.-',zorder=1,alpha=1):\n",
    "        if count > self.nmax:\n",
    "            print('index out of list bound!')\n",
    "            return \n",
    "        attrs={ 'color':self.colors[count],\n",
    "            'markersize':self.markersizes[count],\n",
    "            'marker':self.markers[count],\n",
    "            'markerfacecolor':self.colors[count],\n",
    "            'markeredgecolor':'white', #'black' if not self.fillstyles[count] else None,\n",
    "            'label':label,\n",
    "           'markevery':nevery,\n",
    "           'errorevery':nevery,\n",
    "           'markeredgewidth':1.75,\n",
    "            'linewidth':1, \n",
    "           'barsabove':None,\n",
    "           'capsize':5,\n",
    "           'capthick':1,\n",
    "           'elinewidth':1,\n",
    "           'fmt':fmt,\n",
    "             'zorder':zorder,\n",
    "               'alpha':alpha\n",
    "         }\n",
    "        return attrs\n",
    "    \n",
    "    def GetAttrs2nd(self,count=0,label='',nevery=1,fmt='.-',zorder=1):\n",
    "        '''\n",
    "        empty symbols\n",
    "        '''\n",
    "        if count > self.nmax:\n",
    "            print('index out of list bound!')\n",
    "            return \n",
    "        attrs={ 'color':self.colors[count],\n",
    "            'markersize':self.markersizes[count],\n",
    "            'marker':self.markers[count],\n",
    "            'markerfacecolor':'white',\n",
    "#            'markeredgecolor':'black' if not self.fillstyles[count] else None,\n",
    "            'label':label,\n",
    "           'markevery':nevery,\n",
    "           'errorevery':nevery,\n",
    "           'markeredgewidth':1.75,\n",
    "            'linewidth':1, \n",
    "           'barsabove':None,\n",
    "           'capsize':5,\n",
    "           'capthick':1,\n",
    "           'elinewidth':1,\n",
    "           'fmt':fmt,\n",
    "            'zorder':zorder,\n",
    "          }\n",
    "        return attrs\n",
    "\n",
    "    def GetAttrsScatter(self,count=0,label='',nevery=1,fmt='.-',zorder=1,alpha=0.5):\n",
    "        if count > self.nmax:\n",
    "            print('index out of list bound!')\n",
    "            return \n",
    "        attrs={ 'color':self.colors[count],\n",
    "            's':self.markersizes[count],\n",
    "            'marker':self.markers[count],\n",
    "#            'markerfacecolor':self.colors[count],\n",
    "            'edgecolors':'white', #'black' if not self.fillstyles[count] else None,\n",
    "            'label':label,\n",
    "#            'markevery':nevery,\n",
    "#           'errorevery':nevery,\n",
    "#            'markeredgewidth':1.75,\n",
    "            'linewidth':1, \n",
    "#            'barsabove':None,\n",
    "#            'capsize':5,\n",
    "#            'capthick':1,\n",
    "#            'elinewidth':1,\n",
    "#            'fmt':fmt,\n",
    "             'zorder':zorder,\n",
    "               'alpha':alpha\n",
    "         }\n",
    "        return attrs\n",
    "    \n",
    "    \n",
    "class Legends:\n",
    "    def __init__(self\n",
    "                ):\n",
    "        pass\n",
    "    def Set(self,fontsize=20,\n",
    "                 labelspacing=0,\n",
    "                 **kwargs\n",
    "#                 bbox_to_anchor=(0.5,0.48,0.5,0.5),\n",
    "           ):\n",
    "        self.attrs = {'frameon':False,'fontsize':fontsize,\n",
    "                   'labelspacing':labelspacing,\n",
    "                      'handletextpad':.2,\n",
    "                   'handlelength':1,\n",
    "                    **kwargs,\n",
    "                     }\n",
    "    def Get(self):\n",
    "        return self.attrs\n",
    "\n",
    "DRAW_FRAME=(0.23,0.08,0.12,0.07,0.01)\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    matplotlib.rcParams['text.usetex'] = True #--- comment tex stuff!\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Dump File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class ParseConfiguration:\n",
    "    '''\n",
    "    Parse k-art configuration file\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,confParser,verbose=False):\n",
    "\n",
    "        #--- fetch parameters defect_file\n",
    "        self.datFile = '%s/%s'%(confParser['input files']['input_path'],confParser['input files']['diffusion_file'])\n",
    "        self.lib_path = confParser['input files']['lib_path']\n",
    "        \n",
    "        self.verbose = verbose\n",
    "\n",
    "    def Parse(self,fp,outpt):\n",
    "        #--- parse dump: call ovito\n",
    "        t0=time.time()\n",
    "        outpt_headers = 'dumpFile/calcResults.txt'\n",
    "        !ovitos $self.lib_path/OvitosCna.py $fp $outpt 1 7 $outpt_headers\n",
    "        if self.verbose:\n",
    "            print('output dump file=%s s'%(time.time()-t0))\n",
    "\n",
    "        #--- parse dump files\n",
    "        if self.verbose:\n",
    "            print('parsing %s'%(outpt))\n",
    "        t0=time.time()\n",
    "        self.lmpData = lp.ReadDumpFile( '%s'%(outpt) ) \n",
    "        self.lmpData.GetCords( ncount = sys.maxsize)\n",
    "        if self.verbose:\n",
    "            print('elapsed time=%s s'%(time.time()-t0))\n",
    "            print('time steps:',self.lmpData.coord_atoms_broken.keys())\n",
    "            display(self.lmpData.coord_atoms_broken[0].head())\n",
    "\n",
    "        #--- add timescales\n",
    "        self.lmpData.times = np.loadtxt(self.datFile)[:,0]\n",
    "\n",
    "        #--- parse headers\n",
    "        data = np.loadtxt(outpt_headers)\n",
    "        if data.shape[1] == 4:\n",
    "            self.lmpData.headers = pd.DataFrame(data,columns=[\"Barrier\", \"Energy\", \"Step\", \"Time\"])\n",
    "        elif data.shape[1] == 2:\n",
    "            self.lmpData.headers = pd.DataFrame(data,columns=[\"Step\", \"Time\"])\n",
    "\n",
    "\n",
    "    def WignerSeitz(self,fp,reference_file):\n",
    "        '''\n",
    "        perform Wigner-Seitz algorithm\n",
    "        '''\n",
    "        outpt = 'dumpFile/dump_defect.xyz'\n",
    "\n",
    "        #--- parse dump: call ovito\n",
    "        if self.verbose:\n",
    "            print('input=',fp)\n",
    "        t0=time.time()\n",
    "        !ovitos $self.lib_path/OvitosCna.py $fp $outpt 1 11 $reference_file\n",
    "        if self.verbose:\n",
    "            print('output dump file=%s s'%(time.time()-t0))\n",
    "\n",
    "        #--- parse dump files\n",
    "        if self.verbose:\n",
    "            print('parsing %s'%(outpt))\n",
    "        t0=time.time()\n",
    "        self.lmpData_defect = lp.ReadDumpFile( '%s'%(outpt) ) \n",
    "        self.lmpData_defect.GetCords( ncount = sys.maxsize)\n",
    "        if self.verbose:\n",
    "            print('elapsed time=%s s'%(time.time()-t0))\n",
    "\n",
    "        if self.verbose:\n",
    "            print('time steps:',self.lmpData_defect.coord_atoms_broken.keys())\n",
    "            display(self.lmpData_defect.coord_atoms_broken[0].head())\n",
    "\n",
    "        #--- add timescales\n",
    "        self.lmpData_defect.times = np.loadtxt(self.datFile)[:,0]\n",
    "\n",
    "\n",
    "    def Print(self,fout):\n",
    "        '''\n",
    "        dump vacant sites\n",
    "        '''\n",
    "        \n",
    "        times = list( self.lmpData_defect.coord_atoms_broken.keys() )\n",
    "        times.sort()\n",
    "\n",
    "        #--- print dump\n",
    "        !rm $fout\n",
    "        for ii in times:\n",
    "            filtr = self.lmpData_defect.coord_atoms_broken[ii].Occupancy == 0.0\n",
    "            df = self.lmpData_defect.coord_atoms_broken[ii][filtr]\n",
    "            assert df.shape[0] == 1\n",
    "            df.id=1;df.type=1\n",
    "        #    print(df)\n",
    "            atom_current = lp.Atoms(**df)\n",
    "            box  = lp.Box( BoxBounds = self.lmpData_defect.BoxBounds[ii],  AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "            with open(fout,'a') as fp:\n",
    "                lp.WriteDumpFile(atom_current, box).Write(fp, itime = ii,\n",
    "                     attrs=['id', 'type','x', 'y', 'z'],\n",
    "        #                 fmt='%i %i %15.14e %15.14e %15.14e',\n",
    "                                                     )\n",
    "                \n",
    "    def Displacement(self, fp, fout,use_frame_offset=False):\n",
    "        '''\n",
    "        Return total displacements \n",
    "        '''\n",
    "        !rm $fout\n",
    "\n",
    "        #--- fetch parameters\n",
    "        fileCurr = fileRef = fp\n",
    "\n",
    "        #--- call ovito\n",
    "        t0 = time.time()\n",
    "#        pdb.set_trace()\n",
    "        !ovitos $self.lib_path/OvitosCna.py $fileCurr $fout 1 8 $fileRef $use_frame_offset\n",
    "        if self.verbose:\n",
    "            print('output disp:%s s'%(time.time()-t0))\n",
    "\n",
    "        #--- parse disp files\n",
    "        if self.verbose:\n",
    "            print('parsing %s'%fout)\n",
    "        t0 = time.time()\n",
    "        self.lmpDisp = lp.ReadDumpFile( fout )\n",
    "        self.lmpDisp.GetCords( ncount = sys.maxsize )\n",
    "#         if self.verbose:\n",
    "#             print('elapsed time %s s'%(time.time()-t0))\n",
    "#             display(self.lmpDisp.coord_atoms_broken[0].head())\n",
    "\n",
    "    def CommonNeighborAnalysis(self, fp, fout):\n",
    "        '''\n",
    "        common neighbor analysis\n",
    "        '''\n",
    "        !rm fout\n",
    "        !ovitos $self.lib_path/OvitosCna.py $fp $fout 1 0\n",
    "\n",
    "        #--- parse dump files\n",
    "        print('parsing %s'%(fout))\n",
    "        self.lmpCna = lp.ReadDumpFile( '%s'%(fout) ) \n",
    "        self.lmpCna.GetCords( ncount = sys.maxsize, \n",
    "                        )\n",
    "\n",
    "\n",
    "    def Integrate(self):\n",
    "        times = list(self.lmpDisp.coord_atoms_broken.keys())\n",
    "        times.sort()\n",
    "        x=list(map(lambda x:np.c_[self.lmpDisp.coord_atoms_broken[x].DisplacementX].flatten()[0],times))\n",
    "        y=list(map(lambda x:np.c_[self.lmpDisp.coord_atoms_broken[x].DisplacementY].flatten()[0],times))\n",
    "        z=list(map(lambda x:np.c_[self.lmpDisp.coord_atoms_broken[x].DisplacementZ].flatten()[0],times))\n",
    "        X=np.cumsum(x)\n",
    "        Y=np.cumsum(y)\n",
    "        Z=np.cumsum(z)\n",
    "\n",
    "        for itime, indx in zip(times,range(len(times))):\n",
    "            self.lmpDisp.coord_atoms_broken[itime].DisplacementX=X[indx]            \n",
    "            self.lmpDisp.coord_atoms_broken[itime].DisplacementY=Y[indx]\n",
    "            self.lmpDisp.coord_atoms_broken[itime].DisplacementZ=Z[indx]\n",
    "            \n",
    "    def AddZero(self):\n",
    "        self.lmpDisp.coord_atoms_broken[0] = self.lmpDisp.coord_atoms_broken[1]\n",
    "        self.lmpDisp.coord_atoms_broken[0].DisplacementX=0.0\n",
    "        self.lmpDisp.coord_atoms_broken[0].DisplacementY=0.0\n",
    "        self.lmpDisp.coord_atoms_broken[0].DisplacementZ=0.0\n",
    "        \n",
    "    def PrintOvito( self, title ):\n",
    "        #--- save\n",
    "        try:\n",
    "            os.system('rm %s'%title)\n",
    "        except:\n",
    "            pass\n",
    "        times = list( self.lmpDisp_defect.coord_atoms_broken.keys() )\n",
    "        times.sort()\n",
    "        itime0 = times[ 0 ]\n",
    "        rc = np.c_[ self.lmpDisp_defect.coord_atoms_broken[ itime0 ]['x y z'.split()] ]\n",
    "        for itime in times:\n",
    "            sfile        = open(title,'a')\n",
    "            dx           = np.c_[self.lmpDisp_defect.coord_atoms_broken[ itime ]['DisplacementX  DisplacementY  DisplacementZ'.split()]]\n",
    "            utl.PrintOvito(pd.DataFrame(np.c_[dx+rc].reshape(1,3),columns=['x','y','z']), \n",
    "                       sfile, 'itime=%s'%itime, attr_list=['x', 'y', 'z'])\n",
    "            sfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    !rm -r dumpFile; mkdir dumpFile; mkdir disp\n",
    "    \n",
    "    #--- parse allconf\n",
    "    pc = ParseConfiguration(confParser,verbose=True)\n",
    "    #\n",
    "    pc.Parse('%s/%s'%(confParser['input files']['input_path'],confParser['input files']['dump_file']),\n",
    "            'dumpFile/dump.xyz',\n",
    "            )\n",
    "    \n",
    "    #--- vacancy dynamics based on ws analysis\n",
    "    if eval(confParser['MsdAnalysis']['WignerSeitz']):\n",
    "        pc.WignerSeitz('%s/%s'%(confParser['input files']['input_path'],confParser['input files']['dump_file']),\n",
    "                       '%s/%s'%(confParser['input files']['input_path'],confParser['MsdAnalysis']['pure_crystal'])\n",
    "                      )\n",
    "        #--- output vacant sites\n",
    "        pc.Print('dumpFile/dump_vacant.xyz')\n",
    "    \n",
    "    \n",
    "        #--- vacancy disp\n",
    "        pc.Displacement('dumpFile/dump_vacant.xyz',\n",
    "                        'disp_vacant.xyz',\n",
    "                       use_frame_offset = True, #--- velocity\n",
    "                       )\n",
    "        pc.AddZero() #--- add first timestep\n",
    "        pc.Integrate() #--- get displacements\n",
    "        pc.lmpDisp_defect = pc.lmpDisp\n",
    "        ps.PrintOvito('dumpFile/vacancy_trajectories.xyz')\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    #--- total displacements\n",
    "    pc.Displacement('dumpFile/dump.xyz',\n",
    "                     'disp/disp.xyz')\n",
    "\n",
    "    #--- vacant site based on cna analysis\n",
    "#     pc.CommonNeighborAnalysis( 'dumpFile/dump.xyz',\n",
    "#                      'disp/cna.xyz')\n",
    "\n",
    "    #--- parse allconf_defect\n",
    "    #--- vacant site based on defects\n",
    "    pc_defect = ParseConfiguration(confParser,verbose=True)\n",
    "    pc_defect.Parse('%s/%s'%(confParser['input files']['input_path'],confParser['input files']['defect_file']),\n",
    "                    'dumpFile/dump_defects.xyz',\n",
    "\n",
    "                   )\n",
    "\n",
    "    #--- output timeseries\n",
    "    !mkdir msd\n",
    "    with open('msd/event_times.txt','w') as fp:\n",
    "        np.savetxt(fp,pc.lmpData.times,header='t')\n",
    "    #\n",
    "    with open('msd/timeseries.txt','w') as fp:\n",
    "        np.savetxt(fp,np.c_[pc.lmpData.headers],header='Barrier Energy Step Time')\n",
    "\n",
    "\n",
    "    return pc, pc_defect\n",
    "\n",
    "data, data_defect = main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# times = list(data.lmpDisp_defect.coord_atoms_broken.keys())\n",
    "# times.sort()\n",
    "\n",
    "# x=list(map(lambda x:np.c_[data.lmpDisp_defect.coord_atoms_broken[x].DisplacementX].flatten()[0],times))\n",
    "# y=list(map(lambda x:np.c_[data.lmpDisp_defect.coord_atoms_broken[x].DisplacementY].flatten()[0],times))\n",
    "# z=list(map(lambda x:np.c_[data.lmpDisp_defect.coord_atoms_broken[x].DisplacementZ].flatten()[0],times))\n",
    "\n",
    "# ax=utl.PltErr(None,None,Plot=False)\n",
    "# #utl.PltErr(times[:-1],np.diff(x),ax=ax,Plot=False)\n",
    "# utl.PltErr(times,x,ax=ax,Plot=False)\n",
    "# # utl.PltErr(times[:-1],np.diff(y),ax=ax,Plot=False)\n",
    "# # utl.PltErr(times[:-1],np.diff(z),ax=ax,Plot=False)\n",
    "\n",
    "# utl.PltErr(None,None,title='disp/vel.png',ax=ax, yscale='linear',xlim=(0,75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## msd vs. time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MsDisp:\n",
    "    \n",
    "    def __init__(self, lmpDisp,  \n",
    "                 filtr, \n",
    "                 lmpCna = None,\n",
    "                 skip_times = 0):\n",
    "        '''\n",
    "        returns mean-squared displacements\n",
    "        '''\n",
    "        self.disp = lmpDisp.coord_atoms_broken\n",
    "        try:\n",
    "            self.cna = lmpCna.coord_atoms_broken\n",
    "        except:\n",
    "            pass\n",
    "        self.times = list(lmpDisp.coord_atoms_broken.keys())\n",
    "        self.times.sort()\n",
    "        self.times = self.times[ skip_times: ]\n",
    "#        print(self.times)\n",
    "        self.filtr=filtr\n",
    "        \n",
    "    def Get(self,LOG=False):\n",
    "        '''\n",
    "        returns msd (no temporal window)\n",
    "        '''\n",
    "        if not LOG: #---  mean\n",
    "            msd = list(map(lambda x:(self.disp[x]['DisplacementX']**2+\\\n",
    "                         self.disp[x]['DisplacementY']**2+\\\n",
    "                         self.disp[x]['DisplacementZ']**2).mean(),\n",
    "                    self.times))\n",
    "        else: #--- geometric mean\n",
    "            msd = list(map(lambda x:10**((np.log10(self.disp[x]['DisplacementX']**2+\\\n",
    "                         self.disp[x]['DisplacementY']**2+\\\n",
    "                         self.disp[x]['DisplacementZ']**2)).mean()),\n",
    "                    self.times))\n",
    "        return np.array(msd)\n",
    "        \n",
    "    def GetPdfJumps(self):\n",
    "        '''\n",
    "        pdf's of jumps\n",
    "        '''\n",
    "        cols = ['DisplacementX','DisplacementY','DisplacementZ']\n",
    "        for itime, itime0, count in zip(self.times[1:],self.times[:-1],range(len(self.times))):\n",
    "            df=self.disp[itime][self.filtr]\n",
    "            df0=self.disp[itime0][self.filtr]\n",
    "            veloc = df[cols]-df0[cols]\n",
    "            if count == 0:\n",
    "                df_concat = np.c_[veloc]\n",
    "            else:\n",
    "                df_concat = np.concatenate([df_concat,veloc],axis=0) \n",
    "        df_abs = np.abs(df_concat.flatten())\n",
    "        filtr = df_abs > 0.0\n",
    "        \n",
    "        hist, bin_edges, err = utl.GetPDF(df_abs[filtr],n_per_decade=4)\n",
    "        utl.PltErr(bin_edges,hist, yerr=err,\n",
    "                  yscale='log',\n",
    "                   xscale='log',\n",
    "        #           ylim=(1e-6,1e4)\n",
    "                  )\n",
    "        #\n",
    "        with open('msd/event_jumps.txt','w') as fp:\n",
    "            np.savetxt(fp,np.c_[bin_edges,hist,err],header='bin_edges hist err')\n",
    "\n",
    "        \n",
    "    def WindowAverage(self,ttime,bins_per_decade=4,LOG=False):\n",
    "        '''\n",
    "        returnd msd (include temporal windows)\n",
    "        '''\n",
    "        time_keys = np.arange(0,len(self.times),2) #--- ignore half step\n",
    "        assert len(ttime) == len(time_keys), 'must be of the same size!'\n",
    "\n",
    "        t0=time.time()\n",
    "        cols = 'DisplacementX DisplacementY DisplacementZ'.split()\n",
    "        for shift in range(1,len(time_keys)): #-1):\n",
    "    #        shift = 1 #--- time index  shift\n",
    "            dt = zip(time_keys,time_keys[shift:]) #--- time tuples\n",
    "#            print(shift,list(dt))\n",
    "            dt_real = list(map(lambda x: x[1]-x[0], zip(ttime,ttime[shift:]))) #--- real time difference\n",
    "#             if not LOG: #---  mean\n",
    "#                 disp = list(map(lambda x: ((self.disp[x[1]]['DisplacementX'][self.filtr]-self.disp[x[0]]['DisplacementX'][self.filtr])**2+\\\n",
    "#                               (self.disp[x[1]]['DisplacementY'][self.filtr]-self.disp[x[0]]['DisplacementY'][self.filtr])**2+\\\n",
    "#                               (self.disp[x[1]]['DisplacementZ'][self.filtr]-self.disp[x[0]]['DisplacementZ'][self.filtr])**2).mean(),\n",
    "#                     zip(time_keys,time_keys[shift:])))\n",
    "            disp    = list(map(lambda x: self.disp[x[1]][cols]-self.disp[x[0]][cols],zip(time_keys,time_keys[shift:])))\n",
    "#             else:\n",
    "#                 disp = list(map(lambda x: 10**((np.log10((self.disp[x[1]]['DisplacementX'][self.filtr]-self.disp[x[0]]['DisplacementX'][self.filtr])**2+\\\n",
    "#                               (self.disp[x[1]]['DisplacementY'][self.filtr]-self.disp[x[0]]['DisplacementY'][self.filtr])**2+\\\n",
    "#                               (self.disp[x[1]]['DisplacementZ'][self.filtr]-self.disp[x[0]]['DisplacementZ'][self.filtr])**2)).mean()),\n",
    "#                     zip(time_keys,time_keys[shift:])))\n",
    "            \n",
    "#            print(np.array(disp).shape)\n",
    "            if shift == 1:\n",
    "                tr_mat=np.c_[dt_real,disp]\n",
    "            else:    \n",
    "                tr_mat = np.concatenate([tr_mat,np.c_[dt_real,disp]],axis=0)\n",
    "\n",
    "        print('1st: t=%s'%(time.time()-t0))\n",
    "\n",
    "        #--- remove dt == 0\n",
    "        filtr = tr_mat[:,0] > 0\n",
    "        tr_mat = tr_mat[filtr]\n",
    "#        print('dt_min=',tr_mat[:,0].min())\n",
    "#        pdb.set_trace()\n",
    "#        print('tr_mat=',tr_mat)\n",
    "\n",
    "        return self.Binning(tr_mat,bins_per_decade)\n",
    "\n",
    "\n",
    "    def WindowAverage2ndMethod(self,ttime,bins_per_decade=4,LOG=False):\n",
    "        '''\n",
    "        returnd msd (include temporal windows)\n",
    "        '''\n",
    "\n",
    "        time_keys = np.arange(0,len(self.times),2) #--- ignore half step\n",
    "        assert len(ttime) == len(time_keys), 'must be of the same size!'\n",
    "        \n",
    "        tij = MsDisp.GetTijMatrix(ttime)\n",
    "        t0 = time.time()\n",
    "        xsq = self.GetXsqMatrix(time_keys,0)\n",
    "        ysq = self.GetXsqMatrix(time_keys,1)\n",
    "        zsq = self.GetXsqMatrix(time_keys,2)\n",
    "#        print(xsq)\n",
    "        print('2nd: t=%s'%(time.time()-t0))\n",
    "\n",
    "                \n",
    "        #--- remove dt == 0\n",
    "        tij_flat = tij.flatten()\n",
    "        filtr = tij_flat > 0.0\n",
    "        usq = (xsq + ysq + zsq).flatten()\n",
    "#         tr_mat = tr_mat[filtr]\n",
    "# #        print('dt_min=',tr_mat[:,0].min())\n",
    "# #        pdb.set_trace()\n",
    "#        print('t,u=',tij_flat[filtr],usq[filtr])\n",
    "\n",
    "        return MsDisp.Binning2nd(tij_flat[filtr],usq[filtr],bins_per_decade),\\\n",
    "               MsDisp.Binning2nd(tij_flat[filtr],usq[filtr],bins_per_decade, LogScale = False)\n",
    "\n",
    "    def GetXsqMatrix(self,tlist, dim):\n",
    "        n = len(tlist)\n",
    "        xijsqMatrix = np.zeros(n*n).reshape((n,n))\n",
    "        atom_indices = self.FiltrdAtoms(tlist) #--- rows corresponding to filtered frame\n",
    "        key = ['DisplacementX','DisplacementY','DisplacementZ'][dim]\n",
    "        for irow in range(n):\n",
    "            for iatom in atom_indices: \n",
    "                x_peratom_timeseries = self.GetTimeSeriesPerAtom(iatom, tlist, key ) \n",
    "                xijsqMatrix[ irow ] +=  (x_peratom_timeseries - x_peratom_timeseries[ irow ])**2\n",
    "        return xijsqMatrix / len(atom_indices)\n",
    "\n",
    "    def GetTimeSeriesPerAtom(self, atomIndx, tlist, key, vacancy = False ):\n",
    "        return list(map(lambda x:self.disp[x][key].iloc[atomIndx], tlist))\n",
    "\n",
    "\n",
    "    def FiltrdAtoms(self,tlist):\n",
    "        time0 = tlist[0]\n",
    "        return self.disp[time0][self.filtr].index\n",
    "\n",
    "    @staticmethod\n",
    "    def GetTijMatrix(tlist):\n",
    "        tlist = np.array(list(tlist))\n",
    "        n = len(tlist)\n",
    "        tijMatrix = np.zeros(n*n).reshape((n,n))\n",
    "        t0 = time.time()\n",
    "        for irow in range(n):\n",
    "            tijMatrix[ irow ] = tlist - tlist[ irow ]\n",
    "        return tijMatrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def Binning2nd(tlist,usq,bins_per_decade, LogScale = True):\n",
    "        #--- binning\n",
    "        xmin = 0.99*tlist.min()\n",
    "        xmax = 1.01*tlist.max()\n",
    "        if LogScale:\n",
    "            n_decades = int(np.ceil(np.log10(xmax/xmin)))\n",
    "            bins = np.logspace(np.log10(xmin),np.log10(xmax),n_decades*bins_per_decade)\n",
    "        else:\n",
    "            bins = np.linspace(xmin,xmax,32)\n",
    "        #\n",
    "        ysum, edges = np.histogram(tlist,bins=bins,weights=usq)\n",
    "        ysum_sq, edges = np.histogram(tlist,bins=bins,weights=usq*usq)\n",
    "        xsum, edges = np.histogram(tlist,bins=bins,weights=tlist)\n",
    "        count, edges = np.histogram(tlist,bins=bins)\n",
    "        #\n",
    "#        filtr = count > 1\n",
    "        filtr = count > 0\n",
    "        ysum = ysum[filtr]\n",
    "        ysum_sq = ysum_sq[filtr]\n",
    "        xsum = xsum[filtr]\n",
    "        count = count[filtr]\n",
    "        assert not np.any(count == 0), 'incerease bin size!'\n",
    "        #\n",
    "        ysum_sq /= count\n",
    "        ysum /= count\n",
    "        xsum /= count\n",
    "        ysum_sq -= (ysum * ysum)\n",
    "#        assert not np.any(ysum_sq < 0.0), 'print %s'%ysum_sq\n",
    "        \n",
    "        return np.c_[xsum,ysum,(ysum_sq/count)**0.5]\n",
    "    \n",
    "    def VacancyDynamics(self, title='void.xyz',\n",
    "                       **kwargs):\n",
    "        '''\n",
    "        return xyz coordinates associated with vacancy \n",
    "        '''\n",
    "        \n",
    "        #--- unwrapped coordinates\n",
    "        times            = self.times[1:]\n",
    "        times_ref        = self.times[:-1]\n",
    "            \n",
    "\n",
    "        cols             = ['DisplacementX','DisplacementY','DisplacementZ']\n",
    "        xsum_concat=np.array([0,0,0])\n",
    "        for itime, itime_ref in zip(times,times_ref):\n",
    "            df           = self.disp[itime]\n",
    "            df0          = self.disp[itime_ref]\n",
    "            veloc        = pd.DataFrame(np.c_[df0['id'],df[cols]-df0[cols]],columns=['id']+cols)\n",
    "            #\n",
    "#            filtr = self.cna[itime_ref]['StructureType'] == 0.0 #--- neighboring atoms\n",
    "        #--- filter atom type\n",
    "            if 'filtr_type' in kwargs:\n",
    "                filtr = self.cna[itime_ref].type == eval(kwargs['filtr_type'])\n",
    "                defect_atoms = self.cna[itime_ref][filtr].id\n",
    "            else:\n",
    "#                defect_atoms = self.cna[itime_ref].id\n",
    "                defect_atoms_ref = self.cna[itime_ref].id\n",
    "                defect_atoms_current = self.cna[itime].id\n",
    "                defect_atoms = list(set(list(defect_atoms_ref)+list(defect_atoms_current)))\n",
    "\n",
    "            veloc        = utl.FilterDataFrame(veloc,key='id',val=defect_atoms)\n",
    "            #\n",
    "            #indx_max     = np.argmax(list(map(lambda x:np.sum(x*x),np.c_[veloc[cols]])))\n",
    "\n",
    "            xsum         = -np.array(veloc[cols].sum()) #---disp\n",
    "            xsum_concat  = np.c_[xsum_concat,xsum]\n",
    "        xsum_concat      = xsum_concat.T\n",
    "        xv               = xsum_concat.cumsum(axis=0) #--- integrate\n",
    "        #--- add initial position\n",
    "        itime            = times_ref[0]\n",
    "        if 'filtr_type' in kwargs:\n",
    "            filtr = self.cna[itime].type == eval(kwargs['filtr_type'])\n",
    "            defect_atoms = self.cna[itime][filtr].id\n",
    "        else:\n",
    "            defect_atoms     = self.cna[itime].id\n",
    "        disps            = utl.FilterDataFrame(self.disp[itime],key='id',val=defect_atoms)\n",
    "        rc               = np.array(disps[['x','y','z']].iloc[0]) #mean())\n",
    "        #--- print\n",
    "        try:\n",
    "            os.system('rm msd/%s'%title)\n",
    "        except:\n",
    "            pass\n",
    "        for itime in range(xv.shape[0]):\n",
    "            sfile        = open('msd/%s'%title,'a')\n",
    "            utl.PrintOvito(pd.DataFrame(np.c_[xv[itime,:]+rc].reshape(1,3),columns=['x','y','z']), \n",
    "                       sfile, 'itime=%s'%itime, attr_list=['x', 'y', 'z'])\n",
    "            sfile.close()\n",
    "        self.xv          = xv\n",
    "        self.dxv         = xsum_concat\n",
    "        \n",
    "    def msdVacancy(self,ttime,bins_per_decade=4,LOG=False,nmin=1):\n",
    "        '''\n",
    "        returnd msd(t) associated with motion of the vacancy\n",
    "        '''\n",
    "        time_keys        =  np.arange(0,len(self.times),2) #--- ignore half step\n",
    "        assert len(ttime)== len(time_keys), 'must be of the same size!'\n",
    "        time_indices     = np.arange(len(time_keys))\n",
    "        for shift in range(1,len(time_keys)):\n",
    "    #        shift = 1 #--- time index  shift\n",
    "            dt      = zip(time_keys,time_keys[shift:]) #--- time tuples\n",
    "            dt_real = list(map(lambda x: x[1]-x[0], zip(ttime,ttime[shift:]))) #--- real time difference\n",
    "            \n",
    "            disp    = list(map(lambda x: self.xv[x[1]]-self.xv[x[0]],zip(time_indices,time_indices[shift:])))\n",
    "            \n",
    "#             disp    = list(map(lambda x: np.mean((self.xv[x[1]]-self.xv[x[0]])*(self.xv[x[1]]-self.xv[x[0]])),\n",
    "#                     zip(time_indices,time_indices[shift:])))\n",
    "            \n",
    "#            print(np.array(disp).shape)\n",
    "            if shift== 1:\n",
    "                tr_mat=np.c_[dt_real,disp]\n",
    "            else:    \n",
    "                tr_mat = np.concatenate([tr_mat,np.c_[dt_real,disp]],axis=0)\n",
    "                \n",
    "        #--- remove dt == 0\n",
    "        filtr = tr_mat[:,0] > 0\n",
    "        tr_mat = tr_mat[filtr]\n",
    "        return self.Binning(tr_mat,bins_per_decade,nmin=nmin)\n",
    "#        print('dt_min=',tr_mat[:,0].min())\n",
    "#        pdb.set_trace()\n",
    "\n",
    "\n",
    "    def Binning(self,tr_mat,bins_per_decade, nmin=1):\n",
    "        #--- binning\n",
    "        xmin       = 0.99*tr_mat[:,0].min()\n",
    "        xmax       = 1.01*tr_mat[:,0].max()\n",
    "        n_decades  = int(np.ceil(np.log10(xmax/xmin)))\n",
    "        bins       = np.logspace(np.log10(xmin),np.log10(xmax),n_decades*bins_per_decade)\n",
    "        \n",
    "        #\n",
    "        count, _   = np.histogram(tr_mat[:,0],bins=bins)\n",
    "        tsum,  _   = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,0])\n",
    "        filtr      = count >= nmin\n",
    "        #  \n",
    "        xsum, _    = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,1])\n",
    "        ysum, _    = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,2])\n",
    "        zsum, _    = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,3])\n",
    "\n",
    "        xsum_sq, _ = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,1]*tr_mat[:,1])\n",
    "        ysum_sq, _ = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,2]*tr_mat[:,2])\n",
    "        zsum_sq, _ = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,3]*tr_mat[:,3])\n",
    "        #\n",
    "        xsum       = xsum[filtr]\n",
    "        ysum       = ysum[filtr]\n",
    "        zsum       = zsum[filtr]\n",
    "        #\n",
    "        xsum_sq    = xsum_sq[filtr]\n",
    "        ysum_sq    = ysum_sq[filtr]\n",
    "        zsum_sq    = zsum_sq[filtr]\n",
    "        #\n",
    "        tsum       = tsum[filtr]\n",
    "        count      = count[filtr]\n",
    "        assert not np.any(count < nmin), 'incerease bin size!'\n",
    "        #\n",
    "        xsum_sq   /= count\n",
    "        ysum_sq   /= count\n",
    "        zsum_sq   /= count\n",
    "        #\n",
    "        xsum      /= count\n",
    "        ysum      /= count\n",
    "        zsum      /= count\n",
    "        #     \n",
    "        tsum      /= count\n",
    "        #\n",
    "        xsum_sq   -= (xsum * xsum)\n",
    "        ysum_sq   -= (ysum * ysum)\n",
    "        zsum_sq   -= (zsum * zsum)\n",
    "        assert np.all(xsum_sq >= 0) and np.all(ysum_sq >= 0) and np.all(zsum_sq >= 0)\n",
    "        #\n",
    "        var        = ( xsum_sq + ysum_sq + zsum_sq ) / 3.0\n",
    "#        assert not np.any(ysum_sq < 0.0), 'print %s'%ysum_sq\n",
    "        \n",
    "        return np.c_[tsum,var,np.zeros( len( tsum ) ) ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def junk(**kwargs):\n",
    "#     print(kwargs)\n",
    "\n",
    "# junk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomChoice(lmpDisp):\n",
    "    natom = lmpDisp.coord_atoms_broken[0].shape[0]\n",
    "    size=np.min([natom,eval(confParser['MsdAnalysis']['natom'])])\n",
    "    indices = np.random.choice(range(natom),replace=False,\n",
    "                               size=size)\n",
    "    assert indices.shape[ 0 ] == size\n",
    "    filtr = np.zeros(natom,dtype=bool)\n",
    "    filtr[ indices ] = True\n",
    "    assert np.sum(filtr) == indices.shape[0], '%s %s' %(np.sum(filtr), indices.shape[0])\n",
    "    \n",
    "    return filtr\n",
    "\n",
    "def main(data):\n",
    "    \n",
    "    if not eval(confParser['MsdAnalysis']['MsdAnalysis']):\n",
    "        return\n",
    "    \n",
    "    \n",
    "    !mkdir msd\n",
    "    \n",
    "    #----------------------------------\n",
    "    #--- msd: dynamics of vacant site \n",
    "    #--- based on the cna analysis\n",
    "    #----------------------------------\n",
    "    msd          = MsDisp(data.lmpDisp, \n",
    "                         RandomChoice(data.lmpDisp), #--- filter \n",
    "                         data_defect.lmpData,\n",
    "                        )\n",
    "    #---  vacancy\n",
    "    if eval(confParser['MsdAnalysis']['vacancy']):\n",
    "        msd.VacancyDynamics(title='void2.xyz', \n",
    "                            **confParser['MsdAnalysis'])\n",
    "        vac_data     = msd.msdVacancy(data.lmpData.headers['Time'][::2],\n",
    "                                      bins_per_decade=4,LOG=False,nmin=10)\n",
    "        #\n",
    "        with open('msd/msd_vac_cna.txt','w') as fp:\n",
    "#             np.savetxt(fp,vac_data,header='t\\tmsd\\terr')\n",
    "             np.savetxt(fp,vac_data,header='t dx dy dz')\n",
    "\n",
    "#    msd.GetPdfJumps() #--- jump distributions\n",
    "\n",
    "     #--- msd\n",
    "    if eval(confParser['MsdAnalysis']['total']):\n",
    "        ans, ans_lin = msd.WindowAverage2ndMethod(data.lmpData.headers['Time'][::2],\n",
    "                                                  bins_per_decade=4,LOG=False) #---msd\n",
    "    \n",
    "        with open('msd/msd.txt','w') as fp:\n",
    "            np.savetxt(fp,ans,header='t\\tmsd\\terr')\n",
    "        with open('msd/msd_lin.txt','w') as fp:\n",
    "            np.savetxt(fp,ans_lin,header='t\\tmsd\\terr')\n",
    "    #\n",
    "\n",
    "        #--- correlated noise\n",
    "    #     xvv = np.c_[list(map(lambda x:msd.dxv[x]+msd.dxv[x+1],range(1,msd.dxv.shape[0],2)))] #--- include half steps\n",
    "    #     with open('msd/noise.txt','w') as fp:\n",
    "    #         np.savetxt(fp,np.c_[lmpData.headers['Time'][1:-1:2],xvv],header='time dx dy dz')\n",
    "\n",
    "        #---  filter based on atom types\n",
    "        types      = list(set(data.lmpDisp.coord_atoms_broken[0]['type']))\n",
    "        for itype in types:\n",
    "            filtr  = data.lmpDisp.coord_atoms_broken[0]['type'] == itype\n",
    "            msd    = MsDisp( data.lmpDisp,\n",
    "                             filtr, #--- filter \n",
    "                             data_defect.lmpData\n",
    "                           )\n",
    "            ans, _ = msd.WindowAverage2ndMethod(data.lmpData.headers['Time'][::2],\n",
    "                                               bins_per_decade=4,LOG=False)\n",
    "            #--- print\n",
    "            with open('msd/msd_type%s.txt'%itype,'w') as fp:\n",
    "                np.savetxt(fp,ans,header='t\\tmsd\\terr')\n",
    "\n",
    "\n",
    "    #--- correlated noise\n",
    "#    xvv = np.c_[list(map(lambda x:msd.dxv[x]+msd.dxv[x+1],range(1,msd.dxv.shape[0],2)))] #--- include half steps\n",
    "#    with open('msd/noise.txt','w') as fp:\n",
    "#        np.savetxt(fp,np.c_[lmpData.headers['Time'][1:-1:2],xvv],header='time dx dy dz')\n",
    "\n",
    "#     with open('msd/msd_logAveraged.txt','w') as fp:\n",
    "#         np.savetxt(fp,ans_logAveraged,header='t\\tmsd\\terr')\n",
    "\n",
    "\n",
    "\n",
    "    #----------------------------------\n",
    "    #--- msd: dynamics of vacant site \n",
    "    #--- based on the ws analysis\n",
    "    #----------------------------------\n",
    "    if eval(confParser['MsdAnalysis']['WignerSeitz']):\n",
    "        start_frame  = 0\n",
    "        msd          = MsDisp( data.lmpDisp_defect, \n",
    "                              np.ones(data.lmpDisp_defect.coord_atoms_broken[start_frame].shape[0],dtype=bool) #--- filter \n",
    "                            )\n",
    "        ans          = msd.WindowAverage(data.lmpData.headers['Time'][start_frame::2],\n",
    "                                         bins_per_decade= 4,\n",
    "                                         LOG            = False\n",
    "                                                 ) #---msd\n",
    "        !mkdir msd\n",
    "        with open('msd/msd_vac_ws.txt','w') as fp:\n",
    "             np.savetxt(fp,ans,header='t\\tmsd\\terr')\n",
    "\n",
    "\n",
    "\n",
    "main(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy barriers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnergyBarrier:\n",
    "    '''\n",
    "    return energy barriers corresponding to diffusional hopping\n",
    "    '''\n",
    "    def __init__(self,events_directory,evlist_directory,lmpData):\n",
    "        self.events_dir = events_directory\n",
    "        self.evlist_dir = evlist_directory\n",
    "        self.lmpData = lmpData.coord_atoms_broken[0]\n",
    "        \n",
    "    def Parse(self):\n",
    "        '''\n",
    "        parse event files\n",
    "        '''\n",
    "        self.events_id_energy = self.ParseEvents_dir()\n",
    "        self.catalog = self.ParseEvList_dir()\n",
    "        \n",
    "        \n",
    "    def ParseEvents_dir(self):\n",
    "        files = os.listdir(self.events_dir)\n",
    "        d=[]\n",
    "        for sfile in files:\n",
    "            if not '.xyz' in sfile: #--- skip .xyz files \n",
    "                try:\n",
    "                    filee=open('%s/%s'%(self.events_dir,sfile)) #--- open file\n",
    "                    xstrs = filee.readlines()\n",
    "                    event_id = int(xstrs[0].split()[-1]) #--- event id\n",
    "                    barrier = float(xstrs[2].split()[-1]) #--- energy\n",
    "                    ncluster =  int(xstrs[15].split()[-1])                 \n",
    "                    shape_cluster_atoms =  int(xstrs[16].split()[-1])\n",
    "                    atom_id = int(xstrs[17+ncluster].split()[0])\n",
    "                    #print(atom_id)\n",
    "                    d = np.c_[event_id,atom_id,barrier] if len(d) == 0 else\\\n",
    "                    np.concatenate([d,np.c_[event_id,atom_id,barrier]])\n",
    "#                    d.setdefault(event_id,[]).append(barrier) #--- store\n",
    "                except:\n",
    "        #            traceback.print_exc()\n",
    "                    continue\n",
    "            \n",
    "        #--- extract types\n",
    "        df=self.lmpData\n",
    "        atom_ids = d[:,1]\n",
    "        types = utl.FilterDataFrame(df, \n",
    "                    key='id', \n",
    "                    val=atom_ids\n",
    "                   )['type']\n",
    "\n",
    "        return pd.DataFrame(np.c_[types,d],columns=['atom_type','event_id','atom_id','barrier'])\n",
    "\n",
    "    def ParseEvList_dir(self):\n",
    "        files = os.listdir(self.evlist_dir)\n",
    "        events={}\n",
    "        for sfile in files:\n",
    "            try:\n",
    "                kmc_step = int(sfile.split('_')[-1])\n",
    "        #        print(kmc_step)\n",
    "                filee=open('%s/%s'%(self.evlist_dir,sfile)) #--- open file\n",
    "                events[kmc_step] = pd.read_csv(filee,delim_whitespace=True).iloc[1:]#delimiter='')\n",
    "            except:\n",
    "                continue\n",
    "        return events\n",
    "        \n",
    "    def SplitByType(self):\n",
    "        '''\n",
    "        return energies (parsed from catalogs) slipt by atom types\n",
    "        '''\n",
    "        kmc_steps = list(self.catalog.keys())\n",
    "        kmc_steps.sort()\n",
    "\n",
    "\n",
    "        #--- dict based on types\n",
    "        df_concat = {}\n",
    "        types = list(set(self.lmpData.type))\n",
    "        for itype in types:\n",
    "            df_concat[str(itype)] = {}\n",
    "\n",
    "        for kmc_step in kmc_steps: #--- kmc loop\n",
    "            df = self.catalog[kmc_step]\n",
    "            sdict=df.groupby(by='#TypeId').groups #--- group by type\n",
    "            for itype in sdict:\n",
    "                indices = sdict[itype] #--- row index: atoms with  '#TypeId' == itype\n",
    "                cond = len(df_concat[itype]) == 0 #--- empty key?\n",
    "                df_concat[itype] = np.c_[df.loc[indices]] if cond else\\\n",
    "                np.concatenate([df_concat[itype],np.c_[df.loc[indices]]],axis=0)\n",
    "\n",
    "        self.energyByType = {}\n",
    "        for itype in df_concat:\n",
    "             self.energyByType[ itype ] = pd.DataFrame(df_concat[itype],columns=list(df.keys()))        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data):\n",
    "    if not eval(confParser['EnergyBarrier']['EnergyBarrier']):\n",
    "        return\n",
    "    \n",
    "    eb = EnergyBarrier('%s/EVENTS_DIR'%confParser['input files']['input_path'],\n",
    "                       '%s/EVLIST_DIR'%confParser['input files']['input_path'],\n",
    "                       data.lmpData\n",
    "\n",
    "                      )\n",
    "    eb.Parse()\n",
    "    eb.SplitByType()\n",
    "\n",
    "    #eb.events_id_energy extract from Events_dir\n",
    "    #self.energyByType extract from catalogs\n",
    "\n",
    "    #--- write to file\n",
    "    !mkdir msd\n",
    "    with open('msd/eventID_barrier.txt','w') as fp:\n",
    "        np.savetxt(fp,\n",
    "                   np.c_[eb.events_id_energy],\n",
    "                   header='atom_type event_id atom_id barrier')\n",
    "\n",
    "    #--- write to file: energy from catalogs\n",
    "    for itype in eb.energyByType.keys():\n",
    "        with open('msd/eventID_barrier_catalog_type%s.txt'%itype,'w') as fp:\n",
    "        #--- concat different types\n",
    "            sarr = np.c_[eb.energyByType[itype][['AtomId','eventId','barrier']]].astype(float)\n",
    "            np.savetxt(fp,\n",
    "                       sarr,\n",
    "                       header='AtomId eventId barrier'\n",
    "                      )\n",
    "main(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## arrhenius law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Temperature:\n",
    "    def __init__(self,temp_range,nrun,verbose=False):\n",
    "        self.temps =  temp_range\n",
    "        self.nrun = nrun\n",
    "        self.verbose = verbose\n",
    "#         pdb.set_trace()\n",
    "#        self.temps_runs = np.concatenate(list(map(lambda x:self.BuildTempRealizationPair([x[0]],np.arange(x[1])),\n",
    "#            zip(self.temps,self.nrun))))\n",
    "\n",
    "        self.temps_runs = np.concatenate(list(map(lambda x:self.BuildTempRealizationPair([x[0]],x[1]),\n",
    "             zip(self.temps,self.nrun))))\n",
    "        \n",
    "    \n",
    "    def BuildTempRealizationPair(self,temps,nrun):\n",
    "        t,r=np.meshgrid(temps,nrun,indexing='ij')\n",
    "        return np.array(list(zip(t.flatten(),r.flatten())))\n",
    "        \n",
    "    def ModifyNrun(self,dirs):\n",
    "        #--- modify dirs\n",
    "        count = -1\n",
    "        dirs_copy = dirs[:]\n",
    "        for _, indx in zip(self.temps,range(len(self.temps))):\n",
    "            nrun_mod = self.nrun[indx][:]\n",
    "            for y in self.nrun[indx]:\n",
    "                count += 1\n",
    "                x = dirs[count]\n",
    "                if not os.path.isfile(x): #--- if false: remove file from \"dirs\"\n",
    "                    dirs_copy.remove(x)\n",
    "                    nrun_mod.remove(y)\n",
    "            self.nrun[indx] = nrun_mod[:]\n",
    "\n",
    "            assert len(self.nrun[indx]) > 0, 'temp = %s has no data!'%(self.temps[indx])\n",
    "                \n",
    "        self.temps_runs = np.concatenate(list(map(lambda x:self.BuildTempRealizationPair([x[0]],x[1]),\n",
    "             zip(self.temps,self.nrun))))\n",
    "        return dirs_copy\n",
    "        \n",
    "    def Parse(self,dirs):\n",
    "            \n",
    "        dirs = self.ModifyNrun(dirs)\n",
    "#         print('dirs:',dirs)\n",
    "        self.data=list(map(lambda x:np.loadtxt(x,ndmin=2),dirs))\n",
    "        if self.verbose:\n",
    "            n = np.array(self.nrun).flatten()\n",
    "            list(map(lambda x:print('Parsing: %s data.shape is: %s'%(x[1],x[0].shape)),zip(self.data,n)))\n",
    "#        print('np.array(self.data):',np.array(self.data))\n",
    "\n",
    "        \n",
    "    def Plot(self,**kwargs):\n",
    "#        print(list(self.temps_runs))\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs\n",
    "                    else (1.0,0.5,0.5,0.5)\n",
    "                   )\n",
    "        for data, temp_run, count in zip(self.data,self.temps_runs,range(len(self.data))): \n",
    "            temp = temp_run[0]\n",
    "            try:\n",
    "                utl.PltErr(data[:,0],data[:,1],\n",
    "                       yerr=data[:,2],\n",
    "                       ax = self.ax,\n",
    "                       attrs=symbols.GetAttrs(count=count%7,label=r'$%s$'%temp),\n",
    "                       Plot=False,\n",
    "                      )\n",
    "            except:\n",
    "                continue\n",
    "        #\n",
    "        utl.PltErr(None,\n",
    "                   None,\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "#                 legend=legends.Get(),\n",
    "                   **kwargs\n",
    "                  )\n",
    "\n",
    "\n",
    "\n",
    "    def Binning(self,tr_mat,bins_per_decade, nmin=1):\n",
    "        #--- binning\n",
    "        xmin       = 0.99*tr_mat[:,0].min()\n",
    "        xmax       = 1.01*tr_mat[:,0].max()\n",
    "        n_decades  = int(np.ceil(np.log10(xmax/xmin)))\n",
    "        bins       = np.logspace(np.log10(xmin),np.log10(xmax),n_decades*bins_per_decade)\n",
    "        \n",
    "        #\n",
    "        count, _   = np.histogram(tr_mat[:,0],bins=bins)\n",
    "        tsum,  _   = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,0])\n",
    "        filtr      = count >= nmin\n",
    "        #  \n",
    "        xsum, _    = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,1])\n",
    "        ysum, _    = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,2])\n",
    "        zsum, _    = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,3])\n",
    "\n",
    "        xsum_sq, _ = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,1]*tr_mat[:,1])\n",
    "        ysum_sq, _ = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,2]*tr_mat[:,2])\n",
    "        zsum_sq, _ = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,3]*tr_mat[:,3])\n",
    "        #\n",
    "        xsum       = xsum[filtr]\n",
    "        ysum       = ysum[filtr]\n",
    "        zsum       = zsum[filtr]\n",
    "        #\n",
    "        xsum_sq    = xsum_sq[filtr]\n",
    "        ysum_sq    = ysum_sq[filtr]\n",
    "        zsum_sq    = zsum_sq[filtr]\n",
    "        #\n",
    "        tsum       = tsum[filtr]\n",
    "        count      = count[filtr]\n",
    "        print('count=',count)\n",
    "        assert not np.any(count < nmin), 'incerease bin size!'\n",
    "        #\n",
    "        xsum_sq   /= count\n",
    "        ysum_sq   /= count\n",
    "        zsum_sq   /= count\n",
    "        #\n",
    "        xsum      /= count\n",
    "        ysum      /= count\n",
    "        zsum      /= count\n",
    "        #     \n",
    "        tsum      /= count\n",
    "        #\n",
    "        xsum_sq   -= (xsum * xsum)\n",
    "        ysum_sq   -= (ysum * ysum)\n",
    "        zsum_sq   -= (zsum * zsum)\n",
    "        assert np.all(xsum_sq >= 0) and np.all(ysum_sq >= 0) and np.all(zsum_sq >= 0)\n",
    "        #\n",
    "        var        = ( xsum_sq + ysum_sq + zsum_sq ) / 3.0\n",
    "#        assert not np.any(ysum_sq < 0.0), 'print %s'%ysum_sq\n",
    "        \n",
    "        return np.c_[tsum,var,np.zeros( len( tsum ) ) ] \n",
    "\n",
    "\n",
    "    def EnsAverage2nd(self,\n",
    "                   log_scale_x=False,log_scale_y=False,\n",
    "                   col_x=0,col_y=1,\n",
    "                   n_bins_per_decade=6,\n",
    "                  n_thresh=0,\n",
    "                   ymin=-sys.maxsize,ymax=sys.maxsize\n",
    "                  ):\n",
    "        kount = 0\n",
    "        self.data_averaged = {} \n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp\n",
    "            nruns = len(self.nrun[indx])\n",
    "            data = self.data[kount:kount+nruns]\n",
    "#             if self.verbose:\n",
    "#                 print('data.shape:',np.array(data).shape)\n",
    "    \n",
    "            filtr = list(map(lambda x:x.shape[0] > 0,data)) #--- filter empty arrays\n",
    "    \n",
    "            data = np.concatenate(np.array(data)[filtr]) #,axis=0)\n",
    "            if self.verbose:\n",
    "                print('data.shape:',np.array(data).shape)\n",
    "#             pdb.set_trace()\n",
    "        \n",
    "            self.data_averaged[ temp ] = self.Binning(data,n_bins_per_decade,nmin=n_thresh)\n",
    "\n",
    "            kount += nruns #self.nrun\n",
    "            \n",
    "    def EnsAverage(self,\n",
    "                   log_scale_x=False,log_scale_y=False,\n",
    "                   col_x=0,col_y=1,\n",
    "                   n_bins_per_decade=6,\n",
    "                  n_thresh=0,\n",
    "                   ymin=-sys.maxsize,ymax=sys.maxsize\n",
    "                  ):\n",
    "        kount = 0\n",
    "        self.data_averaged = {} #np.zeros(len(self.temps))\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp\n",
    "            nruns = len(self.nrun[indx])\n",
    "            data = self.data[kount:kount+nruns]\n",
    "            if self.verbose:\n",
    "                print('data.shape:',np.array(data).shape)\n",
    "#             print('np.array(data):',np.array(data))\n",
    "#            pdb.set_trace()\n",
    "    \n",
    "            filtr = list(map(lambda x:x.shape[0] > 0,data)) #--- filter empty arrays\n",
    "    \n",
    "            data = np.concatenate(np.array(data)[filtr]) #,axis=0)\n",
    "            self.data_averaged[ temp ] = self.hist(data,\n",
    "                                                   log_scale_x,log_scale_y,\n",
    "                                                   n_bins_per_decade=n_bins_per_decade,\n",
    "                                                   col_x = col_x, col_y = col_y,\n",
    "                                                   n_thresh=n_thresh,\n",
    "                                                   ymin=ymin,ymax=ymax\n",
    "                                                  )\n",
    "            kount += nruns #self.nrun\n",
    "\n",
    "    def hist(self,data,\n",
    "             log_scale_x,log_scale_y,\n",
    "             n_bins_per_decade=6,\n",
    "             col_x = 0, col_y = 1,\n",
    "             n_thresh=0,\n",
    "                   ymin=-sys.maxsize,ymax=sys.maxsize\n",
    "            ):\n",
    "        n_thresh = n_thresh\n",
    "            #--- average\n",
    "        xdata = data[:,col_x]\n",
    "        ydata = data[:,col_y]\n",
    "        filtr = np.all([ydata>=ymin,ydata<ymax],axis=0)\n",
    "        xdata = xdata[filtr]\n",
    "        ydata = ydata[filtr]\n",
    "        if log_scale_x:\n",
    "            xmin = np.floor(np.log10(xdata).min())\n",
    "            xmax = np.ceil(np.log10(xdata).max())\n",
    "            n_decades = int((xmax - xmin))\n",
    "            bins = np.logspace(xmin,xmax,n_decades*n_bins_per_decade)\n",
    "        else:\n",
    "            xmin = xdata.min()*0.999\n",
    "            xmax = xdata.max()*1.001\n",
    "            bins = np.linspace(xmin,xmax,n_bins_per_decade)\n",
    "            \n",
    "        #\n",
    "        count, _ = np.histogram(xdata,bins=bins)\n",
    "        xsum, _  = np.histogram(xdata,bins=bins,weights=xdata)\n",
    "        weights = ydata if not log_scale_y else np.log10(ydata)\n",
    "        ysum, _  = np.histogram(xdata,bins=bins,weights=weights)\n",
    "        ysum_sq, _  = np.histogram(xdata,bins=bins,weights=weights*weights)\n",
    "        #\n",
    "        xsum = xsum[count>n_thresh]\n",
    "        ysum = ysum[count>n_thresh]\n",
    "        ysum_sq = ysum_sq[count>n_thresh]\n",
    "        count = count[count>n_thresh]\n",
    "        #\n",
    "        xsum /= count\n",
    "        ysum /= count\n",
    "        ysum_sq /= count\n",
    "        std = np.sqrt((ysum_sq - ysum * ysum)/count)\n",
    "        if log_scale_y:\n",
    "            ysum = 10 ** ysum\n",
    "            std = 0.5 * ysum * (1+2*std*np.log(10))\n",
    "        return np.c_[xsum,ysum,std]\n",
    "        \n",
    "        \n",
    "#            utl.PltErr(xsum,ysum,ax=self.ax)\n",
    "            \n",
    "\n",
    "    def PlotAverage(self,rescale=False,**kwargs):\n",
    "#        print(list(self.temps_runs))\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "        for temp, count in zip(self.temps,range(len(self.temps))): \n",
    "            data = self.data_averaged[ temp ]\n",
    "            xdata = data[:,0]\n",
    "            ydata = data[:,1]\n",
    "            yerr = data[:,2]\n",
    "            if rescale:\n",
    "                ydata /= xdata\n",
    "                yerr /= xdata\n",
    "            utl.PltErr(xdata,ydata,\n",
    "                   yerr=yerr,\n",
    "                   ax = self.ax,\n",
    "                   attrs=symbols.GetAttrs(count=count%7 if not 'count' in kwargs else kwargs['count'],label=r'$%s$'%temp,nevery=1),\n",
    "                   Plot=False,\n",
    "                  )\n",
    "\n",
    "        utl.PltErr(None,\n",
    "                   None, \n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "#                    legend=legends.Get(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "        \n",
    "        \n",
    "    def func2nd(self,x,y0,c0,alpha):\n",
    "#        return y0+c0*(x/x0)**alpha\n",
    "        return y0*y0+c0*x**alpha\n",
    "\n",
    "    def func3rd(self,x,c0,alpha):\n",
    "         return c0*x**alpha\n",
    "\n",
    "    def Fit(self,Plot=None,\n",
    "            shift = False,\n",
    "#             SIGMA=False,\n",
    "            plotAttrs=None,\n",
    "            bounds=(-np.inf, np.inf),\n",
    "            xlo=float('-inf'),xhi=float('inf'),\n",
    "            **kwargs):\n",
    "        self.Diffusion = {}\n",
    "        self.exponent = {}\n",
    "        pref=1e-10*1e-10 #--- ang^2 to m^2\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=plotAttrs['bbox_to_anchor'] if 'bbox_to_anchor' in plotAttrs\n",
    "                    else (1.0,0.5,0.5,0.5),\n",
    "                   fontsize=18,\n",
    "                   )\n",
    "\n",
    "        if Plot:\n",
    "            ax = utl.PltErr(None,None,\n",
    "                            Plot=False)\n",
    "        #\n",
    "        for temp, count in zip(self.temps,range(len(self.temps))): \n",
    "            nruns = len(self.nrun[count])\n",
    "\n",
    "            self.smat = smat = self.data_averaged[ temp ] if nruns > 1 else self.data[count]\n",
    "\n",
    "            xdata=smat[:,0]\n",
    "            ydata=smat[:,1]\n",
    "            yerr = smat[:,2]\n",
    "#             print(smat)\n",
    "\n",
    "        \n",
    "            #--- set limits:\n",
    "            if self.verbose:\n",
    "                print('limits:',xlo,xhi)\n",
    "\n",
    "            filtr = np.ones(xdata.shape[0],dtype=bool)\n",
    "            filtr = np.all([filtr,xdata > xlo],axis=0)\n",
    "            filtr = np.all([filtr,xdata <= xhi],axis=0)\n",
    "            assert np.any(filtr), 'empty arrays!'\n",
    "            if self.verbose:\n",
    "                print('filtr=',filtr)\n",
    "            \n",
    "            #--- error in y\n",
    "            if 'sigma' in kwargs:\n",
    "                kwargs['sigma'] = 2*yerr[filtr]\n",
    "\n",
    "            #--- fit\n",
    "#             print(kwargs)\n",
    "            popt, pcov = curve_fit(self.func2nd, xdata[filtr], ydata[filtr],\n",
    "                                   bounds=bounds, #([1e-1, 1e5,0.5], [1e0, 1e7,2.0]), #[(4e-3, 1e5,0.5), (1e-2, 1e7,2.0)],#bounds,\n",
    "                                    **kwargs\n",
    "                                    )\n",
    "            self.popt = popt\n",
    "            self.pcov = pcov\n",
    "            self.filtr = filtr\n",
    "            #--- uncertainties\n",
    "            if self.verbose:\n",
    "                print('Temp=%s,y0,c0,alpha'%temp,list(popt),pcov)\n",
    "                print('alpha=%s'%popt[2])\n",
    "            y0=popt[0]\n",
    "            alpha=popt[2]\n",
    "            err_alpha = pcov[2,2]**0.5\n",
    "            c0=popt[1]\n",
    "            dc = pcov[1,1]**0.5\n",
    "            tau=1#popt[0]\n",
    "            dtau=0#pcov[0,0]**0.5\n",
    "            self.time_scale = tau * (y0/c0)**(1/alpha)\n",
    "            if self.verbose:\n",
    "                print('Temp=%s,tau=%s'%(temp,self.time_scale))\n",
    "                print('err_alpha=%s'%err_alpha)\n",
    "#             self.Diffusion[temp] = [pref*c0/tau,pref*c0/tau,pref*c0/tau]\n",
    "            self.Diffusion[temp] = [pref*c0/(tau)**alpha, pref*(c0+dc)/(tau-dtau)**alpha, \n",
    "                                    pref*(c0-dc)/(tau+dtau)**alpha]\n",
    "            self.exponent[temp] = [alpha,alpha+err_alpha,alpha-err_alpha]\n",
    "            if Plot:\n",
    "                #---fit\n",
    "                y0=0 #kam\n",
    "                xdata_shift = xdata*20**count if shift else xdata\n",
    "                utl.PltErr(xdata_shift,\n",
    "                                (self.func2nd(xdata,*popt)-y0),#-y0)/xdata_shift,\n",
    "                                attrs={'fmt':'-.','color':symbols.colors[count%7],\\\n",
    "                                       'label':r'$\\alpha=%3.2f$'%popt[2]},\n",
    "                           Plot=False,ax=ax)\n",
    "                #--- points\n",
    "#                temp= [1000,1200,1400,1600,1800,2000][count]\n",
    "                utl.PltErr(xdata_shift,\n",
    "                           (ydata-y0),#-y0)/xdata_shift,\n",
    "                           yerr=(yerr),#-y0),#/xdata_shift,\n",
    "#                           attrs=symbols.GetAttrs(count=count%7,label=r'$%s$'%temp,fmt='.'),\n",
    "                           attrs=symbols.GetAttrs(count=count%7,fmt='.'),\n",
    "                           ax=ax,\n",
    "                           Plot=False,\n",
    "                          )\n",
    "        if Plot:\n",
    "            utl.PltErr(None,\n",
    "                       None, \n",
    "                       ax=ax,\n",
    "                       Plot=False,\n",
    "                         legend=legends.Get(),\n",
    "                       DrawFrame=DRAW_FRAME,\n",
    "                       **plotAttrs\n",
    "                      )\n",
    "\n",
    "    def FitLinear(self,Plot=None,\n",
    "            shift = False,\n",
    "#             SIGMA=False,\n",
    "            plotAttrs=None,\n",
    "            y0=0.0,\n",
    "            bounds=(-np.inf, np.inf),\n",
    "            xlo=float('-inf'),xhi=float('inf'),\n",
    "            **kwargs):\n",
    "        self.Diffusion = {}\n",
    "        self.exponent = {}\n",
    "        pref=1e-10*1e-10 #--- ang^2 to m^2\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=plotAttrs['bbox_to_anchor'] if 'bbox_to_anchor' in plotAttrs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "\n",
    "        if Plot:\n",
    "            ax = utl.PltErr(None,None,\n",
    "                            Plot=False)\n",
    "        #\n",
    "        for temp, count in zip(self.temps,range(len(self.temps))): \n",
    "            nruns = len(self.nrun[count])\n",
    "            self.smat = smat = self.data_averaged[ temp ] if nruns > 1 else self.data[count]\n",
    "\n",
    "            xdata=smat[:,0]\n",
    "            ydata=smat[:,1] - y0*y0\n",
    "            yerr = smat[:,2]\n",
    "#             print(smat)\n",
    "\n",
    "        \n",
    "            #--- set limits:\n",
    "            if self.verbose:\n",
    "                print('limits:',xlo,xhi)\n",
    "\n",
    "            filtr = np.ones(xdata.shape[0],dtype=bool)\n",
    "            filtr = np.all([filtr,xdata > xlo],axis=0)\n",
    "            filtr = np.all([filtr,xdata <= xhi],axis=0)\n",
    "            assert np.any(filtr), 'empty arrays!'\n",
    "            if self.verbose:\n",
    "                print('filtr=',filtr)\n",
    "            \n",
    "            #--- error in y\n",
    "            if 'sigma' in kwargs:\n",
    "                kwargs['sigma'] = 2*yerr[filtr]\n",
    "\n",
    "            #--- fit\n",
    "#             print(kwargs)\n",
    "            popt, pcov = curve_fit(self.func3rd, xdata[filtr], ydata[filtr],\n",
    "                                   bounds=bounds, #([1e-1, 1e5,0.5], [1e0, 1e7,2.0]), #[(4e-3, 1e5,0.5), (1e-2, 1e7,2.0)],#bounds,\n",
    "                                    **kwargs\n",
    "                                    )\n",
    "            self.popt = popt\n",
    "            self.filtr = filtr\n",
    "            #--- uncertainties\n",
    "            if self.verbose:\n",
    "                print('Temp=%s,y0,c0,alpha'%temp,list(popt),pcov)\n",
    "#            y0=popt[0]\n",
    "            alpha=popt[1]\n",
    "            err_alpha = pcov[1,1]**0.5\n",
    "            c0=popt[0]\n",
    "            dc = pcov[0,0]**0.5\n",
    "            tau=1#popt[0]\n",
    "            dtau=0#pcov[0,0]**0.5\n",
    "#            self.time_scale = tau * (y0/c0)**(1/alpha)\n",
    "#            if self.verbose:\n",
    "#                print('Temp=%s,tau=%s'%(temp,self.time_scale))\n",
    "#             self.Diffusion[temp] = [pref*c0/tau,pref*c0/tau,pref*c0/tau]\n",
    "            self.Diffusion[temp] = [pref*c0/(tau)**alpha, pref*(c0+dc)/(tau-dtau)**alpha, \n",
    "                                    pref*(c0-dc)/(tau+dtau)**alpha]\n",
    "            self.exponent[temp] = [alpha,alpha+err_alpha,alpha-err_alpha]\n",
    "            if Plot:\n",
    "                #---fit\n",
    "#                y0=0 #kam\n",
    "                xdata_shift = xdata*20**count if shift else xdata\n",
    "                utl.PltErr(xdata_shift,\n",
    "                                self.func3rd(xdata,*popt),\n",
    "                                attrs={'fmt':'-.','color':symbols.colors[count%7]},\n",
    "                           Plot=False,ax=ax)\n",
    "                #--- points\n",
    "#                temp= [1000,1200,1400,1600,1800,2000][count]\n",
    "                utl.PltErr(xdata_shift,\n",
    "                           ydata,\n",
    "                           yerr=yerr,\n",
    "                           attrs=symbols.GetAttrs(count=count%7,label=r'$%s$'%temp,fmt='.'),\n",
    "                           ax=ax,\n",
    "                           Plot=False,\n",
    "                          )\n",
    "        if Plot:\n",
    "            utl.PltErr(None,\n",
    "                       None, \n",
    "                       ax=ax,\n",
    "                       Plot=False,\n",
    "#                       legend=legends.Get(),\n",
    "                       DrawFrame=DRAW_FRAME,\n",
    "                       **plotAttrs\n",
    "                      )\n",
    "            \n",
    "    def PlotDiff(self,**kwargs):\n",
    "        symbols=utl.Symbols()\n",
    "        utl.PltErr(1.0/np.array(self.temps),\n",
    "                   list(map(lambda x:self.Diffusion[x][0],self.temps)),\n",
    "                   yerr=list(map(lambda x:(self.Diffusion[x][1]-self.Diffusion[x][2])/2,self.temps)),\n",
    "                   attrs=symbols.GetAttrs(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "\n",
    "    def PlotExponent(self,**kwargs):\n",
    "        symbols=utl.Symbols()\n",
    "        ax=utl.PltErr([0.5e-3,1e-3],[1,1],attrs={'fmt':'-.r'},Plot=False)\n",
    "        utl.PltErr(1.0/np.array(self.temps),\n",
    "                   list(map(lambda x:self.exponent[x][0],self.temps)),\n",
    "                   yerr=list(map(lambda x:1.0*(self.exponent[x][1]-self.exponent[x][2]),self.temps)),\n",
    "                   attrs=symbols.GetAttrs(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   ax=ax,\n",
    "                   **kwargs\n",
    "                  )\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    if eval(confParser['flags']['RemoteMachine']):\n",
    "        return\n",
    "    !mkdir png\n",
    "    #--- temp object\n",
    "    temp = Temperature(\n",
    "        [1000],[list(range(8))]*10,\n",
    "#          verbose = True,\n",
    "                     )\n",
    "    #\n",
    "    #--- parse data\n",
    "#    temp.Parse(['./msd/msd.txt']) \n",
    "#    temp.Parse( list(map(lambda x:'ni/void5th/Run%s/msd/msd.txt'%(x[1]),\n",
    "    temp.Parse( list(map(lambda x:'ni/kmc/void_2d/Run%s/msd/msd_vac_cna.txt'%(x[1]),\n",
    "#    temp.Parse( list(map(lambda x:'ni/pure/Run%s/msd/msd_vac_cna.txt'%(x[1]),\n",
    "#    temp.Parse( list(map(lambda x:'ni/mlmc/latest_void5th/Run%s/msd/msd_vac_cna.txt'%(x[1]),\n",
    "                         temp.temps_runs ))\n",
    "             )\n",
    "    #\n",
    "    #--- plot\n",
    "    xlim = (1e0,1e6)\n",
    "#     xlim = (1e-10,1e-6)\n",
    "    ylim = (1e-1,1e3)\n",
    "    print('single realizations')\n",
    "    temp.Plot(**{\n",
    "                  'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "                   'attrs':{'fmt':'-'},\n",
    "                  'xlim':xlim,\n",
    "                     'ylim':ylim,\n",
    "                   'title':'png/msd_temp_ni.png',\n",
    "                    'xstr':r'$t(\\mathrm{s})$','ystr':r'$\\mathrm{msd}(\\r{A}^2)$',\n",
    "        'bbox_to_anchor':(0.01,0.3,0.5,0.5)\n",
    "    })\n",
    "    \n",
    "    #\n",
    "    #--- plot average\n",
    "    #\n",
    "    print('ensemble average')\n",
    "    temp.EnsAverage(log_scale_x=True,log_scale_y=True,\n",
    "                   n_thresh=2,\n",
    "                    n_bins_per_decade=4,#32,\n",
    "#                     ymin=1e-3,\n",
    "                   )\n",
    "    temp.PlotAverage(**{\n",
    "                  'yscale':'log',\n",
    "                  'xscale':'log',\n",
    "#                   'count':0,\n",
    "                   'xlim':xlim,\n",
    "                     'ylim':ylim,\n",
    "                    'xstr':r'$t(\\mathrm{s})$','ystr':r'$\\mathrm{msd}(\\r{A}^2)$',\n",
    "                    'title':'png/msd_temp_ni_T%sK.png'%temp.temps[0],\n",
    "         })\n",
    "\n",
    "    #\n",
    "    #--- fit\n",
    "    #\n",
    "    temp.Fit(Plot=True,\n",
    "#              shift=True,\n",
    "#             bounds=([4e-3, 1e5,0.5], [1e-2, 1e7,2.0]),\n",
    "#            p0=[[1e-4, 1e6, 1.0]],\n",
    "            p0=[[1e-1, 1e6, 1.5]],\n",
    "               sigma=True, #--- comment for ni\n",
    "              xlo=xlim[0],\n",
    "             plotAttrs={'yscale':'log',\n",
    "                  'xscale':'log',\n",
    "                   'xlim':xlim,\n",
    "                      'ylim':ylim,\n",
    "                        'ndecade_x':1,\n",
    "                    'bbox_to_anchor':(-0.05,0.33,0.5,0.5),\n",
    "                   'title':'png/msd_temp_ni_fit_inset.png',\n",
    "                    'xstr':r'$t(\\mathrm{s})$','ystr':r'$\\mathrm{msd}(\\r{A}^2)$',\n",
    "#                         'fontsize':24,\n",
    "#              'halfopen':True\n",
    "                       }\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "    temp.PlotExponent(**{\n",
    "                    'title':'png/alpha_temp_ni.png',\n",
    "                    'ylim':(0.5,1.5),\n",
    "                    }\n",
    "                )\n",
    "    \n",
    "    return temp\n",
    "temp = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vacancy dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: png: File exists\n",
      "Parsing: 1 data.shape is: (500395, 4)\n",
      "ensemble average\n",
      "data.shape: (500395, 4)\n",
      "count= [     8      4     17     22    254    261    512    930   1685   2771\n",
      "   4997   8814  15188  25933  43629  70572 102515 133792  88491]\n"
     ]
    }
   ],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    #--- temp object\n",
    "    temp_vac = Temperature(\n",
    "#        [1000,1200,1400,1600,1800,2000],[[8,7,6,5,4,1,0],list(range(8)),list(range(8)),list(range(8)),list(range(8)),list(range(8))],\n",
    "        [1000],[[1]]*100,\n",
    "         verbose = True,\n",
    "                     )\n",
    "    #\n",
    "    #--- parse data\n",
    "#    temp_vac.Parse(['./msd/msd_vac.txt'])\n",
    "#    temp_vac.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/msd_vac.txt'%(x[0],x[1]),\n",
    "#    temp_vac.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/msd_vac.txt'%(x[0],x[1]),\n",
    "#    temp_vac.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/msd_vac.txt'%(x[0],x[1]),\n",
    "#    temp_vac.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/msd_vac_cna.txt'%(x[0],x[1]),\n",
    "    temp_vac.Parse( list(map(lambda x:'msd_definition/ni/temp0/Run%s/msd/msd_vac_cna.txt'%(x[1]),\n",
    "                          temp_vac.temps_runs ))\n",
    "              )\n",
    "    #\n",
    "    #--- plot\n",
    "#     print('single realizations')\n",
    "#     temp_vac.Plot(**{\n",
    "#                   'xscale':'log',\n",
    "#                   'yscale':'log',\n",
    "#                    'attrs':{'fmt':'-'},\n",
    "# #                   'xlim':(1e-10,1e-3),\n",
    "# #                    'ylim':(1e-5,1e-1),\n",
    "# #                   'xstr':r'$t\\mathrm{(s)}$',\n",
    "# #                   'ystr':r'msd(A$^2$)',\n",
    "# #                   'title':'png/msd_temp_ni.png',\n",
    "#         'bbox_to_anchor':(0.01,0.3,0.5,0.5)\n",
    "#     })\n",
    "    #\n",
    "    #--- plot average\n",
    "    #\n",
    "#    if len(temp_vac.nrun[0]) > 1:\n",
    "    print('ensemble average')\n",
    "    temp_vac.EnsAverage2nd(log_scale_x=True,log_scale_y=True,n_bins_per_decade=4,n_thresh=1)\n",
    "#    pdb.set_trace()\n",
    "    #\n",
    "    #--- fit\n",
    "#     n=len(temp_vac.data_averaged[1000][:,2])\n",
    "#     temp_vac.data_averaged[1000][:,2] = np.random.normal(size=n)\n",
    "#     temp_vac.Fit(Plot=True,\n",
    "#              shift=False,\n",
    "# #             bounds=(np.array([-np.inf, -np.inf,0]), np.array([np.inf, np.inf,np.inf])),\n",
    "# #            p0=[[1e0, 1e6, 1.0]],\n",
    "# #             p0=[[0.4, 1e6, 1.1]],\n",
    "# #             p0=[[-1, 1e6, 1.0]],\n",
    "#              sigma=True, #--- comment for ni\n",
    "#               xlo=1e-10,\n",
    "#              plotAttrs={'yscale':'log',\n",
    "#                   'xscale':'log',\n",
    "# #                   'xlim':(4e-13,8e-4),\n",
    "# #                    'ylim':(1e-1,1e4),\n",
    "# #                     'xstr':r'$t\\mathrm{(s)}$',\n",
    "# #                   'ystr':r'msd(A$^2$)',\n",
    "#                         'ndecade_x':1,\n",
    "#                     'bbox_to_anchor':(-0.05,0.4,0.5,0.5),\n",
    "#                    'title':'png/msd_temp_ni_fit_vac_cna.png'},\n",
    "#             )\n",
    "    \n",
    "#     temp_vac.FitLinear(Plot=True,\n",
    "#              shift=True,\n",
    "# #             bounds=([4e-3, 1e5,0.5], [1e-2, 1e7,2.0]),\n",
    "#             p0=[[1e6, 1.0]],\n",
    "# #             sigma=True, #--- comment for ni\n",
    "# #             xlo=1e-12,\n",
    "#              y0 = 0.7,\n",
    "#              plotAttrs={'yscale':'log',\n",
    "#                   'xscale':'log',\n",
    "# #                   'xlim':(4e-13,8e-4),\n",
    "# #                   'ylim':(1e-6,1e-2),\n",
    "# #                     'xstr':r'$t\\mathrm{(s)}$',\n",
    "# #                   'ystr':r'msd(A$^2$)',\n",
    "#                         'ndecade_x':2,\n",
    "#                     'bbox_to_anchor':(-0.05,0.23,0.5,0.5),\n",
    "#                    'title':'png/msd_temp_cantor_fit.png'},\n",
    "#             )\n",
    "\n",
    "\n",
    "#     temp.PlotDiff(**{\n",
    "#                   'yscale':'log',\n",
    "# #                   'xlim':(1e-12,1e-3),\n",
    "# #                   'ylim':(1e-4,1e-1),\n",
    "# #                   xstr=r'$1/T(K^{-1})$',\n",
    "# #                   ystr=r'$D(m^2/s)$',\n",
    "#                     'title':'png/D_temp_cantor.png',\n",
    "#                     }\n",
    "#                 )\n",
    "\n",
    "#     temp_vac.PlotExponent(**{\n",
    "# #                  'yscale':'log',\n",
    "# #                   'xlim':(1e-10,1e-3),\n",
    "# #                   'ylim':(.9,1.6),\n",
    "# #                   xstr=r'$1/T(K^{-1})$',\n",
    "# #                   ystr=r'$D(m^2/s)$',\n",
    "#                     'title':'png/alpha_temp_ni_vac_cna.png',\n",
    "#                     }\n",
    "#                 )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing: 0 data.shape is: (500404, 4)\n",
      "Parsing: 1 data.shape is: (500395, 4)\n",
      "Parsing: 2 data.shape is: (500400, 4)\n",
      "Parsing: 3 data.shape is: (500393, 4)\n",
      "Parsing: 4 data.shape is: (500395, 4)\n",
      "Parsing: 5 data.shape is: (500408, 4)\n",
      "Parsing: 6 data.shape is: (500388, 4)\n",
      "Parsing: 7 data.shape is: (500387, 4)\n",
      "ensemble average\n",
      "data.shape: (4003170, 4)\n",
      "count= [     32      37      59     124    1853    2031    5644    7545   13382\n",
      "   23326   43881   74796  129898  223353  382742  625406  932991 1102916\n",
      "  433154]\n",
      "16\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.22466465e-04  2.89192802e+09  9.86590352e-01]\n"
     ]
    }
   ],
   "source": [
    "temp_vac = Temperature(\n",
    "    [1000],[[0,1,2,3,4,5,6,7]]*100,\n",
    "     verbose = True,\n",
    "                 )\n",
    "    #\n",
    "    #--- parse data\n",
    "temp_vac.Parse( list(map(lambda x:'msd_definition/ni/temp0/Run%s/msd/msd_vac_cna.txt'%(x[1]),\n",
    "                          temp_vac.temps_runs ))\n",
    "              )\n",
    "    #\n",
    "    #\n",
    "    #--- plot average\n",
    "    #\n",
    "#    if len(temp_vac.nrun[0]) > 1:\n",
    "print('ensemble average')\n",
    "temp_vac.EnsAverage2nd(log_scale_x=True,log_scale_y=True,n_bins_per_decade=4,n_thresh=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Optimal parameters not found: Number of calls to function has reached maxfev = 10000.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-922234c59f1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m              \u001b[0mp0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                        \u001b[0mftol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                        \u001b[0mmaxfev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                         )\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gnnEnv/lib/python3.7/site-packages/scipy/optimize/minpack.py\u001b[0m in \u001b[0;36mcurve_fit\u001b[0;34m(f, xdata, ydata, p0, sigma, absolute_sigma, check_finite, bounds, method, jac, **kwargs)\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfodict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fvec'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mier\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Optimal parameters not found: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0merrmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;31m# Rename maxfev (leastsq) to max_nfev (least_squares), if specified.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Optimal parameters not found: Number of calls to function has reached maxfev = 10000."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR4AAAEECAYAAAD+hFsrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAARRUlEQVR4nO3dv3ITSb/G8edHbaTEKheklo9fX4HxXsHxhmTAGzhe+Q5wUY5dW+YOUAwBL5sR4lN7AQdzAyw6iHQp1k4I+Z1ALXYsj/VnNNPqmfl+qly2esajaWweT/d095i7CwBiurPuEwDQPgQPgOgIHgDRETwAoiN4AERH8ACIjuABEF0jgsfM+us+h7JRp3qgTsXUInjM7MGcr1f6h8oes8h+eeXzyqjT8mLUadZr6lSeWgSPpAcLfF3W8Yvsl1c+r4w6LS9GnWa9pk4lsZSnTNy9e9e3t7d1dXWljY0NScr9+q+//tK9e/cKv0/2mEX2yyufV0adlhejTrNet61OFxcXX9y9eOVm+KmKg5Zle3tb7969W/dpAK1kZqOqjl2XphaABiF4AERH8ACIjuABEB3BAyC6JIPHzB6Y2eDq6mrdpwI0wsuXL7W9va07d+5oe3tbL1++XOTbNsxssOggx2UkPY5nf3/fuZ0OrObly5fq9/v69u3bj7JOp6PBYKDDw8Nbv8/MLtx9v4pzSvKKB0B5Tk5OroWOJH379k0nJydrOiOCB2i8z58/L1UeA8EDNNzW1tZS5TEQPEDDnZ6eqtPpXCvrdDo6PT1d0xkRPEDjHR4eajAYqNfryczU6/XmdixXjbtaAHJxVwtAoxA8AKIjeABER/AAiC7J4GGuFpAE5moBiIu7WgAaheABEB3BAyA6ggdAdAQPgOgIHgDRETwAoiN4AERH8ACIjuABEN1PMd7EzPYkHYSXP0v61d0vY7w3gPRUfsVjZl1J++7+zN2fSXol6X+qfl+gqQo+nC8pMZpa+5KOM6/PJe2FQAKwhMnD+Uajkdxdo9FI/X6/duFTefC4+7mkR5minVB+WfV7A02T4sP5ili4j8fMziS9cvf3OdsmfThDSZuShiFwJElT3/NvSc8KnzHQYik+nK+ImcFjZjsaN5MuJfUlvb1ln6fu/ihT9trMvk6HVGhe7bn7L6ufOtA+W1tbGo1GueV1MrOp5e5Ddz9y92NJX2/Z7VjS86my3ySd5ex7RugAxaX4cL4iyujjeaxxEytrqH9un0uSzOyJQiczHctAMSk+nK+IlcbxhGZW192vBY+7X5qZzGzP3d+b2UNJv2c6lB9LGqzy3kBbHR4e1i5opq06gLA7Z/tmCKfXkmRmk/KhCB6gtSofuRyuhmzujoGZ9TXuyK5dhxnQMHfNLPu0hYG7l3LBUErwmFm3rHE5oWIDafyUiTKOCaCQL6k+ZeIyfN7MFmY6j2+7EwagxVYKntCMutTNvp7NsP3GYMNF8EA/IAmVPdCvjNvp5wrTIDJ2Qnkh7v7G3fsbGxsrnRiAlVy5e9/d35R94DKC51jS06myI12fGAoAP8ybMtHVOFR2wseZmZ1LejuZi+XuQzM7DnejhmG/50WbWQCaL8lnp4c25YPd3d1fP3z4sO7TAVrJzP6U9IekN2U3t5IMnon9/X1/9+7d/B0BlM7MLlK9nQ4ASyN4AESXZPAwjgdIQmXjeOjjAZCLPh4AjULwAIiO4AEQXZLBQ+cy2iLxh/PRuQw0zeThfNnnZHU6nWTWUKZzGWigpjycrwiCB1iTpjycrwiCB1iT29YUb8Na40kGD53LaIMaPJwv6RUIS8cKhGiDGjycr7IVCLmrBSAXd7UANArBAyA6ggdAdAQPgOiSDB5upwNJYK4WgLi4qwWgUQgeANERPACiI3gAREfwAIiO4AEQHcEDILokg4cBhKijxBduL4IBhEDKUl+4vQgGEAKJa/PC7UUQPEAJ2rxwexEED1CCNi/cXgTBA5SgBgu3J4XgAUpQg4Xbk8JdLQC5uKsFoFEIHgDRETwAoiN4AERH8ACILsngYZIokAQmiQKIi9vpABqF4AEQHcEDIDqCB0B0BA+Qo4HLmCblp3WfAJCa6WVMR6OR+v2+JDHbvCRc8QBTWMa0egQPMIVlTKtH8ABTWMa0etGCx8wOzOwi1vsBRbGMafWiBI+ZHUj6KmkvxvsBq2AZ0+pFnatlZu7utuj+zNUC1oe5WgAaZeFxPGZ2JumVu7/P2bYn6UDSUNKmpKG7n5d2lgAaZWbwmNmOpGNJl5L6kt7ess9Td3+UKXttZl/zQgoAZja13H3o7kfufqxx53CeY0nPp8p+k3RWwvkBaKAy+ngea9zEyhpq3PQCgBtWCp7QzOq6+7XgcffLsJ3b5wBuWPWKpztn+6b0Y/DgWfj6LIzrAdBSUWanhztc5xr3B81kZn2NO7IZog6s110zyw6kG7j7oIwDlxI8ZtadNK9WFSo2kMYDCMs4JoBCvqQ6gPAyfN7MFppZN3x5250wIBoW9UrPSlc87j40s0vd7OvZDNsZx4O1YlGvNJVxO/1c0s5U2U4oL4QH+qEsLOq1ksoe6FdG8BxLejpVdqQFOpJv4+5v3L2/sbGx0okBLOq1kit377v7m7IPPG/KRFfjUNkJH2dmdi7p7WQuVmhuHYe7UcOw33OaWUjB1taWRqNRbjnWZ2bwhDtVc69cyp4QGi7tHuzu7pZ5WLTQ6enptT4eiUW9lrBhZgNJb8q+6klyWQyaWigLi3qtpLKmVtSFwJbFQmDA+rAQGIBGSTJ4uJ0OJKGy2+k0tQDkoqkFoFEIHgDRETwAoksyeOhcBpJA5zKAuOhcBtAoBA+A6Age1AqrCTZDlMXegTKwmmBzJNm5nFkW49cPHz6s+3SQiO3t7dy1dXq9nj59+hT/hBrOzP6U9IcqWBYjyeCZ4K4Wsu7cuaO831cz0/fv39dwRs3GXS1At68ayGqC9UPwoDZOT0/V6XSulbGaYD0RPKgNVhNsDvp4AOSijwdAoyQZPEwSBZLAJFEAcdHUAtAoBA+A6AgeANERPFgbZpq3F7PTsRbMNG83rniwFicnJz9CZ+Lbt286OTlZ0xkhJoIHa/H58+elytEsSQYPAwibj5nmtVDZAMIkg8fd37h7f2NjY92ngoow07wWrty9X/YiYFKiwYPmY6Z5uzFlAkAupkwAaBSCB0B0BA+A6AgeANERPACiI3hQGiZ9YlFMEkUpmPSJZXDFg1Iw6RPLSDJ4mKtVP0z6bCTmaiFtTPpsJOZqIW1M+sQyCB6UgkmfWAaTRAHkYpIogEYheABER/AAiI7gwTVMe0AMTJnAD0x7QCxc8eAHpj0gFoIHPzDtAbFECR4z2zGzJ2Z2ED53Y7wvlsO0B8QS64rnubs/c/dzSb9LOov0vlgC0x4QS+XBY2Y7kjYnr919KOlx1e+L5THtAbHEuKu1J+nrdKGZ7YQQQkIODw8JGlRu4eAxszNJr9z9fc62PUkHkoYaX90MQ7NK4fXl1Ld8ldQtcL4AGmBm8IRm0rHGwdGX9PaWfZ66+6NM2Wsz+5oXUgAws4/H3YfufuTux8ppLgXHkp5Plf2mfzqQ865u8q6CUBJGHyN1ZXQuP9a4iZU11LjpJUnvlelcnqB/pxqT0cej0Uju/mP0MeGDlKwUPKGZ1Z0OEXe/DNv3preF7/nPKu+L2zH6GHWw6l2t7pztkyudR2b2ROMroZ/d/WjF98UtGH2MOogySTRc9TwLL3+fta+Z9TXuyGbEbAFbW1sajUa55cCS7ppZdgnQgbsPyjhwKQMIy5wC4e4Dd9939/179+6VddjWYPQxSvRl8n8xfJQSOtLqwXMZPl/rPM4E0W13wlARRh+jDhZe7N3MPko6ygwMnJT/Lem/s2N2QgfyR3e3Qic1foDYg93d3V8/fPhQ5BAAVmRmf0r6Q9Kbsp+tVUZT61zSzlTZTigvpO0P9GMcDhJR2QP9yuhcPpb0Wtc7jY9COZbEKoBog5lNrdBX81TjK5iHGg8GPJf0NtvkMrODsM9w8nm6SVZEG5+rtb29nXtXqtfr6dOnT/FPCK1V5XO1knygX5v7eO7cuaO8n4mZ6fv372s4I7RV6n08pWtzHw+rACIhlfXxJBk8bcY4HLQBwZMYxuGgDejjAZCryj6eJINnoo13tYBUVHlXi6YWgOgIHgDRETwAoksyeMzsgZkNrq6u1n0qC1t2fhXzsVADG2Y2CDd7yuXuyX7cv3/f6+DFixfe6XRc0o+PTqfjL168KGV/YB0kvfOK/m9zV6sEy86vYj4W6oC7WpEt2wxadp1j1kVG29U6eKroJynyeJhl51cxHwutV1UbbpUPSQ8kDXZ3d29tf1bVT9Lr9a4dc/LR6/VKOxf6eFAHkj5IGkh64GX/Hy/7gGV+zOpcLhIQizCz3OOa2czve/Hihfd6PTcz7/V6c0Nk2f2B2ETn8k1VrVtDxy8wRudyjqr6SViWAqhebYOnqoBgWQqgerVtaknjO1AnJyf6/Pmztra2dHp6SkAAJWndmssTdRlACDRR6/p46jhXC2igyuZqccUDIFfrrngANBvBAyA6ggdAdEn38ZjZX5JGkjYkTXqa876+K+nLCm+VPWaR/fLK55VRp+XFqNOs122rU8/d7y1wbsurai5GmR+SBrO+1opzSrLHLLJfXvm8MuqUZp1mvaZO5X3Upan1ZoGvyzp+kf3yyueVUaflxajTrNfUqSRJN7UWZWbvvKLbfutCneqBOhVTlyueeQbzdjCzAzO7WHbbGhWuk5ntmNmTsP2JmXUrOcPlza3TRKYOfTM7q/KkVrRsnfpm9jCxn8u0Zer0ukg9GnHFM4+ZHUj6KunC3W3RbSmbU6e37v5L+HpH0rG7H63hNAszs4/u/q/w9Z6kf7v78ZpPayVm9sTdn2VenzWgTnkBcpytZ56mXPHM5O7n7v5+2W0pu+28Q9BsZvYbSnoc89xWZWYPJQ0nr0M9++s7o9L8MvW6u46TKEv4XXvk7jb5kHQ0L3SklgRPy+xpfCV0TfglqYvNnLJuwk2ThZnZWzPrhivW1+s+nxV9dfffJy/CH4z/LPKNP1V2SgsIbfdXt/zl3pN0oPFfvk1JQ3c/j3yKS0ugTpuSLqfKvqqkv66R6ncu6UcTJBxXknYklX51Gutn5u6/hD65/5P02yJXBkXFqJO7X2aO2ZW0mS2b981RPzT+5Xku6UzS35IObtnn9VTZa0l7K763F9lWpzpp3CSZfp+Pq7zPOuon6UmoS1fj/yR/S9qp8+9hqMdBqJdLelJWfRL4PTyT1F10/7V2LpvZR43bhOdT5c81/sc5z5TtSTrzfzpN+5L+NePwb3OO635LB/KsbctYd53C5e7R5Jih7G9J933c37OSmPULf0V33P19WT+fPDHqFJq6Dz1c5YTXF5L+yxe9SljCGn4PL9z9/sInWGbiFkjJj8pP5Rt/3TT+y+crvt+t37/qsVOpk8Z/0S6m37uuP7NwnL3wy17b30ONr3L2psrOpo9fpzplvv9g2Z9Pcp3L4S9B16f+Onv4q5Bp79dGzDpNv0d474U6/Iqqon7hKm3iSJk+nxgqqNO5xv9Br5k+fpUq/D3c081+xZnW2rl8i+6c7Xl3PGYKdxAml5FnylwqztpWou6c7aXWSdIjM3uicefhz179GJ7unO1L10/ScWg2bmrcNIg95KE7Z/tSdXL3oZkNMz+XTY37Y2Lqztle5OckjUPnf5f5hhSDp3ThP+S1OyWLbEvZnDoNJU3umPw+vb0O3H3h0bN14Zlbz01S5GeVXFNrogljNqY1sU5ZTawfdapGisFzGT5fu+zL/GPdGBxXA5fhc5PqlHUZPjepfpfhM3WqQHLBE5oJl7rZHt0M2+s4vaFxdcpqYv2oU7WSC57gXOPbwlk7obyumlinrCbWjzpVJNXgOZb0dKos+i3VkjWxTllNrB91qkj0kcuhPflU45R9qPHcm3PdHLV6EPYZTj5XcJu7FE2sU1YT60ed1lunVqzHAyAtqTa1ADQYwQMgOoIHQHQED4DoCB4A0RE8AKIjeABER/AAiI7gARAdwQMguv8H4xH/qlc0T5oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xdata = temp_vac.data_averaged[1000][:,0]\n",
    "ydata = temp_vac.data_averaged[1000][:,1]\n",
    "filtr = xdata < 1e-7\n",
    "xdata = xdata[filtr]\n",
    "ydata = ydata[filtr]\n",
    "print(len(xdata))\n",
    "ax = utl.PltErr(None,None,Plot=False)\n",
    "utl.PltErr(xdata,ydata,\n",
    "           attrs={'fmt':'o','color':'black'},\n",
    "          xscale='log',yscale='log',\n",
    "           ax=ax,\n",
    "           Plot=False\n",
    "          )\n",
    "\n",
    "popt, pcov = curve_fit(temp_vac.func2nd, xdata, ydata,\n",
    "             p0=[[0.4, 1e5, 1.1]],\n",
    "                       ftol=1e-10, xtol=1e-10, gtol=1e-10,\n",
    "                       maxfev=10000,\n",
    "                        )\n",
    "\n",
    "utl.PltErr(xdata,temp_vac.func2nd(xdata,*popt),\n",
    "           attrs={'fmt':'-.','color':'red'},\n",
    "          xscale='log',yscale='log',\n",
    "           ax=ax\n",
    "          )\n",
    "\n",
    "print(popt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function least_squares in module scipy.optimize._lsq.least_squares:\n",
      "\n",
      "least_squares(fun, x0, jac='2-point', bounds=(-inf, inf), method='trf', ftol=1e-08, xtol=1e-08, gtol=1e-08, x_scale=1.0, loss='linear', f_scale=1.0, diff_step=None, tr_solver=None, tr_options={}, jac_sparsity=None, max_nfev=None, verbose=0, args=(), kwargs={})\n",
      "    Solve a nonlinear least-squares problem with bounds on the variables.\n",
      "    \n",
      "    Given the residuals f(x) (an m-D real function of n real\n",
      "    variables) and the loss function rho(s) (a scalar function), `least_squares`\n",
      "    finds a local minimum of the cost function F(x)::\n",
      "    \n",
      "        minimize F(x) = 0.5 * sum(rho(f_i(x)**2), i = 0, ..., m - 1)\n",
      "        subject to lb <= x <= ub\n",
      "    \n",
      "    The purpose of the loss function rho(s) is to reduce the influence of\n",
      "    outliers on the solution.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    fun : callable\n",
      "        Function which computes the vector of residuals, with the signature\n",
      "        ``fun(x, *args, **kwargs)``, i.e., the minimization proceeds with\n",
      "        respect to its first argument. The argument ``x`` passed to this\n",
      "        function is an ndarray of shape (n,) (never a scalar, even for n=1).\n",
      "        It must allocate and return a 1-D array_like of shape (m,) or a scalar.\n",
      "        If the argument ``x`` is complex or the function ``fun`` returns\n",
      "        complex residuals, it must be wrapped in a real function of real\n",
      "        arguments, as shown at the end of the Examples section.\n",
      "    x0 : array_like with shape (n,) or float\n",
      "        Initial guess on independent variables. If float, it will be treated\n",
      "        as a 1-D array with one element.\n",
      "    jac : {'2-point', '3-point', 'cs', callable}, optional\n",
      "        Method of computing the Jacobian matrix (an m-by-n matrix, where\n",
      "        element (i, j) is the partial derivative of f[i] with respect to\n",
      "        x[j]). The keywords select a finite difference scheme for numerical\n",
      "        estimation. The scheme '3-point' is more accurate, but requires\n",
      "        twice as many operations as '2-point' (default). The scheme 'cs'\n",
      "        uses complex steps, and while potentially the most accurate, it is\n",
      "        applicable only when `fun` correctly handles complex inputs and\n",
      "        can be analytically continued to the complex plane. Method 'lm'\n",
      "        always uses the '2-point' scheme. If callable, it is used as\n",
      "        ``jac(x, *args, **kwargs)`` and should return a good approximation\n",
      "        (or the exact value) for the Jacobian as an array_like (np.atleast_2d\n",
      "        is applied), a sparse matrix (csr_matrix preferred for performance) or\n",
      "        a `scipy.sparse.linalg.LinearOperator`.\n",
      "    bounds : 2-tuple of array_like, optional\n",
      "        Lower and upper bounds on independent variables. Defaults to no bounds.\n",
      "        Each array must match the size of `x0` or be a scalar, in the latter\n",
      "        case a bound will be the same for all variables. Use ``np.inf`` with\n",
      "        an appropriate sign to disable bounds on all or some variables.\n",
      "    method : {'trf', 'dogbox', 'lm'}, optional\n",
      "        Algorithm to perform minimization.\n",
      "    \n",
      "            * 'trf' : Trust Region Reflective algorithm, particularly suitable\n",
      "              for large sparse problems with bounds. Generally robust method.\n",
      "            * 'dogbox' : dogleg algorithm with rectangular trust regions,\n",
      "              typical use case is small problems with bounds. Not recommended\n",
      "              for problems with rank-deficient Jacobian.\n",
      "            * 'lm' : Levenberg-Marquardt algorithm as implemented in MINPACK.\n",
      "              Doesn't handle bounds and sparse Jacobians. Usually the most\n",
      "              efficient method for small unconstrained problems.\n",
      "    \n",
      "        Default is 'trf'. See Notes for more information.\n",
      "    ftol : float or None, optional\n",
      "        Tolerance for termination by the change of the cost function. Default\n",
      "        is 1e-8. The optimization process is stopped when ``dF < ftol * F``,\n",
      "        and there was an adequate agreement between a local quadratic model and\n",
      "        the true model in the last step.\n",
      "    \n",
      "        If None and 'method' is not 'lm', the termination by this condition is\n",
      "        disabled. If 'method' is 'lm', this tolerance must be higher than\n",
      "        machine epsilon.\n",
      "    xtol : float or None, optional\n",
      "        Tolerance for termination by the change of the independent variables.\n",
      "        Default is 1e-8. The exact condition depends on the `method` used:\n",
      "    \n",
      "            * For 'trf' and 'dogbox' : ``norm(dx) < xtol * (xtol + norm(x))``.\n",
      "            * For 'lm' : ``Delta < xtol * norm(xs)``, where ``Delta`` is\n",
      "              a trust-region radius and ``xs`` is the value of ``x``\n",
      "              scaled according to `x_scale` parameter (see below).\n",
      "    \n",
      "        If None and 'method' is not 'lm', the termination by this condition is\n",
      "        disabled. If 'method' is 'lm', this tolerance must be higher than\n",
      "        machine epsilon.\n",
      "    gtol : float or None, optional\n",
      "        Tolerance for termination by the norm of the gradient. Default is 1e-8.\n",
      "        The exact condition depends on a `method` used:\n",
      "    \n",
      "            * For 'trf' : ``norm(g_scaled, ord=np.inf) < gtol``, where\n",
      "              ``g_scaled`` is the value of the gradient scaled to account for\n",
      "              the presence of the bounds [STIR]_.\n",
      "            * For 'dogbox' : ``norm(g_free, ord=np.inf) < gtol``, where\n",
      "              ``g_free`` is the gradient with respect to the variables which\n",
      "              are not in the optimal state on the boundary.\n",
      "            * For 'lm' : the maximum absolute value of the cosine of angles\n",
      "              between columns of the Jacobian and the residual vector is less\n",
      "              than `gtol`, or the residual vector is zero.\n",
      "    \n",
      "        If None and 'method' is not 'lm', the termination by this condition is\n",
      "        disabled. If 'method' is 'lm', this tolerance must be higher than\n",
      "        machine epsilon.\n",
      "    x_scale : array_like or 'jac', optional\n",
      "        Characteristic scale of each variable. Setting `x_scale` is equivalent\n",
      "        to reformulating the problem in scaled variables ``xs = x / x_scale``.\n",
      "        An alternative view is that the size of a trust region along jth\n",
      "        dimension is proportional to ``x_scale[j]``. Improved convergence may\n",
      "        be achieved by setting `x_scale` such that a step of a given size\n",
      "        along any of the scaled variables has a similar effect on the cost\n",
      "        function. If set to 'jac', the scale is iteratively updated using the\n",
      "        inverse norms of the columns of the Jacobian matrix (as described in\n",
      "        [JJMore]_).\n",
      "    loss : str or callable, optional\n",
      "        Determines the loss function. The following keyword values are allowed:\n",
      "    \n",
      "            * 'linear' (default) : ``rho(z) = z``. Gives a standard\n",
      "              least-squares problem.\n",
      "            * 'soft_l1' : ``rho(z) = 2 * ((1 + z)**0.5 - 1)``. The smooth\n",
      "              approximation of l1 (absolute value) loss. Usually a good\n",
      "              choice for robust least squares.\n",
      "            * 'huber' : ``rho(z) = z if z <= 1 else 2*z**0.5 - 1``. Works\n",
      "              similarly to 'soft_l1'.\n",
      "            * 'cauchy' : ``rho(z) = ln(1 + z)``. Severely weakens outliers\n",
      "              influence, but may cause difficulties in optimization process.\n",
      "            * 'arctan' : ``rho(z) = arctan(z)``. Limits a maximum loss on\n",
      "              a single residual, has properties similar to 'cauchy'.\n",
      "    \n",
      "        If callable, it must take a 1-D ndarray ``z=f**2`` and return an\n",
      "        array_like with shape (3, m) where row 0 contains function values,\n",
      "        row 1 contains first derivatives and row 2 contains second\n",
      "        derivatives. Method 'lm' supports only 'linear' loss.\n",
      "    f_scale : float, optional\n",
      "        Value of soft margin between inlier and outlier residuals, default\n",
      "        is 1.0. The loss function is evaluated as follows\n",
      "        ``rho_(f**2) = C**2 * rho(f**2 / C**2)``, where ``C`` is `f_scale`,\n",
      "        and ``rho`` is determined by `loss` parameter. This parameter has\n",
      "        no effect with ``loss='linear'``, but for other `loss` values it is\n",
      "        of crucial importance.\n",
      "    max_nfev : None or int, optional\n",
      "        Maximum number of function evaluations before the termination.\n",
      "        If None (default), the value is chosen automatically:\n",
      "    \n",
      "            * For 'trf' and 'dogbox' : 100 * n.\n",
      "            * For 'lm' :  100 * n if `jac` is callable and 100 * n * (n + 1)\n",
      "              otherwise (because 'lm' counts function calls in Jacobian\n",
      "              estimation).\n",
      "    \n",
      "    diff_step : None or array_like, optional\n",
      "        Determines the relative step size for the finite difference\n",
      "        approximation of the Jacobian. The actual step is computed as\n",
      "        ``x * diff_step``. If None (default), then `diff_step` is taken to be\n",
      "        a conventional \"optimal\" power of machine epsilon for the finite\n",
      "        difference scheme used [NR]_.\n",
      "    tr_solver : {None, 'exact', 'lsmr'}, optional\n",
      "        Method for solving trust-region subproblems, relevant only for 'trf'\n",
      "        and 'dogbox' methods.\n",
      "    \n",
      "            * 'exact' is suitable for not very large problems with dense\n",
      "              Jacobian matrices. The computational complexity per iteration is\n",
      "              comparable to a singular value decomposition of the Jacobian\n",
      "              matrix.\n",
      "            * 'lsmr' is suitable for problems with sparse and large Jacobian\n",
      "              matrices. It uses the iterative procedure\n",
      "              `scipy.sparse.linalg.lsmr` for finding a solution of a linear\n",
      "              least-squares problem and only requires matrix-vector product\n",
      "              evaluations.\n",
      "    \n",
      "        If None (default), the solver is chosen based on the type of Jacobian\n",
      "        returned on the first iteration.\n",
      "    tr_options : dict, optional\n",
      "        Keyword options passed to trust-region solver.\n",
      "    \n",
      "            * ``tr_solver='exact'``: `tr_options` are ignored.\n",
      "            * ``tr_solver='lsmr'``: options for `scipy.sparse.linalg.lsmr`.\n",
      "              Additionally,  ``method='trf'`` supports  'regularize' option\n",
      "              (bool, default is True), which adds a regularization term to the\n",
      "              normal equation, which improves convergence if the Jacobian is\n",
      "              rank-deficient [Byrd]_ (eq. 3.4).\n",
      "    \n",
      "    jac_sparsity : {None, array_like, sparse matrix}, optional\n",
      "        Defines the sparsity structure of the Jacobian matrix for finite\n",
      "        difference estimation, its shape must be (m, n). If the Jacobian has\n",
      "        only few non-zero elements in *each* row, providing the sparsity\n",
      "        structure will greatly speed up the computations [Curtis]_. A zero\n",
      "        entry means that a corresponding element in the Jacobian is identically\n",
      "        zero. If provided, forces the use of 'lsmr' trust-region solver.\n",
      "        If None (default), then dense differencing will be used. Has no effect\n",
      "        for 'lm' method.\n",
      "    verbose : {0, 1, 2}, optional\n",
      "        Level of algorithm's verbosity:\n",
      "    \n",
      "            * 0 (default) : work silently.\n",
      "            * 1 : display a termination report.\n",
      "            * 2 : display progress during iterations (not supported by 'lm'\n",
      "              method).\n",
      "    \n",
      "    args, kwargs : tuple and dict, optional\n",
      "        Additional arguments passed to `fun` and `jac`. Both empty by default.\n",
      "        The calling signature is ``fun(x, *args, **kwargs)`` and the same for\n",
      "        `jac`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    result : OptimizeResult\n",
      "        `OptimizeResult` with the following fields defined:\n",
      "    \n",
      "            x : ndarray, shape (n,)\n",
      "                Solution found.\n",
      "            cost : float\n",
      "                Value of the cost function at the solution.\n",
      "            fun : ndarray, shape (m,)\n",
      "                Vector of residuals at the solution.\n",
      "            jac : ndarray, sparse matrix or LinearOperator, shape (m, n)\n",
      "                Modified Jacobian matrix at the solution, in the sense that J^T J\n",
      "                is a Gauss-Newton approximation of the Hessian of the cost function.\n",
      "                The type is the same as the one used by the algorithm.\n",
      "            grad : ndarray, shape (m,)\n",
      "                Gradient of the cost function at the solution.\n",
      "            optimality : float\n",
      "                First-order optimality measure. In unconstrained problems, it is\n",
      "                always the uniform norm of the gradient. In constrained problems,\n",
      "                it is the quantity which was compared with `gtol` during iterations.\n",
      "            active_mask : ndarray of int, shape (n,)\n",
      "                Each component shows whether a corresponding constraint is active\n",
      "                (that is, whether a variable is at the bound):\n",
      "    \n",
      "                    *  0 : a constraint is not active.\n",
      "                    * -1 : a lower bound is active.\n",
      "                    *  1 : an upper bound is active.\n",
      "    \n",
      "                Might be somewhat arbitrary for 'trf' method as it generates a\n",
      "                sequence of strictly feasible iterates and `active_mask` is\n",
      "                determined within a tolerance threshold.\n",
      "            nfev : int\n",
      "                Number of function evaluations done. Methods 'trf' and 'dogbox' do\n",
      "                not count function calls for numerical Jacobian approximation, as\n",
      "                opposed to 'lm' method.\n",
      "            njev : int or None\n",
      "                Number of Jacobian evaluations done. If numerical Jacobian\n",
      "                approximation is used in 'lm' method, it is set to None.\n",
      "            status : int\n",
      "                The reason for algorithm termination:\n",
      "    \n",
      "                    * -1 : improper input parameters status returned from MINPACK.\n",
      "                    *  0 : the maximum number of function evaluations is exceeded.\n",
      "                    *  1 : `gtol` termination condition is satisfied.\n",
      "                    *  2 : `ftol` termination condition is satisfied.\n",
      "                    *  3 : `xtol` termination condition is satisfied.\n",
      "                    *  4 : Both `ftol` and `xtol` termination conditions are satisfied.\n",
      "    \n",
      "            message : str\n",
      "                Verbal description of the termination reason.\n",
      "            success : bool\n",
      "                True if one of the convergence criteria is satisfied (`status` > 0).\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    leastsq : A legacy wrapper for the MINPACK implementation of the\n",
      "              Levenberg-Marquadt algorithm.\n",
      "    curve_fit : Least-squares minimization applied to a curve-fitting problem.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Method 'lm' (Levenberg-Marquardt) calls a wrapper over least-squares\n",
      "    algorithms implemented in MINPACK (lmder, lmdif). It runs the\n",
      "    Levenberg-Marquardt algorithm formulated as a trust-region type algorithm.\n",
      "    The implementation is based on paper [JJMore]_, it is very robust and\n",
      "    efficient with a lot of smart tricks. It should be your first choice\n",
      "    for unconstrained problems. Note that it doesn't support bounds. Also,\n",
      "    it doesn't work when m < n.\n",
      "    \n",
      "    Method 'trf' (Trust Region Reflective) is motivated by the process of\n",
      "    solving a system of equations, which constitute the first-order optimality\n",
      "    condition for a bound-constrained minimization problem as formulated in\n",
      "    [STIR]_. The algorithm iteratively solves trust-region subproblems\n",
      "    augmented by a special diagonal quadratic term and with trust-region shape\n",
      "    determined by the distance from the bounds and the direction of the\n",
      "    gradient. This enhancements help to avoid making steps directly into bounds\n",
      "    and efficiently explore the whole space of variables. To further improve\n",
      "    convergence, the algorithm considers search directions reflected from the\n",
      "    bounds. To obey theoretical requirements, the algorithm keeps iterates\n",
      "    strictly feasible. With dense Jacobians trust-region subproblems are\n",
      "    solved by an exact method very similar to the one described in [JJMore]_\n",
      "    (and implemented in MINPACK). The difference from the MINPACK\n",
      "    implementation is that a singular value decomposition of a Jacobian\n",
      "    matrix is done once per iteration, instead of a QR decomposition and series\n",
      "    of Givens rotation eliminations. For large sparse Jacobians a 2-D subspace\n",
      "    approach of solving trust-region subproblems is used [STIR]_, [Byrd]_.\n",
      "    The subspace is spanned by a scaled gradient and an approximate\n",
      "    Gauss-Newton solution delivered by `scipy.sparse.linalg.lsmr`. When no\n",
      "    constraints are imposed the algorithm is very similar to MINPACK and has\n",
      "    generally comparable performance. The algorithm works quite robust in\n",
      "    unbounded and bounded problems, thus it is chosen as a default algorithm.\n",
      "    \n",
      "    Method 'dogbox' operates in a trust-region framework, but considers\n",
      "    rectangular trust regions as opposed to conventional ellipsoids [Voglis]_.\n",
      "    The intersection of a current trust region and initial bounds is again\n",
      "    rectangular, so on each iteration a quadratic minimization problem subject\n",
      "    to bound constraints is solved approximately by Powell's dogleg method\n",
      "    [NumOpt]_. The required Gauss-Newton step can be computed exactly for\n",
      "    dense Jacobians or approximately by `scipy.sparse.linalg.lsmr` for large\n",
      "    sparse Jacobians. The algorithm is likely to exhibit slow convergence when\n",
      "    the rank of Jacobian is less than the number of variables. The algorithm\n",
      "    often outperforms 'trf' in bounded problems with a small number of\n",
      "    variables.\n",
      "    \n",
      "    Robust loss functions are implemented as described in [BA]_. The idea\n",
      "    is to modify a residual vector and a Jacobian matrix on each iteration\n",
      "    such that computed gradient and Gauss-Newton Hessian approximation match\n",
      "    the true gradient and Hessian approximation of the cost function. Then\n",
      "    the algorithm proceeds in a normal way, i.e., robust loss functions are\n",
      "    implemented as a simple wrapper over standard least-squares algorithms.\n",
      "    \n",
      "    .. versionadded:: 0.17.0\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [STIR] M. A. Branch, T. F. Coleman, and Y. Li, \"A Subspace, Interior,\n",
      "              and Conjugate Gradient Method for Large-Scale Bound-Constrained\n",
      "              Minimization Problems,\" SIAM Journal on Scientific Computing,\n",
      "              Vol. 21, Number 1, pp 1-23, 1999.\n",
      "    .. [NR] William H. Press et. al., \"Numerical Recipes. The Art of Scientific\n",
      "            Computing. 3rd edition\", Sec. 5.7.\n",
      "    .. [Byrd] R. H. Byrd, R. B. Schnabel and G. A. Shultz, \"Approximate\n",
      "              solution of the trust region problem by minimization over\n",
      "              two-dimensional subspaces\", Math. Programming, 40, pp. 247-263,\n",
      "              1988.\n",
      "    .. [Curtis] A. Curtis, M. J. D. Powell, and J. Reid, \"On the estimation of\n",
      "                sparse Jacobian matrices\", Journal of the Institute of\n",
      "                Mathematics and its Applications, 13, pp. 117-120, 1974.\n",
      "    .. [JJMore] J. J. More, \"The Levenberg-Marquardt Algorithm: Implementation\n",
      "                and Theory,\" Numerical Analysis, ed. G. A. Watson, Lecture\n",
      "                Notes in Mathematics 630, Springer Verlag, pp. 105-116, 1977.\n",
      "    .. [Voglis] C. Voglis and I. E. Lagaris, \"A Rectangular Trust Region\n",
      "                Dogleg Approach for Unconstrained and Bound Constrained\n",
      "                Nonlinear Optimization\", WSEAS International Conference on\n",
      "                Applied Mathematics, Corfu, Greece, 2004.\n",
      "    .. [NumOpt] J. Nocedal and S. J. Wright, \"Numerical optimization,\n",
      "                2nd edition\", Chapter 4.\n",
      "    .. [BA] B. Triggs et. al., \"Bundle Adjustment - A Modern Synthesis\",\n",
      "            Proceedings of the International Workshop on Vision Algorithms:\n",
      "            Theory and Practice, pp. 298-372, 1999.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    In this example we find a minimum of the Rosenbrock function without bounds\n",
      "    on independent variables.\n",
      "    \n",
      "    >>> def fun_rosenbrock(x):\n",
      "    ...     return np.array([10 * (x[1] - x[0]**2), (1 - x[0])])\n",
      "    \n",
      "    Notice that we only provide the vector of the residuals. The algorithm\n",
      "    constructs the cost function as a sum of squares of the residuals, which\n",
      "    gives the Rosenbrock function. The exact minimum is at ``x = [1.0, 1.0]``.\n",
      "    \n",
      "    >>> from scipy.optimize import least_squares\n",
      "    >>> x0_rosenbrock = np.array([2, 2])\n",
      "    >>> res_1 = least_squares(fun_rosenbrock, x0_rosenbrock)\n",
      "    >>> res_1.x\n",
      "    array([ 1.,  1.])\n",
      "    >>> res_1.cost\n",
      "    9.8669242910846867e-30\n",
      "    >>> res_1.optimality\n",
      "    8.8928864934219529e-14\n",
      "    \n",
      "    We now constrain the variables, in such a way that the previous solution\n",
      "    becomes infeasible. Specifically, we require that ``x[1] >= 1.5``, and\n",
      "    ``x[0]`` left unconstrained. To this end, we specify the `bounds` parameter\n",
      "    to `least_squares` in the form ``bounds=([-np.inf, 1.5], np.inf)``.\n",
      "    \n",
      "    We also provide the analytic Jacobian:\n",
      "    \n",
      "    >>> def jac_rosenbrock(x):\n",
      "    ...     return np.array([\n",
      "    ...         [-20 * x[0], 10],\n",
      "    ...         [-1, 0]])\n",
      "    \n",
      "    Putting this all together, we see that the new solution lies on the bound:\n",
      "    \n",
      "    >>> res_2 = least_squares(fun_rosenbrock, x0_rosenbrock, jac_rosenbrock,\n",
      "    ...                       bounds=([-np.inf, 1.5], np.inf))\n",
      "    >>> res_2.x\n",
      "    array([ 1.22437075,  1.5       ])\n",
      "    >>> res_2.cost\n",
      "    0.025213093946805685\n",
      "    >>> res_2.optimality\n",
      "    1.5885401433157753e-07\n",
      "    \n",
      "    Now we solve a system of equations (i.e., the cost function should be zero\n",
      "    at a minimum) for a Broyden tridiagonal vector-valued function of 100000\n",
      "    variables:\n",
      "    \n",
      "    >>> def fun_broyden(x):\n",
      "    ...     f = (3 - x) * x + 1\n",
      "    ...     f[1:] -= x[:-1]\n",
      "    ...     f[:-1] -= 2 * x[1:]\n",
      "    ...     return f\n",
      "    \n",
      "    The corresponding Jacobian matrix is sparse. We tell the algorithm to\n",
      "    estimate it by finite differences and provide the sparsity structure of\n",
      "    Jacobian to significantly speed up this process.\n",
      "    \n",
      "    >>> from scipy.sparse import lil_matrix\n",
      "    >>> def sparsity_broyden(n):\n",
      "    ...     sparsity = lil_matrix((n, n), dtype=int)\n",
      "    ...     i = np.arange(n)\n",
      "    ...     sparsity[i, i] = 1\n",
      "    ...     i = np.arange(1, n)\n",
      "    ...     sparsity[i, i - 1] = 1\n",
      "    ...     i = np.arange(n - 1)\n",
      "    ...     sparsity[i, i + 1] = 1\n",
      "    ...     return sparsity\n",
      "    ...\n",
      "    >>> n = 100000\n",
      "    >>> x0_broyden = -np.ones(n)\n",
      "    ...\n",
      "    >>> res_3 = least_squares(fun_broyden, x0_broyden,\n",
      "    ...                       jac_sparsity=sparsity_broyden(n))\n",
      "    >>> res_3.cost\n",
      "    4.5687069299604613e-23\n",
      "    >>> res_3.optimality\n",
      "    1.1650454296851518e-11\n",
      "    \n",
      "    Let's also solve a curve fitting problem using robust loss function to\n",
      "    take care of outliers in the data. Define the model function as\n",
      "    ``y = a + b * exp(c * t)``, where t is a predictor variable, y is an\n",
      "    observation and a, b, c are parameters to estimate.\n",
      "    \n",
      "    First, define the function which generates the data with noise and\n",
      "    outliers, define the model parameters, and generate data:\n",
      "    \n",
      "    >>> from numpy.random import default_rng\n",
      "    >>> rng = default_rng()\n",
      "    >>> def gen_data(t, a, b, c, noise=0., n_outliers=0, seed=None):\n",
      "    ...     rng = default_rng(seed)\n",
      "    ...\n",
      "    ...     y = a + b * np.exp(t * c)\n",
      "    ...\n",
      "    ...     error = noise * rng.standard_normal(t.size)\n",
      "    ...     outliers = rng.integers(0, t.size, n_outliers)\n",
      "    ...     error[outliers] *= 10\n",
      "    ...\n",
      "    ...     return y + error\n",
      "    ...\n",
      "    >>> a = 0.5\n",
      "    >>> b = 2.0\n",
      "    >>> c = -1\n",
      "    >>> t_min = 0\n",
      "    >>> t_max = 10\n",
      "    >>> n_points = 15\n",
      "    ...\n",
      "    >>> t_train = np.linspace(t_min, t_max, n_points)\n",
      "    >>> y_train = gen_data(t_train, a, b, c, noise=0.1, n_outliers=3)\n",
      "    \n",
      "    Define function for computing residuals and initial estimate of\n",
      "    parameters.\n",
      "    \n",
      "    >>> def fun(x, t, y):\n",
      "    ...     return x[0] + x[1] * np.exp(x[2] * t) - y\n",
      "    ...\n",
      "    >>> x0 = np.array([1.0, 1.0, 0.0])\n",
      "    \n",
      "    Compute a standard least-squares solution:\n",
      "    \n",
      "    >>> res_lsq = least_squares(fun, x0, args=(t_train, y_train))\n",
      "    \n",
      "    Now compute two solutions with two different robust loss functions. The\n",
      "    parameter `f_scale` is set to 0.1, meaning that inlier residuals should\n",
      "    not significantly exceed 0.1 (the noise level used).\n",
      "    \n",
      "    >>> res_soft_l1 = least_squares(fun, x0, loss='soft_l1', f_scale=0.1,\n",
      "    ...                             args=(t_train, y_train))\n",
      "    >>> res_log = least_squares(fun, x0, loss='cauchy', f_scale=0.1,\n",
      "    ...                         args=(t_train, y_train))\n",
      "    \n",
      "    And, finally, plot all the curves. We see that by selecting an appropriate\n",
      "    `loss`  we can get estimates close to optimal even in the presence of\n",
      "    strong outliers. But keep in mind that generally it is recommended to try\n",
      "    'soft_l1' or 'huber' losses first (if at all necessary) as the other two\n",
      "    options may cause difficulties in optimization process.\n",
      "    \n",
      "    >>> t_test = np.linspace(t_min, t_max, n_points * 10)\n",
      "    >>> y_true = gen_data(t_test, a, b, c)\n",
      "    >>> y_lsq = gen_data(t_test, *res_lsq.x)\n",
      "    >>> y_soft_l1 = gen_data(t_test, *res_soft_l1.x)\n",
      "    >>> y_log = gen_data(t_test, *res_log.x)\n",
      "    ...\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> plt.plot(t_train, y_train, 'o')\n",
      "    >>> plt.plot(t_test, y_true, 'k', linewidth=2, label='true')\n",
      "    >>> plt.plot(t_test, y_lsq, label='linear loss')\n",
      "    >>> plt.plot(t_test, y_soft_l1, label='soft_l1 loss')\n",
      "    >>> plt.plot(t_test, y_log, label='cauchy loss')\n",
      "    >>> plt.xlabel(\"t\")\n",
      "    >>> plt.ylabel(\"y\")\n",
      "    >>> plt.legend()\n",
      "    >>> plt.show()\n",
      "    \n",
      "    In the next example, we show how complex-valued residual functions of\n",
      "    complex variables can be optimized with ``least_squares()``. Consider the\n",
      "    following function:\n",
      "    \n",
      "    >>> def f(z):\n",
      "    ...     return z - (0.5 + 0.5j)\n",
      "    \n",
      "    We wrap it into a function of real variables that returns real residuals\n",
      "    by simply handling the real and imaginary parts as independent variables:\n",
      "    \n",
      "    >>> def f_wrap(x):\n",
      "    ...     fx = f(x[0] + 1j*x[1])\n",
      "    ...     return np.array([fx.real, fx.imag])\n",
      "    \n",
      "    Thus, instead of the original m-D complex function of n complex\n",
      "    variables we optimize a 2m-D real function of 2n real variables:\n",
      "    \n",
      "    >>> from scipy.optimize import least_squares\n",
      "    >>> res_wrapped = least_squares(f_wrap, (0.1, 0.1), bounds=([0, 0], [1, 1]))\n",
      "    >>> z = res_wrapped.x[0] + res_wrapped.x[1]*1j\n",
      "    >>> z\n",
      "    (0.49999999999925893+0.49999999999925893j)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(scipy.optimize.least_squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function curve_fit in module scipy.optimize.minpack:\n",
      "\n",
      "curve_fit(f, xdata, ydata, p0=None, sigma=None, absolute_sigma=False, check_finite=True, bounds=(-inf, inf), method=None, jac=None, **kwargs)\n",
      "    Use non-linear least squares to fit a function, f, to data.\n",
      "    \n",
      "    Assumes ``ydata = f(xdata, *params) + eps``.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    f : callable\n",
      "        The model function, f(x, ...). It must take the independent\n",
      "        variable as the first argument and the parameters to fit as\n",
      "        separate remaining arguments.\n",
      "    xdata : array_like or object\n",
      "        The independent variable where the data is measured.\n",
      "        Should usually be an M-length sequence or an (k,M)-shaped array for\n",
      "        functions with k predictors, but can actually be any object.\n",
      "    ydata : array_like\n",
      "        The dependent data, a length M array - nominally ``f(xdata, ...)``.\n",
      "    p0 : array_like, optional\n",
      "        Initial guess for the parameters (length N). If None, then the\n",
      "        initial values will all be 1 (if the number of parameters for the\n",
      "        function can be determined using introspection, otherwise a\n",
      "        ValueError is raised).\n",
      "    sigma : None or M-length sequence or MxM array, optional\n",
      "        Determines the uncertainty in `ydata`. If we define residuals as\n",
      "        ``r = ydata - f(xdata, *popt)``, then the interpretation of `sigma`\n",
      "        depends on its number of dimensions:\n",
      "    \n",
      "            - A 1-D `sigma` should contain values of standard deviations of\n",
      "              errors in `ydata`. In this case, the optimized function is\n",
      "              ``chisq = sum((r / sigma) ** 2)``.\n",
      "    \n",
      "            - A 2-D `sigma` should contain the covariance matrix of\n",
      "              errors in `ydata`. In this case, the optimized function is\n",
      "              ``chisq = r.T @ inv(sigma) @ r``.\n",
      "    \n",
      "              .. versionadded:: 0.19\n",
      "    \n",
      "        None (default) is equivalent of 1-D `sigma` filled with ones.\n",
      "    absolute_sigma : bool, optional\n",
      "        If True, `sigma` is used in an absolute sense and the estimated parameter\n",
      "        covariance `pcov` reflects these absolute values.\n",
      "    \n",
      "        If False (default), only the relative magnitudes of the `sigma` values matter.\n",
      "        The returned parameter covariance matrix `pcov` is based on scaling\n",
      "        `sigma` by a constant factor. This constant is set by demanding that the\n",
      "        reduced `chisq` for the optimal parameters `popt` when using the\n",
      "        *scaled* `sigma` equals unity. In other words, `sigma` is scaled to\n",
      "        match the sample variance of the residuals after the fit. Default is False.\n",
      "        Mathematically,\n",
      "        ``pcov(absolute_sigma=False) = pcov(absolute_sigma=True) * chisq(popt)/(M-N)``\n",
      "    check_finite : bool, optional\n",
      "        If True, check that the input arrays do not contain nans of infs,\n",
      "        and raise a ValueError if they do. Setting this parameter to\n",
      "        False may silently produce nonsensical results if the input arrays\n",
      "        do contain nans. Default is True.\n",
      "    bounds : 2-tuple of array_like, optional\n",
      "        Lower and upper bounds on parameters. Defaults to no bounds.\n",
      "        Each element of the tuple must be either an array with the length equal\n",
      "        to the number of parameters, or a scalar (in which case the bound is\n",
      "        taken to be the same for all parameters). Use ``np.inf`` with an\n",
      "        appropriate sign to disable bounds on all or some parameters.\n",
      "    \n",
      "        .. versionadded:: 0.17\n",
      "    method : {'lm', 'trf', 'dogbox'}, optional\n",
      "        Method to use for optimization. See `least_squares` for more details.\n",
      "        Default is 'lm' for unconstrained problems and 'trf' if `bounds` are\n",
      "        provided. The method 'lm' won't work when the number of observations\n",
      "        is less than the number of variables, use 'trf' or 'dogbox' in this\n",
      "        case.\n",
      "    \n",
      "        .. versionadded:: 0.17\n",
      "    jac : callable, string or None, optional\n",
      "        Function with signature ``jac(x, ...)`` which computes the Jacobian\n",
      "        matrix of the model function with respect to parameters as a dense\n",
      "        array_like structure. It will be scaled according to provided `sigma`.\n",
      "        If None (default), the Jacobian will be estimated numerically.\n",
      "        String keywords for 'trf' and 'dogbox' methods can be used to select\n",
      "        a finite difference scheme, see `least_squares`.\n",
      "    \n",
      "        .. versionadded:: 0.18\n",
      "    kwargs\n",
      "        Keyword arguments passed to `leastsq` for ``method='lm'`` or\n",
      "        `least_squares` otherwise.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    popt : array\n",
      "        Optimal values for the parameters so that the sum of the squared\n",
      "        residuals of ``f(xdata, *popt) - ydata`` is minimized.\n",
      "    pcov : 2-D array\n",
      "        The estimated covariance of popt. The diagonals provide the variance\n",
      "        of the parameter estimate. To compute one standard deviation errors\n",
      "        on the parameters use ``perr = np.sqrt(np.diag(pcov))``.\n",
      "    \n",
      "        How the `sigma` parameter affects the estimated covariance\n",
      "        depends on `absolute_sigma` argument, as described above.\n",
      "    \n",
      "        If the Jacobian matrix at the solution doesn't have a full rank, then\n",
      "        'lm' method returns a matrix filled with ``np.inf``, on the other hand\n",
      "        'trf'  and 'dogbox' methods use Moore-Penrose pseudoinverse to compute\n",
      "        the covariance matrix.\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        if either `ydata` or `xdata` contain NaNs, or if incompatible options\n",
      "        are used.\n",
      "    \n",
      "    RuntimeError\n",
      "        if the least-squares minimization fails.\n",
      "    \n",
      "    OptimizeWarning\n",
      "        if covariance of the parameters can not be estimated.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    least_squares : Minimize the sum of squares of nonlinear functions.\n",
      "    scipy.stats.linregress : Calculate a linear least squares regression for\n",
      "                             two sets of measurements.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    With ``method='lm'``, the algorithm uses the Levenberg-Marquardt algorithm\n",
      "    through `leastsq`. Note that this algorithm can only deal with\n",
      "    unconstrained problems.\n",
      "    \n",
      "    Box constraints can be handled by methods 'trf' and 'dogbox'. Refer to\n",
      "    the docstring of `least_squares` for more information.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> from scipy.optimize import curve_fit\n",
      "    \n",
      "    >>> def func(x, a, b, c):\n",
      "    ...     return a * np.exp(-b * x) + c\n",
      "    \n",
      "    Define the data to be fit with some noise:\n",
      "    \n",
      "    >>> xdata = np.linspace(0, 4, 50)\n",
      "    >>> y = func(xdata, 2.5, 1.3, 0.5)\n",
      "    >>> rng = np.random.default_rng()\n",
      "    >>> y_noise = 0.2 * rng.normal(size=xdata.size)\n",
      "    >>> ydata = y + y_noise\n",
      "    >>> plt.plot(xdata, ydata, 'b-', label='data')\n",
      "    \n",
      "    Fit for the parameters a, b, c of the function `func`:\n",
      "    \n",
      "    >>> popt, pcov = curve_fit(func, xdata, ydata)\n",
      "    >>> popt\n",
      "    array([2.56274217, 1.37268521, 0.47427475])\n",
      "    >>> plt.plot(xdata, func(xdata, *popt), 'r-',\n",
      "    ...          label='fit: a=%5.3f, b=%5.3f, c=%5.3f' % tuple(popt))\n",
      "    \n",
      "    Constrain the optimization to the region of ``0 <= a <= 3``,\n",
      "    ``0 <= b <= 1`` and ``0 <= c <= 0.5``:\n",
      "    \n",
      "    >>> popt, pcov = curve_fit(func, xdata, ydata, bounds=(0, [3., 1., 0.5]))\n",
      "    >>> popt\n",
      "    array([2.43736712, 1.        , 0.34463856])\n",
      "    >>> plt.plot(xdata, func(xdata, *popt), 'g--',\n",
      "    ...          label='fit: a=%5.3f, b=%5.3f, c=%5.3f' % tuple(popt))\n",
      "    \n",
      "    >>> plt.xlabel('x')\n",
      "    >>> plt.ylabel('y')\n",
      "    >>> plt.legend()\n",
      "    >>> plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(curve_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('msd/msd_cna.txt',np.c_[temp_vac.data_averaged[1000]])\n",
    "# np.savetxt('msd/msd_cna_opt.txt',np.c_[temp_vac.popt])\n",
    "# np.savetxt('msd/msd_cna_cov.txt',np.c_[temp_vac.pcov])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    symbols=utl.Symbols()\n",
    "    legends = Legends()\n",
    "    legends.Set(bbox_to_anchor=(0.1,0.5,0.5,0.5))\n",
    "    #\n",
    "    ax=utl.PltErr([0.5e-3,1e-3],[1,1],attrs={'fmt':'-.r'},Plot=False)\n",
    "    utl.PltErr(1.0/np.array(temp.temps),\n",
    "               list(map(lambda x:temp.exponent[x][0],temp.temps)),\n",
    "               yerr=list(map(lambda x:1.0*(temp.exponent[x][1]-temp.exponent[x][2]),temp.temps)),\n",
    "               attrs=symbols.GetAttrs(count=0,label=r'$\\mathrm{Total}$'),\n",
    "               ax=ax,\n",
    "               Plot=False,\n",
    "    #           **kwargs\n",
    "              )\n",
    "\n",
    "    utl.PltErr(1.0/np.array(temp_vac.temps),\n",
    "               list(map(lambda x:temp_vac.exponent[x][0],temp_vac.temps)),\n",
    "               yerr=list(map(lambda x:1.0*(temp_vac.exponent[x][1]-temp_vac.exponent[x][2]),temp_vac.temps)),\n",
    "               attrs=symbols.GetAttrs(count=1,label=r'$\\mathrm{Vacancy}$'),\n",
    "               DrawFrame=DRAW_FRAME,\n",
    "               ax=ax,\n",
    "                       ylim=(.5,1.5),\n",
    "#               halfopen=True,\n",
    "#               legend=legends.Get(),\n",
    "                        title='png/alpha_temp_cantor.png',\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Robustness(Temperature):\n",
    "    \n",
    "    def __init__(self,temp_range,nrun,verbose=False):\n",
    "        Temperature.__init__(self,temp_range,nrun,verbose=verbose)\n",
    "\n",
    "    def FitRange(self,decades=9):\n",
    "        self.Fit(Plot=False,shift=False,\n",
    "                    p0=[[1e-2, 1e6, 1.0]],\n",
    "                 sigma=True, #--- comment for ni\n",
    "                     plotAttrs={'bbox_to_anchor':(-0.05,0.23,0.5,0.5)}\n",
    "                )\n",
    "\n",
    "        self.xlo = np.floor(np.log2(self.smat[:,0].min()))\n",
    "        xhii = np.ceil(np.log2(self.smat[:,0].max()))\n",
    "        self.xrange = 2**np.arange(xhii+1,xhii-decades,-1)\n",
    "        \n",
    "    def Fitting(self):\n",
    "        #--- bounds\n",
    "        self.exponents = np.zeros(len(self.xrange))\n",
    "        self.error = np.zeros(len(self.xrange))\n",
    "        self.npoin = np.zeros(len(self.xrange))\n",
    "        \n",
    "        npoint_filtrd0 = self.smat.shape[0]\n",
    "        for xhi, indx in zip(self.xrange,range(len(self.xrange))):\n",
    "            self.Fit(Plot=True,\n",
    "                     shift=False,\n",
    "        #             bounds=([0, 0, 0,0.999], [1e-2, 1e-3, 1,1.001]),\n",
    "                        p0=[[1e-2, 1e6, 1.0]],\n",
    "                     sigma=True, #--- comment for ni\n",
    "                     xlo=2**self.xlo,xhi=xhi,\n",
    "                     plotAttrs={'yscale':'log',\n",
    "                          'xscale':'log',\n",
    "        #                   'xlim':(4e-13,8e-4),\n",
    "        #                   'ylim':(1e-4,1e-1),\n",
    "        #                     'xstr':r'$t\\mathrm{(s)}$',\n",
    "        #                   'ystr':r'msd(A$^2$)',\n",
    "                                'ndecade_x':2,\n",
    "                            'bbox_to_anchor':(-0.05,0.23,0.5,0.5),\n",
    "    #                       'title':'png/msd_temp_nicocr_fit.png'\n",
    "                               },\n",
    "                    )\n",
    "            \n",
    "            #--- check if decrease in tc leads to fewere points\n",
    "#             npoint_filtrd = np.sum(self.filtr)\n",
    "#             if self.verbose:\n",
    "#                 print('npoint_filtrd=',npoint_filtrd)\n",
    "#             #if indx > 0:\n",
    "#             if npoint_filtrd == npoint_filtrd0 and indx > 0:\n",
    "#                 continue\n",
    "# #                    , '%s >= %sdecrease ndecades!'%(npoint_filtrd,npoint_filtrd0)\n",
    "#             npoint_filtrd0 = npoint_filtrd\n",
    "            \n",
    "            #--- assign\n",
    "            self.npoin[indx] = np.sum(self.filtr)\n",
    "            if self.npoin[indx] == self.npoin[indx-1] and indx > 0:\n",
    "                continue\n",
    "            self.exponents[indx] = self.popt[-1]\n",
    "            x = self.temps[ 0 ]\n",
    "            self.error[indx] = 0.5*(self.exponent[x][1]-self.exponent[x][2])\n",
    "        \n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "\n",
    "    symbols = utl.Symbols()\n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "\n",
    "    temps = [1200] #[1000,1200,1400,1600,1800,2000]\n",
    "    indices = [1] #range(10)\n",
    "    for temperature, indx in zip(temps,indices):\n",
    "        try:\n",
    "            rb = Robustness([temperature],8,\n",
    "#                            verbose = True\n",
    "\n",
    "                            )\n",
    "\n",
    "            #--- parse data\n",
    "#            rb.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "            rb.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "#            rb.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "                                rb.temps_runs ))\n",
    "                     )\n",
    "\n",
    "            #--- plot average\n",
    "            if rb.nrun > 1:\n",
    "                print('ensemble average')\n",
    "                rb.EnsAverage(log_scale=False,n_bins_per_decade=4)\n",
    "#                 rb.PlotAverage(**{\n",
    "#                           'yscale':'log',\n",
    "#                           'xscale':'log',\n",
    "#         #                   'xlim':(1e-10,1e-3),\n",
    "#         #                   'ylim':(1e-4,1e-1),\n",
    "#         #                     'xstr':r'$t\\mathrm{(s)}$',\n",
    "#         #                   'ystr':r'msd(A$^2$)',\n",
    "# #                            'title':'png/msd_temp_cantor.png',\n",
    "#                 })\n",
    "            #\n",
    "            #--- fit\n",
    "            #\n",
    "            rb.FitRange(decades=10)\n",
    "            rb.Fitting()\n",
    "\n",
    "\n",
    "            #--- get data\n",
    "            filtr = np.all([rb.exponents>0,rb.exponents<2],axis=0)\n",
    "            utl.PltErr(rb.xrange[filtr],rb.exponents[filtr],yerr=rb.error[filtr],\n",
    "                       attrs=symbols.GetAttrs(count=indx%7),\n",
    "                       ax=ax,\n",
    "                        Plot=False,\n",
    "                      )\n",
    "        except:\n",
    "            print('increase fit range!')\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "\n",
    "    utl.PltErr(ax.axis()[:2],[1,1],Plot=False,ax=ax,\n",
    "                attrs={'fmt':'-.','color':'red'},\n",
    "                       ylim=(0,2),\n",
    "                      xscale='log',\n",
    "                       DrawFrame=DRAW_FRAME,\n",
    "                       title='png/exponentH_ni_T%sK.png'%temperature,\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### per type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "    symbols=utl.Symbols()\n",
    "    legends = Legends()\n",
    "    legends.Set(bbox_to_anchor=(1.0,0.5,0.5,0.5))\n",
    " \n",
    "                       \n",
    "    ntype = 5\n",
    "    for itype in range(1,ntype+1):\n",
    "        temp = Temperature(#[1000],3\n",
    "                           list(map(int,np.linspace(1000,1400,11))),3\n",
    "                          )\n",
    "        temp.Parse( list(map(lambda x:'CantorNatom16KTemp%sK_ensemble/Run%s/msd/msd_type%s.txt'%(x[0],x[1],itype),\n",
    "                            temp.temps_runs ))\n",
    "                  )\n",
    "        #\n",
    "  #      print('single realizations')\n",
    "  #      temp.Plot()\n",
    "        #\n",
    "        print('ensemble average: type %s'%itype)\n",
    "        temp.EnsAverage()\n",
    "#         temp.PlotAverage()\n",
    "#         #\n",
    "        temp.Fit(#Plot=True,\n",
    "        #         verbose=True\n",
    "        )\n",
    "#         temp.PlotDiff()\n",
    "        \n",
    "        #--- plot\n",
    "        utl.PltErr(1/np.array(list(temp.Diffusion.keys())),\n",
    "                   list(map(lambda x:temp.Diffusion[x],list(temp.Diffusion.keys()))),\n",
    "                       Plot=False,\n",
    "                   ax=ax,\n",
    "                   attrs=symbols.GetAttrs(count=(itype-1)%7,label=r'$%s$'%temp),\n",
    "                 )\n",
    "    utl.PltErr(None,None,\n",
    "               ax=ax,\n",
    "               yscale='log',\n",
    "               ylim=(1e-15,1e-11),\n",
    "              xstr=r'$1/T(K^{-1})$',\n",
    "              ystr=r'$D(m^2/s)$',\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tauu = temp.time_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## correlated noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Noise(Temperature):\n",
    "    def __init__(self,temp_range,nrun,verbose=False):\n",
    "        Temperature.__init__(self,temp_range,nrun)\n",
    "        self.verbose = verbose\n",
    "    #\n",
    "    def PlotNoise(self, col_a = 1, col_b=1,\n",
    "                  **kwargs):\n",
    "        #\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=(1.0,0.5,0.5,0.5))\n",
    "        #\n",
    "        self.crltns_mean_ab = {}\n",
    "        self.crltns_mean_ba = {}\n",
    "        self.crltns_err_ab = {}\n",
    "        self.crltns_err_ba = {}\n",
    "        kount = 0\n",
    "        #\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp\n",
    "            data = self.data[kount:kount+self.nrun]\n",
    "            if self.verbose:\n",
    "                print('data.shape (per temperature):',np.array(data).shape)\n",
    "                \n",
    "            #--- correlations\n",
    "            crltns_ab = np.c_[list(map(lambda x: Noise.Crltns(x[:,col_a],x[:,col_b]),data))]\n",
    "            crltns_ba = np.c_[list(map(lambda x: Noise.Crltns(x[:,col_b],x[:,col_a]),data))]\n",
    "            self.crltns_mean_ab[temp] = np.mean(crltns_ab,axis=0)\n",
    "            self.crltns_mean_ba[temp] = np.mean(crltns_ba,axis=0)\n",
    "            self.crltns_err_ab[temp] = np.std(crltns_ab,axis=0)/self.nrun**0.5\n",
    "            self.crltns_err_ba[temp] = np.std(crltns_ba,axis=0)/self.nrun**0.5\n",
    "            kount += self.nrun\n",
    "        #--- plot\n",
    "        irun = 0\n",
    "        smat=data[irun]\n",
    "        for i,j in zip(smat[:,0],smat[:,col_a]):\n",
    "            utl.PltErr([i,i],[0,j],\n",
    "                       attrs={'fmt':'-','color':'C0'},\n",
    "                       ax=self.ax,\n",
    "                       Plot=False,\n",
    "#                       **kwargs\n",
    "                      )\n",
    "        utl.PltErr(self.ax.axis()[:2],[0,0],\n",
    "                        ax=self.ax,\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                       **kwargs\n",
    "                       )\n",
    "\n",
    "            \n",
    "        \n",
    "    def PlotSum(self, col_a = 1, col_b=1,\n",
    "                  **kwargs):\n",
    "        #\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=(1.0,0.5,0.5,0.5))\n",
    "        #\n",
    "        kount = 0\n",
    "        #\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp\n",
    "            data = self.data[kount:kount+self.nrun]\n",
    "            if self.verbose:\n",
    "                print('data.shape (per temperature):',np.array(data).shape)\n",
    "                \n",
    "            #--- correlations\n",
    "            #--- plot\n",
    "            irun = 0\n",
    "            smat=data[irun]\n",
    "            utl.PltErr(smat[:,0],np.cumsum(smat[:,col_a]),\n",
    "                       attrs={'drawstyle':'steps-post'},\n",
    "                       ax=self.ax,\n",
    "                       Plot=False,\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                       **kwargs\n",
    "                      )\n",
    "\n",
    "#             utl.PltErr(lmpData.headers['Time'][1:-1:2],np.cumsum(xvv[:,2]),\n",
    "#                       attrs={'drawstyle':'steps-post'},\n",
    "#                       )\n",
    "\n",
    "            \n",
    "            kount += self.nrun\n",
    "        \n",
    "    @staticmethod        \n",
    "    def Crltns(a,b,n=10):\n",
    "        cr,err=Noise.CrossCr(a,b)\n",
    "        return cr[:n] #np.c_[cr,err]\n",
    "    \n",
    "    def zscore(slist):\n",
    "        slist -= np.mean(slist)\n",
    "        slist /= np.std( slist )\n",
    "        return slist\n",
    "\n",
    "    def CrossCr(x,y, ZSCORE = True):\n",
    "        if ZSCORE:\n",
    "            x -= np.mean( x )\n",
    "            y -= np.mean( y )\n",
    "\n",
    "            x /= np.std( x )\n",
    "            y /= np.std( y )\n",
    "        assert len(x) == len(y), 'len(x)=%s,len(y)=%s'%(len(x),len(y))\n",
    "        n = len(x)\n",
    "        x=np.concatenate([x,np.zeros(n)],axis=0)\n",
    "        y=np.concatenate([y,np.zeros(n)],axis=0)\n",
    "        ones = np.concatenate([np.ones(n),np.zeros(n)],axis=0)\n",
    "\n",
    "        X=np.fft.fft(x)\n",
    "        Y=np.fft.fft(y)\n",
    "        Z=X.conjugate()*Y\n",
    "\n",
    "        cq = np.fft.fft( ones )\n",
    "        count = np.fft.ifft( cq.conjugate()*cq ).real[:n]\n",
    "\n",
    "        z=np.fft.ifft(Z)[:n] / count\n",
    "\n",
    "        return z, 1.0/np.sqrt(count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def PlotCrltns(self,**kwargs):\n",
    "\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=(1.0,0.5,0.5,0.5))\n",
    "        \n",
    "        ax = utl.PltErr(None,None,Plot=False)\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            n=noise.crltns_mean_ba[temp].shape[0]\n",
    "            x=np.concatenate([-np.arange(n-1,-1,-1),np.arange(n)])\n",
    "            indices=np.arange(n-1,-1,-1)\n",
    "            y=np.concatenate([noise.crltns_mean_ba[temp][indices],\n",
    "                              noise.crltns_mean_ab[temp]])\n",
    "            yerr=np.concatenate([noise.crltns_err_ba[temp][indices],\n",
    "                              noise.crltns_err_ab[temp]])\n",
    "\n",
    "\n",
    "            utl.PltErr(x,\n",
    "                       y,\n",
    "                       yerr=2*yerr,\n",
    "                       attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp),\n",
    "                       Plot=False,\n",
    "                       ax=ax,\n",
    "                      )\n",
    "            \n",
    "        utl.PltErr(ax.axis()[:2],[0,0],\n",
    "                   attrs={'fmt':'-.r'},\n",
    "                   Plot=False,\n",
    "            DrawFrame=DRAW_FRAME,\n",
    "                   ax=ax,\n",
    "                       **kwargs\n",
    "                  )\n",
    "    \n",
    "\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    #--- temp object\n",
    "    noise = Noise(\n",
    "#        [1000,1200,1400,1600,1800,2000],8,\n",
    "        [2000],8,\n",
    "#         verbose = True,\n",
    "                     )\n",
    "    #\n",
    "    #--- parse data\n",
    "#    noise.Parse(['./msd/noise.txt'])\n",
    "#    temp.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "    noise.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/noise.txt'%(x[0],x[1]),\n",
    "#    temp.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "#    temp.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "                        noise.temps_runs ))\n",
    "             )\n",
    "    #\n",
    "    #--- plot\n",
    "    noise.PlotNoise(col_a=1,col_b=1,**{\n",
    "#                   'attrs':{'fmt':'-','color':'C0'},\n",
    "#                   'xlim':(0,0.5e-09),\n",
    "#                    'ylim':(-2,2),\n",
    "#                     'xticks':([r'$0$',r'$2$',r'$4$'],[0,2e-10,4e-10]),\n",
    "#                   'title':'png/noise_z_nicocr.png',\n",
    "#                   'bbox_to_anchor':(0.01,0.3,0.5,0.5)\n",
    "    })\n",
    "    #\n",
    "    #--- plot sum\n",
    "#     noise.PlotSum(col_a=1,col_b=1,**{\n",
    "# #                  'xscale':'log',\n",
    "# #                  'yscale':'log',\n",
    "#                    'xlim':(0,1e-09),\n",
    "# #                    'ylim':(1e-5,1e-1),\n",
    "# #                   'xstr':r'$t\\mathrm{(s)}$',\n",
    "# #                   'ystr':r'msd(A$^2$)',\n",
    "# #                   'title':'png/msd_temp_ni.png',\n",
    "#         'bbox_to_anchor':(0.01,0.3,0.5,0.5)\n",
    "#     })\n",
    "\n",
    "    \n",
    "    #\n",
    "    noise.PlotCrltns(\n",
    "        **{\n",
    "#                   'yscale':'log',\n",
    "#                   'xscale':'log',\n",
    "#                   'xlim':(1e-10,1e-3),\n",
    "#                    'ylim':(1e-4,1e-1),\n",
    "#                     'xstr':r'$t\\mathrm{(s)}$',\n",
    "#                   'ystr':r'msd(A$^2$)',\n",
    "                   'title':'png/noiseCrltn_yz_nicocr.png',\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wait times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stats(Temperature):\n",
    "    def __init__(self,temp_range,nrun,verbose=False):\n",
    "        Temperature.__init__(self,temp_range,nrun)\n",
    "        self.verbose = verbose\n",
    "    #\n",
    "    def PlotWaitTimes(self,scale=False,\n",
    "                      scalePowerLaw=False,\n",
    "                      shift=False,\n",
    "                      n_per_decade=6,\n",
    "                      **kwargs):\n",
    "        #\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=(1.0,0.5,0.5,0.5))\n",
    "        #\n",
    "        self.mean_rate = {}\n",
    "        kount = 0\n",
    "        #\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            nruns = len(self.nrun[indx])\n",
    "            #--- concat. data for each temp\n",
    "            data = self.data[kount:kount+nruns]\n",
    "            data = list(map(lambda x:self.GetWaitTimes(x),data))\n",
    "            if self.verbose:\n",
    "                print('data.shape (per temperature):',np.array(data).shape)\n",
    "            data = np.concatenate(data) #,axis=0)\n",
    "            rate = 1.0 / data.mean()\n",
    "            self.mean_rate[temp] = [ rate, rate*(1/len(data)**0.5)]\n",
    "            if scale:\n",
    "                data /= data.mean() \n",
    "            if self.verbose:\n",
    "                print('data.shape (concatenated):',data.shape)\n",
    "            #--- histogram\n",
    "            hist, bin_edges, err = utl.GetPDF(data,n_per_decade=n_per_decade)\n",
    "            if scalePowerLaw:\n",
    "                alpha = 2 #1.5\n",
    "                hist *= bin_edges ** alpha \n",
    "                err *= bin_edges ** alpha \n",
    "            #--- plot\n",
    "            if shift:\n",
    "                hist *= 10 ** indx \n",
    "                err *= 10 ** indx \n",
    "            utl.PltErr(bin_edges,hist,\n",
    "                          yerr=err,\n",
    "                   attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp,fmt='.'),\n",
    "                   ax = self.ax,\n",
    "                   Plot=False,\n",
    "                          )\n",
    "            kount += nruns\n",
    "        self.data_regr = np.c_[bin_edges,hist,err]\n",
    "        #\n",
    "        xhi=self.ax.axis()[1]\n",
    "        xarr = np.logspace(np.log10(xhi)-5.0,np.log10(xhi),32)\n",
    "        utl.PltErr( xarr if scale else None,\n",
    "                   np.exp(-xarr) if scale else None,\n",
    "                   attrs={'fmt':'-.r','lw':2},\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "                   \n",
    "#                    legend=legends.Get(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "            \n",
    "    def PlotAverageRate(self,**kwargs):\n",
    "#        print(list(self.temps_runs))\n",
    "#         self.ax = utl.PltErr(None,#ans[:,0],\n",
    "#                         None,#1e8*ans[:,0],\n",
    "#                         attrs={'fmt':'-.r'},Plot=False)\n",
    "\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=(1.0,0.5,0.5,0.5))\n",
    "        data = list(map(lambda x:self.mean_rate[ x ][0], self.temps))\n",
    "        err = list(map(lambda x:self.mean_rate[ x ][1], self.temps))\n",
    "#             utl.PltErr(data[:,0],data[:,1],\n",
    "#                    yerr=data[:,2],\n",
    "#                    ax = self.ax,\n",
    "#                    attrs=symbols.GetAttrs(count=count%7,label=r'$%s$'%temp),\n",
    "#                    Plot=False,\n",
    "#                   )\n",
    "\n",
    "        utl.PltErr(1.0/np.array(self.temps),\n",
    "                   data,\n",
    "                   yerr=err,\n",
    "                   attrs=symbols.GetAttrs(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "            \n",
    "    \n",
    "    def GetWaitTimes(self,times):\n",
    "#         times = np.array(np.c_[self.lmpData.headers['Time'].iloc[0::2]].flatten())\n",
    "        dtt = times[1:]-times[:-1]\n",
    "        assert not np.any(dtt<0.0)\n",
    "        filtr = dtt > 0.0\n",
    "        return dtt[filtr]\n",
    "\n",
    "    #\n",
    "    def Barries(self):\n",
    "        Barrier = self.lmpData.headers['Barrier'].iloc[1::2]        \n",
    "        hist, bin_edges, err = utl.GetPDF(Barrier,linscale=True,n_per_decade=16)\n",
    "        utl.PltErr(bin_edges,hist,\n",
    "                  yerr=err,\n",
    "                   attrs=symbols.GetAttrs(),\n",
    "                   #yscale='log',\n",
    "                   #xscale='log',\n",
    "                   xstr=r'$\\Delta E$',\n",
    "                   ystr=r'$P(\\Delta E)$'\n",
    "                  )\n",
    "\n",
    "    def func(self,x,k,alpha,beta,t0):\n",
    "        return k*(x/t0)**(-alpha)/(1+(x/t0)**(beta-alpha))\n",
    "    \n",
    "    \n",
    "    def fit(self,edge,hist,err):\n",
    "        xdata=edge\n",
    "        ydata=hist\n",
    "        yerr=err\n",
    "        popt, pcov = curve_fit(self.func,xdata,ydata,\n",
    "                              p0=(1.0,0.4,2,1.0),\n",
    "                               sigma=yerr,\n",
    "                              )\n",
    "\n",
    "        ax=utl.PltErr(edge,hist,yerr=err,\n",
    "                   yscale='log',xscale='log',\n",
    "                      Plot=False\n",
    "                  )\n",
    "        utl.PltErr(edge,self.func(edge,*popt),attrs={'fmt':'-.r'},\n",
    "                   yscale='log',xscale='log',\n",
    "                   ax=ax,\n",
    "                   ylim=(1e-5,1000),\n",
    "                  )\n",
    "#        assert popt[-1]>0\n",
    "        print('k,alpha,beta,t0',popt)\n",
    "        return popt[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    if eval(confParser['flags']['RemoteMachine']):\n",
    "        return \n",
    "    \n",
    "    !mkdir png\n",
    "\n",
    "    stats = Stats(\n",
    "#         [1000,1200,1400,1600,1800,2000],8,\n",
    "        [1000], [list(range(8))]*10,\n",
    "#        [0,1],[list(range(8))]*10,\n",
    "#        np.arange(1000,1440,80),1,\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse(['msd/event_times.txt'])\n",
    "    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/event_times.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/event_times.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/event_times.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/event_times.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'flickers/nicocr/temp0/thresh%s/Run%s/msd/event_times.txt'%(x[0],x[1]),\n",
    "                        stats.temps_runs ))\n",
    "              )\n",
    "    stats.PlotWaitTimes(scale=True,shift=False,scalePowerLaw=False,\n",
    "                        n_per_decade=6,\n",
    "                        **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "#                     'xlim':(1e-3,100),\n",
    "                      'ylim':(1e-5,1e2),#(1e-8,1e6), #,\n",
    "#                    'ndecade_y':2,\n",
    "#                            'xstr':r'$t_w$',\n",
    "#                            'ystr':r'$P(\\lambda t_w)$',\n",
    "                   'title':'png/waitTimes_unscaled_ni.png'},\n",
    "\n",
    "                       )\n",
    "#     stats.PlotWaitTimes(scale=True,scalePowerLaw=True,\n",
    "#                         **{'xscale':'log',\n",
    "#                   'yscale':'log',\n",
    "# #                   'xlim':(1e-9,1e-3),\n",
    "#                    'ylim':(1e-5,1e0), #(1e-5,1e2),\n",
    "# #                           'xstr':r'$\\Delta t$',\n",
    "# #                           'ystr':r'$P(\\Delta t)$',\n",
    "#                    'title':'png/waitTimes_rescaled_ni.png'},\n",
    "#                       )\n",
    "#     stats.PlotAverageRate(\n",
    "#                 **{\n",
    "# #                    'fontsize':36,\n",
    "# #                  'xscale':'log',\n",
    "#                   'yscale':'log',\n",
    "# #                   'xlim':(1e-9,1e-3),\n",
    "# #                   'ylim':(1e9,1e13), #(1e-5,1e2),\n",
    "# #                           'xstr':r'$1/T$',\n",
    "# #                           'ystr':r'$\\lambda$',\n",
    "#                    'title':'png/eventRate_nicocr.png'},\n",
    "\n",
    "#     )\n",
    "    #\n",
    "#    stats.fit(stats.data_regr[:,0],stats.data_regr[:,1],stats.data_regr[:,2])\n",
    "    #stats.Barries()\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### effective E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x,a,b):\n",
    "    return a*np.exp(-b*x)\n",
    "\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    kb=8.61732814974056e-05\n",
    "    xdata = 1/(kb*np.array(stats.temps))\n",
    "    ydata = list(map(lambda x:stats.mean_rate[x][0],stats.temps))\n",
    "    yerr = list(map(lambda x:stats.mean_rate[x][1],stats.temps))\n",
    "    popt,pcov=curve_fit(func,xdata,ydata,\n",
    "             p0=[1e12,1],\n",
    "             sigma=yerr\n",
    "             )\n",
    "    #\n",
    "    ax=utl.PltErr(xdata,ydata,yerr=yerr,\n",
    "               fmt='.',\n",
    "               Plot=False\n",
    "\n",
    "              )\n",
    "    utl.PltErr(xdata,func(xdata,*popt),\n",
    "               yscale='log',\n",
    "               attrs={'fmt':'-.r'},\n",
    "               ax=ax,\n",
    "               xstr=r'$1/k_BT$',ystr=r'$\\lambda$'\n",
    "\n",
    "              )\n",
    "    Tm=[1650,2100][0]\n",
    "    print('energy=%s eV'%popt[1])\n",
    "    print('scaled energy=',popt[1]/kb/Tm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reduced temperature scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    #Tm = 1650\n",
    "    xdata = np.array(stats.temps)\n",
    "    ydata = list(map(lambda x:stats.mean_rate[x][0],stats.temps))\n",
    "    yerr = list(map(lambda x:stats.mean_rate[x][1],stats.temps))\n",
    "    np.savetxt('ni2nd.txt',np.c_[xdata,ydata,yerr],header='T lambda err')\n",
    "\n",
    "    symbols=utl.Symbols()\n",
    "    legends = Legends()\n",
    "    legends.Set(bbox_to_anchor=(1.0,0.5,0.5,0.5))\n",
    "\n",
    "\n",
    "\n",
    "    Tm = 1650\n",
    "    data_nicocr = np.loadtxt('nicocr.txt')\n",
    "    xdata = Tm/data_nicocr[:,0]\n",
    "    ydata = data_nicocr[:,1]\n",
    "    yerr = data_nicocr[:,2]\n",
    "\n",
    "    ax=utl.PltErr(xdata,ydata,yerr=yerr,\n",
    "                    attrs=symbols.GetAttrs(count=1,label=r'nicocr'),\n",
    "              Plot=False,\n",
    "             yscale='log'\n",
    "             )\n",
    "\n",
    "    Tm = 2100\n",
    "    data_ni = np.loadtxt('ni.txt')\n",
    "    xdata = Tm/data_ni[:,0]\n",
    "    ydata = data_ni[:,1]\n",
    "    yerr = data_ni[:,2]\n",
    "\n",
    "    utl.PltErr(xdata,ydata,yerr=yerr,\n",
    "                    attrs=symbols.GetAttrs(count=0,label=r'ni'),\n",
    "            ax=ax,\n",
    "              Plot=False,\n",
    "             yscale='log',\n",
    "                     legend=legends.Get(),\n",
    "               xstr=r'$T_m/T$',ystr=r'$\\lambda$'\n",
    "             )\n",
    "\n",
    "    # Tm = 1607\n",
    "    # data_ni = np.loadtxt('cantor.txt')\n",
    "    # xdata = Tm/data_ni[:,0]\n",
    "    # ydata = data_ni[:,1]\n",
    "    # yerr = data_ni[:,2]\n",
    "\n",
    "    # utl.PltErr(xdata,ydata,yerr=yerr,\n",
    "    # #          fmt='.',\n",
    "    #         ax=ax,\n",
    "    #           Plot=False,\n",
    "    #          yscale='log'\n",
    "    #          )\n",
    "\n",
    "    # Tm = 2100\n",
    "    # data_ni = np.loadtxt('ni2nd.txt')\n",
    "    # xdata = Tm/data_ni[:,0]\n",
    "    # ydata = data_ni[:,1]\n",
    "    # yerr = data_ni[:,2]\n",
    "\n",
    "    # utl.PltErr(xdata,ydata,yerr=yerr,\n",
    "    # #          fmt='.',\n",
    "    #         ax=ax,\n",
    "    #           Plot=False,\n",
    "    #          yscale='log',\n",
    "    #                  legend=legends.Get(),\n",
    "\n",
    "    #          )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    path = '../simulations/NiMultTemp/Temp2000K/Run0'\n",
    "\n",
    "    #--- parse\n",
    "    data = pd.read_csv('%s/thermo.txt'%path,delimiter=' ')\n",
    "\n",
    "    #--- plot\n",
    "    utl.PltErr(data.time,data.vol,ystr='vol')\n",
    "    utl.PltErr(data.time,data.temp,ystr='temp')\n",
    "\n",
    "    #--- mean \n",
    "    filtr = data.time > 100.0\n",
    "    n = np.sum(filtr)\n",
    "    mean_vol = data.vol[filtr].mean()\n",
    "    err_vol = data.vol[filtr].std()/n**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    mean_vol = {}\n",
    "    err_vol = {}\n",
    "    temps = np.linspace(2000,3000,16)\n",
    "    for temp in temps:\n",
    "        path = '../simulations/NiMultTemp/Temp%sK/Run0'%int(temp)\n",
    "\n",
    "        #--- parse\n",
    "        data = pd.read_csv('%s/thermo.txt'%path,delimiter=' ')\n",
    "\n",
    "        #--- plot\n",
    "    #    utl.PltErr(data.time,data.vol,ystr='vol')\n",
    "    #    utl.PltErr(data.time,data.temp,ystr='temp')\n",
    "\n",
    "        #--- mean \n",
    "        filtr = data.time > 100.0\n",
    "        n = np.sum(filtr)\n",
    "        mean_vol[temp] = data.vol[filtr].mean()\n",
    "        err_vol[temp] = data.vol[filtr].std()/n**0.5\n",
    "    \n",
    "    filtr = temps>0\n",
    "    utl.PltErr(temps[filtr],\n",
    "               np.array(list(map(lambda x:mean_vol[x],temps)))[filtr],\n",
    "\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JumpStats(Temperature):\n",
    "    def __init__(self,temp_range,nrun,verbose=False):\n",
    "        Temperature.__init__(self,temp_range,nrun)\n",
    "        self.verbose = verbose\n",
    "    #\n",
    "    def PlotPdf(self,scale=False,**kwargs):\n",
    "        #\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "        #\n",
    "        self.mean_rate = {}\n",
    "        kount = 0\n",
    "        #\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp\n",
    "            data = self.data[kount:kount+self.nrun][0]\n",
    "            if self.verbose:\n",
    "                print('data.shape (per temperature):',np.array(data).shape)\n",
    "            if self.verbose:\n",
    "                print('data.shape (concatenated):',data.shape)\n",
    "            #--- histogram\n",
    "#            data = np.array(data).flatten()\n",
    "            hist = data[:,1]\n",
    "            bin_edges = data[:,0]\n",
    "            err = data[:,2]\n",
    "            \n",
    "            #--- remove count == 1\n",
    "            filtr = err == hist\n",
    "            hist = hist[~filtr]\n",
    "            bin_edges = bin_edges[~filtr]\n",
    "            err = err[~filtr]\n",
    "            \n",
    "            self.data_regr = np.c_[bin_edges,hist,err]\n",
    "            if scale:\n",
    "                hist *= bin_edges ** self.alpha\n",
    "                err  *= bin_edges ** self.alpha\n",
    "        #--- plot\n",
    "#            temp= [1000,1200,1400,1600,1800,2000][indx]\n",
    "            utl.PltErr(bin_edges,hist,\n",
    "                          yerr=err,\n",
    "                   attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp,fmt='.'),\n",
    "                   ax = self.ax,\n",
    "                   Plot=False,\n",
    "                          )\n",
    "            kount+=self.nrun\n",
    "        #\n",
    "        utl.PltErr(None,\n",
    "                   None,\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "#                      legend=legends.Get(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "            \n",
    "    def func(self,x,k,alpha):\n",
    "        return k*x**alpha\n",
    "    \n",
    "    \n",
    "    def fit(self,edge,hist,err):\n",
    "        xdata=edge\n",
    "        ydata=hist\n",
    "        yerr=err\n",
    "        popt, pcov = curve_fit(self.func,xdata,ydata,\n",
    "                               p0=(1.0e-4,-2.0),\n",
    "                               sigma=2*yerr,\n",
    "                              )\n",
    "\n",
    "        ax=utl.PltErr(edge,hist,yerr=2*err,fmt='.',\n",
    "                   yscale='log',xscale='log',\n",
    "                      Plot=False\n",
    "                  )\n",
    "        utl.PltErr(edge,self.func(edge,*popt),attrs={'fmt':'-.r'},\n",
    "                   yscale='log',xscale='log',\n",
    "                   ax=ax,\n",
    "#                   ylim=(1e-5,1000),\n",
    "                  )\n",
    "#        assert popt[-1]>0\n",
    "        print('k,alpha',popt)\n",
    "        return popt[0]\n",
    "    \n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    \n",
    "    stats = JumpStats(\n",
    "        [1000,1200,1400,1600,1800,2000],\n",
    "#        [1000,1200,1400,1600,1800,2000],\n",
    "#        np.arange(1000,1440,80),\n",
    "        1,\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/event_jumps.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/event_jumps.txt'%(x[0],x[1]),\n",
    "    stats.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/event_jumps.txt'%(x[0],x[1]),\n",
    "                         stats.temps_runs ))\n",
    "               )\n",
    "    stats.PlotPdf(scale=False,\n",
    "                        **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "                   'xlim':(1e-8,4e0),\n",
    "#                   'ylim':(1e-3,1e1), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "                        'ndecade_x':2,'ndecade_y':2,\n",
    "                    'bbox_to_anchor':(0.56,0.27,0.5,0.5),\n",
    "                   'title':'png/jumpsPdf_nicocr.png'},\n",
    "\n",
    "                       )\n",
    "    \n",
    "    #--- rescale\n",
    "    stats.alpha = 2.5 #2.8 #3.0#2.5\n",
    "    stats.PlotPdf(scale=True,\n",
    "                **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "                   'fontsize':32,\n",
    "#                   'xlim':(1e-8,2e0),\n",
    "#                   'ylim':(1e-3,1e1), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "                        'ndecade_x':2,'ndecade_y':4,\n",
    "                   'title':'png/jumpsPdf_rescaled_ni.png'},\n",
    "\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "\n",
    "    stats = JumpStats(\n",
    "        [2000],1,\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/event_jumps.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/event_jumps.txt'%(x[0],x[1]),\n",
    "    stats.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/event_jumps.txt'%(x[0],x[1]),\n",
    "                         stats.temps_runs ))\n",
    "               )\n",
    "    stats.PlotPdf(scale=False,\n",
    "                        **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "                   'xlim':(1e-8,4e0),\n",
    "#                   'ylim':(1e-3,1e1), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "                        'ndecade_x':2,'ndecade_y':2,\n",
    "                    'bbox_to_anchor':(0.56,0.27,0.5,0.5),\n",
    "#                    'title':'png/jumpsPdf_nicocr.png'\n",
    "                          },\n",
    "\n",
    "                       )\n",
    "    filtr = np.all([stats.data_regr[:,0]>1e-3,stats.data_regr[:,0]<1e-1],axis=0)\n",
    "    stats.fit(stats.data_regr[:,0][filtr],stats.data_regr[:,1][filtr],stats.data_regr[:,2][filtr])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Energy = lmpData.headers['Energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not eval(confParser['flags']['RemoteMachine']):\n",
    "#             data = self.data[kount:kount+self.nrun]\n",
    "#             if self.verbose:\n",
    "#                 print('data.shape:',np.array(data).shape)\n",
    "# #             print('np.array(data):',np.array(data))\n",
    "# #             pdb.set_trace()\n",
    "    \n",
    "#             filtr = list(map(lambda x:x.shape[0] > 0,data)) #--- filter empty arrays\n",
    "    \n",
    "#             data = np.concatenate(np.array(data)[filtr]) #,axis=0)\n",
    "#             self.data_averaged[ temp ] = self.hist(data,log_scale)\n",
    "#             kount += self.nrun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sampled energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class EnergyStats(Temperature):\n",
    "    def __init__(self,temp_range,nrun,verbose=False):\n",
    "        Temperature.__init__(self,temp_range,nrun)\n",
    "        self.verbose = verbose\n",
    "    #\n",
    "    def GetWaitTimes(self,times):\n",
    "        times = times[0::2]\n",
    "        dtt = times[1:]-times[:-1]\n",
    "        assert not np.any(dtt<0.0)\n",
    "#        filtr = dtt > 0.0\n",
    "        return dtt#[filtr]\n",
    "    #\n",
    "    def PlotPdf(self,shift=False,column_energy = 0,n_per_decade=8,\n",
    "                linscale = False,\n",
    "                **kwargs):\n",
    "        #\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs #plotAttrs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "        #\n",
    "        self.mean_rate = {}\n",
    "        #\n",
    "        kount = 0\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            nruns = len(self.nrun[indx])\n",
    "\n",
    "            #--- concat. data for each temp            \n",
    "            data = np.concatenate(list(map(lambda x: self.data[x][:,column_energy],range(kount,kount+nruns))))\n",
    "            #--- remove zeros\n",
    "            data = data[data > 0.0]\n",
    "            if self.verbose:\n",
    "                print('data.shape (per temperature):',np.array(data).shape)\n",
    "            if self.verbose:\n",
    "                print('data.shape (concatenated):',data.shape)\n",
    "            #--- histogram\n",
    "#            data = np.array(data).flatten()\n",
    "            #--- histogram\n",
    "            hist, bin_edges, err = utl.GetPDF(data,n_per_decade=n_per_decade,linscale=linscale)\n",
    "        \n",
    "            #--- filtr\n",
    "            filtr = hist == err\n",
    "            hist = hist[~filtr]\n",
    "            bin_edges = bin_edges[~filtr]\n",
    "            err = err[~filtr]\n",
    "        #--- plot\n",
    "            if shift:\n",
    "                hist *= 100**indx if shift else 1\n",
    "                err *= 100**indx if shift else 1\n",
    "\n",
    "            utl.PltErr(bin_edges,hist,\n",
    "#                           yerr=err,\n",
    "                    attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp), #,fmt='.'),\n",
    "#                   attrs={'fmt':'-','color':'C0'},\n",
    "                   ax = self.ax,\n",
    "                   Plot=False,\n",
    "                          )\n",
    "            \n",
    "#            self.ax.fill_between(bin_edges, hist)\n",
    "            \n",
    "            kount += nruns #self.nrun\n",
    "        #\n",
    "        utl.PltErr(None,\n",
    "                   None,\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "                   \n",
    "#                    legend=legends.Get(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "        \n",
    "    def PlotPdfConcat(self,scale=False,\n",
    "                      column_energy = 0,\n",
    "                      type_column=0,\n",
    "                      splitByType=True,\n",
    "                      n_per_decade = 8,\n",
    "                      **kwargs):\n",
    "        #\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs #plotAttrs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "        #\n",
    "        self.mean_rate = {}\n",
    "        kount = 0\n",
    "        #\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp            \n",
    "#            data = np.concatenate(list(map(lambda x: self.data[x][:,column_energy],range(indx,indx+self.nrun))))\n",
    "            data = np.concatenate(list(map(lambda x: self.data[x],range(kount,kount+self.nrun))))\n",
    "#             types = np.concatenate(list(map(lambda x: self.data[x][:,type_column],range(indx,indx+self.nrun))))\n",
    "            #--- remove zeros\n",
    "#            data = data[data > 0.0]\n",
    "            if self.verbose:\n",
    "                print('data.shape (per temperature):',np.array(data).shape)\n",
    "            if self.verbose:\n",
    "                print('data.shape (concatenated):',data.shape)\n",
    "            #--- histogram\n",
    "#            data = np.array(data).flatten()\n",
    "            #--- histogram\n",
    "            data_concat = data.copy() if indx ==0 else np.concatenate([data_concat,data]) #np.c_[types,data] if indx ==0 else\\\n",
    "                        #np.concatenate([data_concat,np.c_[types,data]])\n",
    "            kount += self.nrun\n",
    "        if self.verbose:\n",
    "            print('type.shape (concatenated):',data_concat.shape)\n",
    "        \n",
    "        #--- split by type\n",
    "        if splitByType:\n",
    "            df=pd.DataFrame(np.c_[data_concat[:,type_column],data_concat[:,column_energy]],\n",
    "                            columns=['type','dE'])\n",
    "            types=df.groupby(by='type').groups\n",
    "            for itype in types:\n",
    "                indices = types[itype]\n",
    "                elist = np.array(df['dE'].iloc[indices])\n",
    "                if self.verbose:\n",
    "                    print('elist.shape:',elist.shape)\n",
    "\n",
    "                #--- histogram\n",
    "                hist, bin_edges, err = utl.GetPDF(elist,n_per_decade=n_per_decade)\n",
    "\n",
    "                #--- filtr\n",
    "                filtr = hist == err\n",
    "                hist = hist[~filtr]\n",
    "                bin_edges = bin_edges[~filtr]\n",
    "                err = err[~filtr]\n",
    "                #--- plot\n",
    "                if scale:\n",
    "                    hist *= 1000**int(itype)\n",
    "                    err *= 1000**int(itype)\n",
    "                utl.PltErr(bin_edges,hist,\n",
    "                              yerr=err,\n",
    "                       attrs=symbols.GetAttrs(count=int(itype-1)%7,label=r'$%s$'%itype), #,fmt='.'),\n",
    "                       ax = self.ax,\n",
    "                       Plot=False,\n",
    "                              )\n",
    "        else:\n",
    "                data = data_concat[:,column_energy]\n",
    "                data = data[data > 0.0]\n",
    "\n",
    "                #--- histogram\n",
    "                hist, bin_edges, err = utl.GetPDF(data,n_per_decade=n_per_decade)\n",
    "\n",
    "                #--- filtr\n",
    "                filtr = hist == err\n",
    "                hist = hist[~filtr]\n",
    "                bin_edges = bin_edges[~filtr]\n",
    "                err = err[~filtr]\n",
    "                #--- plot\n",
    "#                 if scale:\n",
    "#                     hist *= 100**int(itype)\n",
    "#                     err *= 100**int(itype)\n",
    "                utl.PltErr(bin_edges,hist,\n",
    "                              yerr=err,\n",
    "                       attrs=symbols.GetAttrs(count=0), #,label=r'$%s$'%itype),#,fmt='.'),\n",
    "                       ax = self.ax,\n",
    "                       Plot=False,\n",
    "                              )\n",
    "        #\n",
    "        utl.PltErr(None,\n",
    "                   None,\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "\n",
    "#                        legend=legends.Get(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "\n",
    "    def Scatter(self,shift=False,nevery=1,**kwargs):\n",
    "        kb_inv=8.61732814974056e05\n",
    "        \n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=Symbols(markersizes=np.array([10,10,10,12,12,12,10])*8)\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs #plotAttrs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "\n",
    "        #\n",
    "        column_energy = 0\n",
    "        column_time = 3\n",
    "        kount = 0\n",
    "        for indx in range(0,len(self.temps),nevery):\n",
    "            temp = self.temps[indx]\n",
    "            #--- concat. data for each temp            \n",
    "            data_energy = np.concatenate(list(map(lambda x: self.GetEnergy(self.data[x][:,column_energy]),\n",
    "                                                  range(kount,kount+self.nrun))))\n",
    "            #--- wait_times\n",
    "            data = self.data[indx:indx+self.nrun]\n",
    "            data_waitTimes = np.concatenate(list(map(lambda x: self.GetWaitTimes(self.data[x][:,column_time]),\n",
    "                                                     range(kount,kount+self.nrun))))\n",
    "\n",
    "            if self.verbose:\n",
    "                print('data_energy.shape (per temperature):',np.array(data_energy).shape)\n",
    "                print('data_waitTimes.shape (per temperature):',np.array(data_waitTimes).shape)\n",
    "            #--- plot scatter\n",
    "            scale = 1e2 ** indx if shift else 1\n",
    "            filtr = data_waitTimes > 0\n",
    "#             utl.PltErr(data_energy[filtr]*kb_inv/temp,scale*data_waitTimes[filtr],\n",
    "#                         attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp,fmt='.',alpha=1.0),\n",
    "#                         ax = self.ax,\n",
    "#                         Plot=False,\n",
    "#                         )\n",
    "            self.ax.scatter(data_energy[filtr]*kb_inv/temp,scale*data_waitTimes[filtr],\n",
    "                        **symbols.GetAttrsScatter(count=indx%7,label=r'$%s$'%temp,fmt='.',alpha=0.1/2),\n",
    "                       )\n",
    "            kount += self.nrun\n",
    "            #--- plot average\n",
    "#             nbins = 8\n",
    "#             count, _=np.histogram(data_energy[filtr],bins=nbins)\n",
    "#             xsum, _=np.histogram(data_energy[filtr],weights=data_energy[filtr],bins=nbins)\n",
    "#             ysum, _=np.histogram(data_energy[filtr],weights=data_waitTimes[filtr],bins=nbins)\n",
    "#             ysum /= count\n",
    "# #            ysum =10 ** ysum \n",
    "#             xsum /= count\n",
    "#             #---\n",
    "#             utl.PltErr(xsum,ysum,\n",
    "#                         attrs=symbols.GetAttrs(count=(indx)%7,label=r'$%s$'%temp,fmt='.'),\n",
    "#                         ax = self.ax,\n",
    "#                         Plot=False,\n",
    "#                         )\n",
    "        \n",
    "        \n",
    "        utl.PltErr(None,\n",
    "                   None,\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "#                     legend=legends.Get(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "\n",
    "    def GetEnergy(self,slist):\n",
    "        n=len(slist)\n",
    "        return slist[1:n:2]\n",
    "            \n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    \n",
    "    stats = EnergyStats(\n",
    "        [1000,1200,1400,1600,1800,2000],8,\n",
    "#        [1000,1400,1800,2000],8,\n",
    "#        [1000, 1400,1800],8,\n",
    "        #        np.arange(1000,1440,40),1,\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "                         stats.temps_runs ))\n",
    "               )\n",
    "    stats.PlotPdf(shift=True,n_per_decade=10,\n",
    "                        **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "#                   'xlim':(1e-3,1e0),\n",
    "#                   'ylim':(1e-2,1e2), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "                        'ndecade_y':2,\n",
    "                   'title':'png/BarrierPdf_cantor.png'},\n",
    "\n",
    "                       )\n",
    "    \n",
    "#     stats.PlotPdfConcat(scale=False,\n",
    "#                         splitByType = False,\n",
    "#                         **{'xscale':'log',\n",
    "#                       'yscale':'log',\n",
    "#     #                   'xlim':(1e-3,1e0),\n",
    "# #                        'ylim':(1e-2,1e2), #(1e-5,1e2),\n",
    "#     #                           'xstr':r'$\\Delta t$',\n",
    "#     #                           'ystr':r'$P(\\Delta t)$',\n",
    "#     #                        'ndecade_x':2,'ndecade_y':2,\n",
    "#     #                   'title':'png/BarrierPdf_cantor.png'\n",
    "#                           },\n",
    "#                        )\n",
    "\n",
    "    stats.Scatter(nevery=2, shift = True,                        \n",
    "                **{'xscale':'linear',\n",
    "                  'yscale':'log',\n",
    "#                   'xlim':(1e-3,1),\n",
    "#                   'ylim':(1e-3,1e1), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "#                     'bbox_to_anchor':(0.56,0.27,0.5,0.5),\n",
    "                        'ndecade_y':2,\n",
    "                   'title':'png/twVsEnergy_nicocr.png',\n",
    "                  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# class EnergyStats(Temperature):\n",
    "#     def __init__(self,temp_range,nrun,verbose=False):\n",
    "#         Temperature.__init__(self,temp_range,nrun)\n",
    "#         self.verbose = verbose\n",
    "#     #\n",
    "#     def GetWaitTimes(self,times):\n",
    "#         times = times[0::2]\n",
    "#         dtt = times[1:]-times[:-1]\n",
    "#         assert not np.any(dtt<0.0)\n",
    "# #        filtr = dtt > 0.0\n",
    "#         return dtt#[filtr]\n",
    "#     #\n",
    "#     def PlotPdf(self,shift=False,column_energy = 0,n_per_decade=8,\n",
    "#                 **kwargs):\n",
    "#         #\n",
    "#         self.ax = utl.PltErr(None,#ans[:,0],\n",
    "#                         None,#1e8*ans[:,0],\n",
    "#                         attrs={'fmt':'-.r'},Plot=False)\n",
    "#         symbols=utl.Symbols()\n",
    "#         legends = Legends()\n",
    "#         legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs #plotAttrs\n",
    "#                     else (1.0,0.5,0.5,0.5))\n",
    "#         #\n",
    "#         self.mean_rate = {}\n",
    "#         #\n",
    "#         kount = 0\n",
    "#         for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "#             #--- concat. data for each temp            \n",
    "#             data = np.concatenate(list(map(lambda x: self.data[x][:,column_energy],range(kount,kount+self.nrun))))\n",
    "#             #--- remove zeros\n",
    "#             data = data[data > 0.0]\n",
    "#             if self.verbose:\n",
    "#                 print('data.shape (per temperature):',np.array(data).shape)\n",
    "#             if self.verbose:\n",
    "#                 print('data.shape (concatenated):',data.shape)\n",
    "#             #--- histogram\n",
    "# #            data = np.array(data).flatten()\n",
    "#             #--- histogram\n",
    "#             hist, bin_edges, err = utl.GetPDF(data,n_per_decade=n_per_decade)\n",
    "        \n",
    "#             #--- filtr\n",
    "#             filtr = hist == err\n",
    "#             hist = hist[~filtr]\n",
    "#             bin_edges = bin_edges[~filtr]\n",
    "#             err = err[~filtr]\n",
    "#         #--- plot\n",
    "#             if shift:\n",
    "#                 hist *= 100**indx if shift else 1\n",
    "#                 err *= 100**indx if shift else 1\n",
    "\n",
    "#             utl.PltErr(bin_edges,hist,\n",
    "#                           yerr=err,\n",
    "#                    attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp), #,fmt='.'),\n",
    "#                    ax = self.ax,\n",
    "#                    Plot=False,\n",
    "#                           )\n",
    "#             kount += self.nrun\n",
    "#         #\n",
    "#         utl.PltErr(None,\n",
    "#                    None,\n",
    "#                    ax=self.ax,\n",
    "#                    Plot=False,\n",
    "                   \n",
    "# #                    legend=legends.Get(),\n",
    "#                    DrawFrame=DRAW_FRAME,\n",
    "#                    **kwargs\n",
    "#                   )\n",
    "        \n",
    "#     def PlotPdfConcat(self,scale=False,\n",
    "#                       column_energy = 0,\n",
    "#                       type_column=0,\n",
    "#                       splitByType=True,\n",
    "#                       n_per_decade = 8,\n",
    "#                       **kwargs):\n",
    "#         #\n",
    "#         self.ax = utl.PltErr(None,#ans[:,0],\n",
    "#                         None,#1e8*ans[:,0],\n",
    "#                         attrs={'fmt':'-.r'},Plot=False)\n",
    "#         symbols=utl.Symbols()\n",
    "#         legends = Legends()\n",
    "#         legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs #plotAttrs\n",
    "#                     else (1.0,0.5,0.5,0.5))\n",
    "#         #\n",
    "#         self.mean_rate = {}\n",
    "#         kount = 0\n",
    "#         #\n",
    "#         for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "#             #--- concat. data for each temp            \n",
    "# #            data = np.concatenate(list(map(lambda x: self.data[x][:,column_energy],range(indx,indx+self.nrun))))\n",
    "#             data = np.concatenate(list(map(lambda x: self.data[x],range(kount,kount+self.nrun))))\n",
    "# #             types = np.concatenate(list(map(lambda x: self.data[x][:,type_column],range(indx,indx+self.nrun))))\n",
    "#             #--- remove zeros\n",
    "# #            data = data[data > 0.0]\n",
    "#             if self.verbose:\n",
    "#                 print('data.shape (per temperature):',np.array(data).shape)\n",
    "#             if self.verbose:\n",
    "#                 print('data.shape (concatenated):',data.shape)\n",
    "#             #--- histogram\n",
    "# #            data = np.array(data).flatten()\n",
    "#             #--- histogram\n",
    "#             data_concat = data.copy() if indx ==0 else np.concatenate([data_concat,data]) #np.c_[types,data] if indx ==0 else\\\n",
    "#                         #np.concatenate([data_concat,np.c_[types,data]])\n",
    "#             kount += self.nrun\n",
    "#         if self.verbose:\n",
    "#             print('type.shape (concatenated):',data_concat.shape)\n",
    "        \n",
    "#         #--- split by type\n",
    "#         if splitByType:\n",
    "#             df=pd.DataFrame(np.c_[data_concat[:,type_column],data_concat[:,column_energy]],\n",
    "#                             columns=['type','dE'])\n",
    "#             types=df.groupby(by='type').groups\n",
    "#             for itype in types:\n",
    "#                 indices = types[itype]\n",
    "#                 elist = np.array(df['dE'].iloc[indices])\n",
    "#                 if self.verbose:\n",
    "#                     print('elist.shape:',elist.shape)\n",
    "\n",
    "#                 #--- histogram\n",
    "#                 hist, bin_edges, err = utl.GetPDF(elist,n_per_decade=n_per_decade)\n",
    "\n",
    "#                 #--- filtr\n",
    "#                 filtr = hist == err\n",
    "#                 hist = hist[~filtr]\n",
    "#                 bin_edges = bin_edges[~filtr]\n",
    "#                 err = err[~filtr]\n",
    "#                 #--- plot\n",
    "#                 if scale:\n",
    "#                     hist *= 1000**int(itype)\n",
    "#                     err *= 1000**int(itype)\n",
    "#                 utl.PltErr(bin_edges,hist,\n",
    "#                               yerr=err,\n",
    "#                        attrs=symbols.GetAttrs(count=int(itype-1)%7,label=r'$%s$'%itype), #,fmt='.'),\n",
    "#                        ax = self.ax,\n",
    "#                        Plot=False,\n",
    "#                               )\n",
    "#         else:\n",
    "#                 data = data_concat[:,column_energy]\n",
    "#                 data = data[data > 0.0]\n",
    "\n",
    "#                 #--- histogram\n",
    "#                 hist, bin_edges, err = utl.GetPDF(data,n_per_decade=n_per_decade)\n",
    "\n",
    "#                 #--- filtr\n",
    "#                 filtr = hist == err\n",
    "#                 hist = hist[~filtr]\n",
    "#                 bin_edges = bin_edges[~filtr]\n",
    "#                 err = err[~filtr]\n",
    "#                 #--- plot\n",
    "# #                 if scale:\n",
    "# #                     hist *= 100**int(itype)\n",
    "# #                     err *= 100**int(itype)\n",
    "#                 utl.PltErr(bin_edges,hist,\n",
    "#                               yerr=err,\n",
    "#                        attrs=symbols.GetAttrs(count=0), #,label=r'$%s$'%itype),#,fmt='.'),\n",
    "#                        ax = self.ax,\n",
    "#                        Plot=False,\n",
    "#                               )\n",
    "#         #\n",
    "#         utl.PltErr(None,\n",
    "#                    None,\n",
    "#                    ax=self.ax,\n",
    "#                    Plot=False,\n",
    "\n",
    "# #                        legend=legends.Get(),\n",
    "#                    DrawFrame=DRAW_FRAME,\n",
    "#                    **kwargs\n",
    "#                   )\n",
    "\n",
    "#     def Scatter(self,shift=False,nevery=1,**kwargs):\n",
    "#         kb_inv=8.61732814974056e05\n",
    "        \n",
    "#         self.ax = utl.PltErr(None,#ans[:,0],\n",
    "#                         None,#1e8*ans[:,0],\n",
    "#                         attrs={'fmt':'-.r'},Plot=False)\n",
    "#         symbols=Symbols(markersizes=np.array([10,10,10,12,12,12,10])*8)\n",
    "#         legends = Legends()\n",
    "#         legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs #plotAttrs\n",
    "#                     else (1.0,0.5,0.5,0.5))\n",
    "\n",
    "#         #\n",
    "#         column_energy = 0\n",
    "#         column_time = 3\n",
    "#         kount = 0\n",
    "#         for indx in range(0,len(self.temps),nevery):\n",
    "#             temp = self.temps[indx]\n",
    "#             #--- concat. data for each temp            \n",
    "#             data_energy = np.concatenate(list(map(lambda x: self.GetEnergy(self.data[x][:,column_energy]),\n",
    "#                                                   range(kount,kount+self.nrun))))\n",
    "#             #--- wait_times\n",
    "#             data = self.data[indx:indx+self.nrun]\n",
    "#             data_waitTimes = np.concatenate(list(map(lambda x: self.GetWaitTimes(self.data[x][:,column_time]),\n",
    "#                                                      range(kount,kount+self.nrun))))\n",
    "\n",
    "#             if self.verbose:\n",
    "#                 print('data_energy.shape (per temperature):',np.array(data_energy).shape)\n",
    "#                 print('data_waitTimes.shape (per temperature):',np.array(data_waitTimes).shape)\n",
    "#             #--- plot scatter\n",
    "#             scale = 1e2 ** indx if shift else 1\n",
    "#             filtr = data_waitTimes > 0\n",
    "# #             utl.PltErr(data_energy[filtr]*kb_inv/temp,scale*data_waitTimes[filtr],\n",
    "# #                         attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp,fmt='.',alpha=1.0),\n",
    "# #                         ax = self.ax,\n",
    "# #                         Plot=False,\n",
    "# #                         )\n",
    "#             self.ax.scatter(data_energy[filtr]*kb_inv/temp,scale*data_waitTimes[filtr],\n",
    "#                         **symbols.GetAttrsScatter(count=indx%7,label=r'$%s$'%temp,fmt='.',alpha=0.1/2),\n",
    "#                        )\n",
    "#             kount += self.nrun\n",
    "#             #--- plot average\n",
    "# #             nbins = 8\n",
    "# #             count, _=np.histogram(data_energy[filtr],bins=nbins)\n",
    "# #             xsum, _=np.histogram(data_energy[filtr],weights=data_energy[filtr],bins=nbins)\n",
    "# #             ysum, _=np.histogram(data_energy[filtr],weights=data_waitTimes[filtr],bins=nbins)\n",
    "# #             ysum /= count\n",
    "# # #            ysum =10 ** ysum \n",
    "# #             xsum /= count\n",
    "# #             #---\n",
    "# #             utl.PltErr(xsum,ysum,\n",
    "# #                         attrs=symbols.GetAttrs(count=(indx)%7,label=r'$%s$'%temp,fmt='.'),\n",
    "# #                         ax = self.ax,\n",
    "# #                         Plot=False,\n",
    "# #                         )\n",
    "        \n",
    "        \n",
    "#         utl.PltErr(None,\n",
    "#                    None,\n",
    "#                    ax=self.ax,\n",
    "#                    Plot=False,\n",
    "# #                     legend=legends.Get(),\n",
    "#                    DrawFrame=DRAW_FRAME,\n",
    "#                    **kwargs\n",
    "#                   )\n",
    "\n",
    "#     def GetEnergy(self,slist):\n",
    "#         n=len(slist)\n",
    "#         return slist[1:n:2]\n",
    "            \n",
    "# if not eval(confParser['flags']['RemoteMachine']):\n",
    "#     !mkdir png\n",
    "    \n",
    "#     stats = EnergyStats(\n",
    "#         [1000,1200,1400,1600,1800,2000],8,\n",
    "# #        [1000,1400,1800,2000],8,\n",
    "# #        [1000, 1400,1800],8,\n",
    "#         #        np.arange(1000,1440,40),1,\n",
    "# #        verbose=True\n",
    "#                      )\n",
    "# #    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "#     stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "# #    stats.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "#                          stats.temps_runs ))\n",
    "#                )\n",
    "#     stats.PlotPdf(shift=True,n_per_decade=10,\n",
    "#                         **{'xscale':'log',\n",
    "#                   'yscale':'log',\n",
    "# #                   'xlim':(1e-3,1e0),\n",
    "# #                   'ylim':(1e-2,1e2), #(1e-5,1e2),\n",
    "# #                           'xstr':r'$\\Delta t$',\n",
    "# #                           'ystr':r'$P(\\Delta t)$',\n",
    "#                         'ndecade_y':2,\n",
    "#                    'title':'png/BarrierPdf_cantor.png'},\n",
    "\n",
    "#                        )\n",
    "    \n",
    "# #     stats.PlotPdfConcat(scale=False,\n",
    "# #                         splitByType = False,\n",
    "# #                         **{'xscale':'log',\n",
    "# #                       'yscale':'log',\n",
    "# #     #                   'xlim':(1e-3,1e0),\n",
    "# # #                        'ylim':(1e-2,1e2), #(1e-5,1e2),\n",
    "# #     #                           'xstr':r'$\\Delta t$',\n",
    "# #     #                           'ystr':r'$P(\\Delta t)$',\n",
    "# #     #                        'ndecade_x':2,'ndecade_y':2,\n",
    "# #     #                   'title':'png/BarrierPdf_cantor.png'\n",
    "# #                           },\n",
    "# #                        )\n",
    "\n",
    "#     stats.Scatter(nevery=2, shift = True,                        \n",
    "#                 **{'xscale':'linear',\n",
    "#                   'yscale':'log',\n",
    "# #                   'xlim':(1e-3,1),\n",
    "# #                   'ylim':(1e-3,1e1), #(1e-5,1e2),\n",
    "# #                           'xstr':r'$\\Delta t$',\n",
    "# #                           'ystr':r'$P(\\Delta t)$',\n",
    "# #                     'bbox_to_anchor':(0.56,0.27,0.5,0.5),\n",
    "#                         'ndecade_y':2,\n",
    "#                    'title':'png/twVsEnergy_nicocr.png',\n",
    "#                   }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    \n",
    "    stats = EnergyStats(\n",
    "#        [1000,1200,1400,1600,1800,2000],[list(range(8))]*10,\n",
    "        [1000],[list(range(8))]*10,\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "    stats.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "                         stats.temps_runs ))\n",
    "               )\n",
    "    stats.PlotPdf(shift=False,column_energy=3,\n",
    "                  linscale=True, n_per_decade = 32,\n",
    "                        **{'xscale':'linear',\n",
    "                  'yscale':'log',\n",
    "                   'xlim':(0,4.8),\n",
    "                    'ylim':(1e-4,1e1), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "#                         'ndecade_x':1,'ndecade_y':2,\n",
    "                    'bbox_to_anchor':(0.4,0.13,0.5,0.5),\n",
    "                   'title':'png/BarrierPdf_nicocr.png'},\n",
    "\n",
    "                       )\n",
    "\n",
    "#     stats.PlotPdfConcat(scale=True, \n",
    "#                         column_energy=3,\n",
    "#                         splitByType = False,\n",
    "#                         n_per_decade=10,\n",
    "#                         **{'xscale':'log',\n",
    "#                   'yscale':'log',\n",
    "# #                   'xlim':(1e-3,1e-1),\n",
    "# #                   'ylim':(1e-2,1e0), #(1e-5,1e2),\n",
    "# #                           'xstr':r'$\\Delta t$',\n",
    "# #                           'ystr':r'$P(\\Delta t)$',\n",
    "# #                        'ndecade_x':2,'ndecade_y':2,\n",
    "# #                   'title':'png/BarrierPdf_cantor.png'\n",
    "#                           },\n",
    "\n",
    "#                        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    \n",
    "    stats = EnergyStats(\n",
    "        [2000],8,\n",
    "#        [2000],8,\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "                         stats.temps_runs ))\n",
    "               )\n",
    "    print(stats.data[0][:,3].mean())\n",
    "    stats.PlotPdf(shift=True,column_energy=3,\n",
    "                        **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "#                   'xlim':(1e-3,1e-1),\n",
    "#                    'ylim':(1e-2,1e0), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "                        'ndecade_x':1,'ndecade_y':2,\n",
    "                    'bbox_to_anchor':(0.4,0.13,0.5,0.5),\n",
    "                   'title':'png/BarrierPdf_nicocr.png'},\n",
    "\n",
    "                       )\n",
    "\n",
    "#     stats.PlotPdfConcat(scale=True, \n",
    "#                         column_energy=3,\n",
    "#                         splitByType = False,\n",
    "#                         n_per_decade=10,\n",
    "#                         **{'xscale':'log',\n",
    "#                   'yscale':'log',\n",
    "# #                   'xlim':(1e-3,1e-1),\n",
    "# #                   'ylim':(1e-2,1e0), #(1e-5,1e2),\n",
    "# #                           'xstr':r'$\\Delta t$',\n",
    "# #                           'ystr':r'$P(\\Delta t)$',\n",
    "# #                        'ndecade_x':2,'ndecade_y':2,\n",
    "# #                   'title':'png/BarrierPdf_cantor.png'\n",
    "#                           },\n",
    "\n",
    "#                        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kb=8.61732814974056e-05\n",
    "\n",
    "# 0.9/1650/kb,1.0/2100/kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    #alpha=-0.4\n",
    "\n",
    "    Emin=1e-2\n",
    "    Emax=1e1\n",
    "    n=100000\n",
    "    for alpha in [-1]:\n",
    "        xmax=1/Emin**alpha\n",
    "        xmin=1/Emax**alpha\n",
    "        x=np.random.uniform(low=xmin,high=xmax,size=n)\n",
    "        #E=np.exp(-E)\n",
    "        E=x**-(1/alpha)\n",
    "        hist, edge,err = utl.GetPDF(E,n_per_decade=4)\n",
    "        ax=utl.PltErr(edge,hist,yerr=err,\n",
    "                   yscale='log',xscale='log',Plot=False,\n",
    "                  )\n",
    "\n",
    "        utl.PltErr(edge,1/edge**(1+alpha),yerr=err,attrs={'fmt':'-.r'},\n",
    "                   yscale='log',xscale='log',\n",
    "                   ax=ax\n",
    "                  )\n",
    "\n",
    "        #\n",
    "        lambdaa=np.exp(-E)\n",
    "        lambdaa = lambdaa[lambdaa>0]\n",
    "        hist, edge,err = utl.GetPDF(lambdaa,n_per_decade=32)\n",
    "        utl.PltErr(edge,hist,yerr=err,\n",
    "                   yscale='log',xscale='log',\n",
    "                   xlim=(1e-10,1),\n",
    "                  )\n",
    "\n",
    "        sarr = np.c_[list(map(lambda x:np.random.exponential(1/x,size=1),lambdaa))].flatten()\n",
    "        hist, edge,err = utl.GetPDF(sarr,n_per_decade=4)\n",
    "        ax=utl.PltErr(edge,hist*edge**0,yerr=err*edge**0,\n",
    "                   yscale='log',xscale='log',\n",
    "                      Plot=False\n",
    "                  )\n",
    "        utl.PltErr(edge,1/edge**(1.5+alpha),attrs={'fmt':'-.r'},\n",
    "                   yscale='log',xscale='log',\n",
    "                   ax=ax\n",
    "                  )\n",
    "        beta=fit(edge,hist,err)\n",
    "        print(beta)\n",
    "        plt.scatter(alpha,beta)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x,beta,k,x0,x1):\n",
    "#    return k/(1+(x/x0)**beta)\n",
    "    return k*np.exp(-x/x1)/(1+(x/x0)**beta)\n",
    "    \n",
    "def fit(edge,hist,err):\n",
    "    xdata=edge\n",
    "    ydata=hist\n",
    "    yerr=err\n",
    "    popt, pcov = curve_fit(func,xdata,ydata,\n",
    "                          p0=(2,1,10,1e3),\n",
    "                           sigma=yerr,\n",
    "                          )\n",
    "\n",
    "    ax=utl.PltErr(edge,hist,yerr=err,\n",
    "               yscale='log',xscale='log',\n",
    "                  Plot=False\n",
    "              )\n",
    "    utl.PltErr(edge,func(edge,*popt),attrs={'fmt':'-.r'},\n",
    "               yscale='log',xscale='log',\n",
    "               ax=ax,\n",
    "               ndecade_x=4,\n",
    "              )\n",
    "    assert popt[-1]>0\n",
    "    return popt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kbt=1000*8.61732814974056e-05\n",
    "# E=5e-2\n",
    "# print('%e'%(1.0/(1e-13*np.exp(E/kbt))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    \n",
    "    stats = EnergyStats(\n",
    "#         [1000,1200,1400,1600,1800,2000],[list(range(8))]*10,\n",
    "        [0],[list(range(8))]\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "    stats.Parse( list(map(lambda x:'barrier/ni/kmc/void_2d/Run%s/msd/eventID_barrier_catalog_type1.txt'%(x[1]),\n",
    "                         stats.temps_runs ))\n",
    "               )\n",
    "\n",
    "    stats.PlotPdf( \n",
    "                        column_energy=2,\n",
    "                        splitByType = False,\n",
    "                        n_per_decade = 16,\n",
    "                        **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "                   'xlim':(1e-1,1e1),\n",
    "#                   'ylim':(1e-3,1e2), #(1e-5,1e2),\n",
    "                           'xstr':r'$\\Delta E$',\n",
    "                           'ystr':r'$P(\\Delta E)$',\n",
    "#                        'ndecade_x':2,'ndecade_y':2,\n",
    "                   'title':'png/BarrierPdf_cantor.png'\n",
    "                          },\n",
    "\n",
    "                       )\n",
    "\n",
    "    \n",
    "\n",
    "#     stats.Scatter(nevery=2,                        \n",
    "#                 **{'xscale':'linear',\n",
    "#                   'yscale':'log',\n",
    "#                    'xlim':(0,1),\n",
    "# #                   'ylim':(1e-3,1e1), #(1e-5,1e2),\n",
    "# #                           'xstr':r'$\\Delta t$',\n",
    "# #                           'ystr':r'$P(\\Delta t)$',\n",
    "#                         'ndecade_y':2,\n",
    "#                    'title':'png/twVsEnergy_cantor.png',\n",
    "#                   }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    pref = 1e6\n",
    "    \n",
    "    temp = Temperature(\n",
    "        [1000],[[7]],\n",
    "#        verbose=True\n",
    "                     )\n",
    "    #--- parse data\n",
    "#    temp.Parse(['./msd/msd.txt'])\n",
    "    temp.Parse( list(map(lambda x:'sro/cantor/kmc/cantorNatom1KTemp%sK/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "                        temp.temps_runs ))\n",
    "              )\n",
    "\n",
    "#     temp.EnsAverage(n_bins_per_decade=100000,\n",
    "#                     col_x = 3, col_y = 1,\n",
    "#                     n_thresh=0,\n",
    "#                    )\n",
    "    \n",
    "    symbols = Symbols()\n",
    "    legend=Legends()\n",
    "    legend.Set(bbox_to_anchor=(0.92,0.48,0.5,0.5),labelspacing=.4)\n",
    "\n",
    "    count = 0\n",
    "#     ax = utl.PltErr(None,None,Plot=False)\n",
    "    for irun in temp.nrun[0]:\n",
    "        xdata=temp.data[count][::2,3]\n",
    "        ydata=temp.data[count][::2,1]\n",
    "\n",
    "#         utl.PltErr(xdata, ydata,\n",
    "#                   attrs={'fmt':'-'},\n",
    "#                    ax=ax,\n",
    "#                    Plot=False,\n",
    "#     #                xscale='log' ,\n",
    "# #                      ylim=(-6000,-5900),\n",
    "#                   )\n",
    "        count += 1\n",
    "        \n",
    "    \n",
    "#     timesteps = temp.data_averaged[1000][:,0]\n",
    "#     wc = temp.data_averaged[1000][:,1]\n",
    "#     yerr = temp.data_averaged[1000][:,2]\n",
    "\n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "    utl.PltErr(pref*xdata,ydata,#yerr=yerr,\n",
    "                 ylim=[(-5538,-5530),(-6000,-5920)][0],\n",
    "#                xlim=(0,0.1),\n",
    "                Plot=False,\n",
    "                ax=ax,\n",
    "                attrs={'fmt':'-','color':'C0'},#symbols.GetAttrs(count=0,nevery=8),\n",
    "               title='png/energy_timeseries_cantor.png',\n",
    "                 DrawFrame=DRAW_FRAME,\n",
    "               fontsize=16,\n",
    "             )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SroAnalysis:\n",
    "    \n",
    "    def __init__(self, lmpData, nevery=1, verbose = False ):\n",
    "        !mkdir sroAnalysis\n",
    "        self.lmpData = lmpData\n",
    "        self.verbose = verbose\n",
    "        self.timesteps = list(lmpData.coord_atoms_broken.keys())[::nevery]\n",
    "        self.timesteps.sort()\n",
    "        self.times = list(lmpData.headers['Time'])[::nevery]\n",
    "        self.times.sort()\n",
    "\n",
    "\n",
    "    \n",
    "    def GetNeighList(self):\n",
    "        itime0 = self.timesteps[0]\n",
    "        natoms = min(self.lmpData.coord_atoms_broken[itime0].shape[0],\\\n",
    "                     eval(confParser['SroAnalysis']['natom'])) #--- subset of atoms\n",
    "        atom_indices = range(natoms)\n",
    "        np.savetxt('atom_indices.txt',atom_indices,fmt='%d')\n",
    "        #\n",
    "        cutoff = eval(confParser['SroAnalysis']['cutoff'])\n",
    "        !rm sroAnalysis/neighList.xyz\n",
    "#         path = confParser['input files']['path']\n",
    "#         indx = confParser['input files']['fileIndex']\n",
    "        py_path=confParser['input files']['lib_path']\n",
    "        fileName = 'dumpFile/dump.xyz'\n",
    "        nevery = int(confParser['SroAnalysis']['nevery'])\n",
    "        if self.verbose:\n",
    "            print('get neighbor list ...')     \n",
    "        t0=time.time()\n",
    "        !ovitos $py_path/OvitosCna.py $fileName neighList.xyz $nevery 4 $cutoff atom_indices.txt\n",
    "        if self.verbose:\n",
    "            print('output neighbor list=%s s'%(time.time()-t0))     \n",
    "            \n",
    "        t0=time.time()\n",
    "        self.lmpNeigh = lp.ReadDumpFile( 'neighList.xyz' )\n",
    "        self.lmpNeigh.GetCords( ncount = sys.maxsize)\n",
    "        \n",
    "        #--- update timesteps\n",
    "        self.timesteps = list(self.lmpNeigh.coord_atoms_broken.keys())\n",
    "        self.timesteps.sort()\n",
    "        \n",
    "        #--- clean\n",
    "        !rm neighList.xyz atom_indices.txt\n",
    "\n",
    "        if self.verbose:\n",
    "            print('load neighbor list=%s s'%(time.time()-t0))\n",
    "            print('times=',self.timesteps)\n",
    "            display(self.lmpNeigh.coord_atoms_broken[self.timesteps[0]].head())\n",
    "            \n",
    "\n",
    "        \n",
    "    def WarrenCowleyOrderParameter(self, itime, **kwargs):        \n",
    "        box = lp.Box( BoxBounds = self.lmpData.BoxBounds[itime], AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "        atoms = lp.Atoms( **self.lmpData.coord_atoms_broken[itime].to_dict(orient='series') )\n",
    "        #--- neighbor list\n",
    "        neigh = self.lmpNeigh.coord_atoms_broken[itime]\n",
    "        \n",
    "        #--- radial dist. function\n",
    "        cutoff = eval(confParser['SroAnalysis']['cutoff'])\n",
    "        rdf = lp.ComputeRdf(  atoms, box )\n",
    "        bins = self.GetValleys(itime) if 'bins' not in kwargs else kwargs['bins']\n",
    "        rdf.PairCrltn(  \n",
    "                  bins=bins, \n",
    "                  rlist=neigh.DIST )\n",
    "        \n",
    "        types = list(set(self.lmpData.coord_atoms_broken[0].type))\n",
    "        sro = {}\n",
    "        count = 0\n",
    "        for pairi in types:\n",
    "            for pairj in types:\n",
    "                if pairi > pairj:\n",
    "                    continue\n",
    "                sro[count] = rdf.Sro(neigh,pairi,pairj,bins=bins)\n",
    "                count += 1\n",
    "        return sro\n",
    "\n",
    "    def MultiTimes(self,**kwargs):\n",
    "        bins = kwargs['bins'] if 'bins' in kwargs else self.GetValleys(self.timesteps[0])\n",
    "        self.data =list(map(lambda x:self.WarrenCowleyOrderParameter(x,bins=bins),self.timesteps))\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def quadratic_spline_roots(spl):\n",
    "        roots = []\n",
    "        knots = spl.get_knots()\n",
    "        for a, b in zip(knots[:-1], knots[1:]):\n",
    "            u, v, w = spl(a), spl((a+b)/2), spl(b)\n",
    "            t = np.roots([u+w-2*v, w-u, 2*v])\n",
    "            t = t[np.isreal(t) & (np.abs(t) <= 1)]\n",
    "            roots.extend(t*(b-a)/2 + (b+a)/2)\n",
    "        return np.array(roots)\n",
    "\n",
    "    @staticmethod\n",
    "    def GetExtrema(bin_edges1,hist1,r0,verbose=True):\n",
    "        y_axis=hist1\n",
    "        x_axis=bin_edges1\n",
    "        f = InterpolatedUnivariateSpline(x_axis, y_axis, k=4)\n",
    "\n",
    "        ext=f.derivative().roots() #--- roots\n",
    "        spl_dd=f.derivative().derivative()\n",
    "        valleys=ext[np.all([spl_dd(ext)>0,ext>r0],axis=0)]\n",
    "        peaks=ext[np.all([spl_dd(ext)<0,ext>r0],axis=0)]\n",
    "\n",
    "        if len(valleys) == 0:\n",
    "            cutoff = eval(confParser['SroAnalysis']['cutoff'])\n",
    "            valleys = [cutoff]\n",
    "\n",
    "        rpeak   = peaks[0]\n",
    "        rvalley = valleys[0]\n",
    "        if rvalley > rpeak:\n",
    "            valleys = np.concatenate([np.array([0]),valleys])\n",
    "#         if verbose:\n",
    "#             print('peaks of g(r) at:r=',peaks)\n",
    "#             print('valleys of g(r) at:r=',valleys)\n",
    "\n",
    "        return x_axis, f, valleys\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def GetValleys(self,itime):\n",
    "        bin_edges, hist,_  = self.PairCrltnFunction(itime)\n",
    "        self.bin_edges, self.hist,_  = self.PairCrltnFunction(itime)\n",
    "        x_axis, f, valleys = SroAnalysis.GetExtrema(bin_edges,hist,1.0)\n",
    "        #--- remove valleys that are too close!\n",
    "        filtr = np.diff(valleys,prepend=valleys[-1]) >0.25\n",
    "        valleys = np.append(0,valleys[filtr])\n",
    "        return valleys\n",
    "        \n",
    "    def PairCrltnFunction(self,itime):\n",
    "        box = lp.Box( BoxBounds = self.lmpData.BoxBounds[itime], AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "        atoms = lp.Atoms( **self.lmpData.coord_atoms_broken[itime].to_dict(orient='series') )\n",
    "        neigh = self.lmpNeigh.coord_atoms_broken[itime]\n",
    "\n",
    "\n",
    "        cutoff = eval(confParser['SroAnalysis']['cutoff'])\n",
    "        rdf = lp.ComputeRdf(  atoms, box )\n",
    "        rdf.PairCrltn(  \n",
    "                      bins=np.arange(0.99*neigh.DIST.min(),cutoff,0.01), \n",
    "                      rlist=neigh.DIST,\n",
    "                      regular_r = True,\n",
    "                      )\n",
    "        return rdf.Get()\n",
    "\n",
    "    @staticmethod\n",
    "    def Reshape(sdict):\n",
    "        keys = list(sdict.keys())\n",
    "        keys.sort()\n",
    "        concat = list(map(lambda x:list(np.concatenate([sdict[x][0],sdict[x][1],sdict[x][2]])),keys))\n",
    "        size = (3,len(sdict[keys[0]][0]))\n",
    "        return dict(zip(keys,concat)), size\n",
    "    \n",
    "                \n",
    "    def Print( self, fp ):\n",
    "        rwj = utl.ReadWriteJson()\n",
    "        rwj.Write(self.data, fp,\n",
    "                  timestep=self.timesteps,\n",
    "                  time=self.times\n",
    "                 # junk=sro.timesteps\n",
    "                 )\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['SroAnalysis']['SroAnalysis']):\n",
    "    sro = SroAnalysis( data.lmpData,\n",
    "                       nevery=eval(confParser['SroAnalysis']['nevery']),\n",
    "                        verbose = True,\n",
    "                     )\n",
    "    sro.GetNeighList()\n",
    "#    sro.WarrenCowleyOrderParameter(sro.timesteps[0])\n",
    "    sro.MultiTimes(\n",
    "                    bins=np.array(confParser['SroAnalysis']['sroBins'].split()).astype(float)\n",
    "                  )\n",
    "    sro.Print('sroAnalysis/sro.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not eval(confParser['flags']['RemoteMachine']):\n",
    "\n",
    "#     path = {0:'sro/CantorNatom16KTemp1000KEnsemble8',\n",
    "#             1:'sro/NiCoCrNatom1KTemp1000K',\n",
    "#            }[1]\n",
    "#     rwj = utl.ReadWriteJson()\n",
    "#     data = rwj.Read('%s/Run0/sroAnalysis/sro.json'%path)\n",
    "#     #\n",
    "#     pairIndx = '0'\n",
    "#     rss = 0.20\n",
    "#     #\n",
    "#     symbols = Symbols()\n",
    "# #    ax = utl.PltErr(None,None,Plot=False)\n",
    "#     for items in data:\n",
    "#         timestep = items['timestep']\n",
    "#         bin_edges, wc, err = items[pairIndx]\n",
    "\n",
    "    \n",
    "#     for pairIndx in range(6):\n",
    "#         ax = utl.PltErr(None,None,Plot=False)\n",
    "\n",
    "#         bin_edges, wc, err = items[str(pairIndx)]\n",
    "#         utl.PltErr(bin_edges,wc,yerr=2*np.array(err),\n",
    "#                     Plot=False,\n",
    "#                     ax=ax,\n",
    "#                     attrs=symbols.GetAttrs(count=0,zorder=2),      \n",
    "#                   )\n",
    "\n",
    "\n",
    "#         cutoff = 20.0 #eval(confParser['SroAnalysis']['cutoff'])\n",
    "#         utl.PltErr([0,cutoff],[rss,rss],\n",
    "#                     xlim=[0.0,cutoff],\n",
    "#     #                ylim=[0.1,.7],\n",
    "#                     ax=ax,\n",
    "#                     attrs={'fmt':'-.r'},\n",
    "#                     title='png/wc_nicocr_indx%s.png'%(pairIndx),\n",
    "#                     DrawFrame=DRAW_FRAME,\n",
    "#                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "\n",
    "    path = {0:'sro/CantorNatom16KTemp1000KEnsemble8',\n",
    "            1:'sro/NiCoCrNatom1KTemp1000K',\n",
    "            2:'sro/nicocr/kmc/NiCoCrNatom1KTemp1000K',\n",
    "            3:'.'\n",
    "           }[2]\n",
    "    alloy = 'nicocr'\n",
    "    runs = range(8) #[7] #range(8)\n",
    "    rss = 0.33 #0.2 #0.33\n",
    "    every_nrow = 1 #--- don't change\n",
    "    inn = 2 #--- 1st nearest neighbor\n",
    "    nneighbors = 3 #--- len(sroBins)-1\n",
    "    \n",
    "    indices = {'nicocr':'0 1 2 3 4 5'.split(),\n",
    "               'cantor':' '.join(list(map(str,range(15)))).split()}[alloy]\n",
    "    pairs = {'nicocr':'NiNi NiCo NiCr CoCo CoCr CrCr'.split(),\n",
    "              'cantor':' '.join(list(map(str,range(15)))).split()\n",
    "            }[alloy]\n",
    "    \n",
    "    rwj = utl.ReadWriteJson()\n",
    "    for irun in runs:\n",
    "        data = rwj.Read('%s/Run%s/sroAnalysis/sro.json'%(path,irun))\n",
    "        #\n",
    "        #--- parse\n",
    "        symbols = Symbols()\n",
    "        legend=Legends()\n",
    "        legend.Set(bbox_to_anchor=(0.92,0.48,0.5,0.5),labelspacing=.4)\n",
    "        ax = utl.PltErr(None,None,Plot=False)\n",
    "        for pairIndx, label in zip(indices,pairs):\n",
    "            sro_data = np.concatenate([list(map(lambda x:\n",
    "                                 np.concatenate([np.array([x['time']]),np.array(x[pairIndx]).flatten()]),\n",
    "                                 data))])\n",
    "            timesteps = sro_data[::every_nrow,0]\n",
    "            r = sro_data[::every_nrow,1:1+nneighbors]\n",
    "            wc = sro_data[::every_nrow,1+nneighbors:1+2*nneighbors]/rss-1.0\n",
    "            err = sro_data[::every_nrow,1+2*nneighbors:1+3*nneighbors]\n",
    "\n",
    "\n",
    "            #--- output\n",
    "            np.savetxt('sro/sro_irun%s_indx%s_nn%s.txt'%(irun,pairIndx,inn),np.c_[timesteps,wc[:,inn],err[:,inn]])\n",
    "\n",
    "            utl.PltErr(timesteps,-wc[:,inn],yerr=err[:,inn],\n",
    "                        Plot=False,\n",
    "                        ax=ax,\n",
    "                        attrs=symbols.GetAttrs(count=int(pairIndx)%7,zorder=2,nevery=1280,label=r'$\\mathrm{%s}$'%label),      \n",
    "                      )\n",
    "\n",
    "\n",
    "        utl.PltErr([0,timesteps[-1]],[0,0],\n",
    "                    ax=ax,\n",
    "                    attrs={'fmt':'-.r'},\n",
    "                    legend=legend.Get(),\n",
    "#                     title='png/wc_time_nicocr_nn%s.png'%inn,\n",
    "                    DrawFrame=DRAW_FRAME,\n",
    "                   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    pref = 1e6\n",
    "    indices = {'nicocr':'0 1 2 3 4 5'.split(),\n",
    "               'cantor':'0 5 9 12 14'.split()}[alloy]\n",
    "    pairs = {'nicocr':'NiNi NiCo NiCr CoCo CoCr CrCr'.split(),\n",
    "              'cantor':'NiNi CoCo CrCr FeFe MnMn '.split()\n",
    "            }[alloy]\n",
    "\n",
    "    \n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "    legend=Legends()\n",
    "    legend.Set(bbox_to_anchor=(-0.02,0.52,0.5,0.5),\n",
    "                 labelspacing=.2,\n",
    "                    fontsize=12,\n",
    "              )\n",
    "    count = 0\n",
    "    for sro_indx, label in zip(indices,pairs):\n",
    "        temp_vac = Temperature(\n",
    "                [int(sro_indx)],[runs],\n",
    "        #         verbose = True,\n",
    "                         )\n",
    "        #--- parse data\n",
    "        temp_vac.Parse( list(map(lambda x:'sro/sro_irun%s_indx%s_nn%s.txt'%(x[1],x[0],inn),\n",
    "                              temp_vac.temps_runs ))\n",
    "                  )\n",
    "\n",
    "        temp_vac.EnsAverage(n_bins_per_decade=32)\n",
    "\n",
    "\n",
    "        timesteps = temp_vac.data_averaged[int(sro_indx)][:,0]\n",
    "        wc = temp_vac.data_averaged[int(sro_indx)][:,1]\n",
    "        yerr = temp_vac.data_averaged[int(sro_indx)][:,2]\n",
    "\n",
    "        utl.PltErr(pref*timesteps,-wc,#yerr=yerr,\n",
    "                    Plot=False,\n",
    "                    ax=ax,\n",
    "                    attrs=symbols.GetAttrs(count=count%7,zorder=2,nevery=4,label=r'$\\mathrm{%s}$'%label),      \n",
    "                  )\n",
    "        count += 1\n",
    "\n",
    "    utl.PltErr([0,pref*timesteps[-1]],[0,0],\n",
    "#                        xlim=[0.0,0.1],\n",
    "                    ylim=[-0.3,0.3],\n",
    "                ax=ax,\n",
    "                attrs={'fmt':'-.r','color':'C0'},\n",
    "                  legend=legend.Get(),\n",
    "                title='png/wc_time_cantor_inn%s.png'%inn,\n",
    "                DrawFrame=DRAW_FRAME,\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnnEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "259.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
