{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parsing configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "confParser = configparser.ConfigParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf. file sections: ['parameters', 'flags', 'input files', 'Atomic Radius']\n"
     ]
    }
   ],
   "source": [
    "#--- parse conf. file\n",
    "confParser.read('configuration.ini')\n",
    "print('conf. file sections:',confParser.sections())\n",
    "\n",
    "#--- set dynamic parameters\n",
    "temp=confParser['parameters']['temperature']\n",
    "\n",
    "#--- edit list of input files\n",
    "confParser.set('input files','dump file',''.join([\n",
    "               'allconf ', #0\n",
    "              ]))\n",
    "confParser.set('input files','diffusion file',''.join([\n",
    "               'Diffusion.dat ', #0\n",
    "              ]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utilityy' from '../../HeaDef/postprocess/utilityy.py'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(confParser['input files']['lib_path'])\n",
    "\n",
    "#--- system libraries\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "import traceback\n",
    "import os\n",
    "import scipy.interpolate as scp_int\n",
    "import warnings\n",
    "import matplotlib\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "from matplotlib import patches\n",
    "import sys\n",
    "import sklearn\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "import patsy\n",
    "from sklearn import linear_model, mixture\n",
    "import sklearn.mixture as skm\n",
    "from scipy import optimize\n",
    "import scipy\n",
    "import re\n",
    "from functools import reduce\n",
    "import time\n",
    "import fnmatch\n",
    "from scipy.optimize import curve_fit\n",
    "#\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#--- user modules\n",
    "import LammpsPostProcess as lp\n",
    "import LammpsPostProcess2nd as lpp\n",
    "import utilityy as utll\n",
    "import utility as utl\n",
    "from utility import *\n",
    "import imp\n",
    "imp.reload(lp)\n",
    "imp.reload(lpp)\n",
    "imp.reload(utl)\n",
    "imp.reload(utll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Symbols:\n",
    "    def __init__(self,\n",
    "                markersizes=[10,10,10,12,12,12,10],\n",
    "                ):\n",
    "        self.colors = ['black','red','green','blue','cyan','brown','grey','magenta','orange','yellow']\n",
    "        self.fillstyles=['white',None,'white',None,'white',None,'white',None,'white',None,'white',None,'white',None,'white',None]\n",
    "        self.markers=['o','s','D','^','<','>','v']\n",
    "        self.markersizes=markersizes\n",
    "        self.nmax=7\n",
    "        \n",
    "    def GetAttrs(self,count=0,label='',nevery=1,fmt='.-',zorder=1,alpha=1):\n",
    "        if count > self.nmax:\n",
    "            print('index out of list bound!')\n",
    "            return \n",
    "        attrs={ 'color':self.colors[count],\n",
    "            'markersize':self.markersizes[count],\n",
    "            'marker':self.markers[count],\n",
    "            'markerfacecolor':self.colors[count],\n",
    "            'markeredgecolor':'white', #'black' if not self.fillstyles[count] else None,\n",
    "            'label':label,\n",
    "           'markevery':nevery,\n",
    "           'errorevery':nevery,\n",
    "           'markeredgewidth':1.75,\n",
    "            'linewidth':1, \n",
    "           'barsabove':None,\n",
    "           'capsize':5,\n",
    "           'capthick':1,\n",
    "           'elinewidth':1,\n",
    "           'fmt':fmt,\n",
    "             'zorder':zorder,\n",
    "               'alpha':alpha\n",
    "         }\n",
    "        return attrs\n",
    "    \n",
    "    def GetAttrs2nd(self,count=0,label='',nevery=1,fmt='.-',zorder=1):\n",
    "        '''\n",
    "        empty symbols\n",
    "        '''\n",
    "        if count > self.nmax:\n",
    "            print('index out of list bound!')\n",
    "            return \n",
    "        attrs={ 'color':self.colors[count],\n",
    "            'markersize':self.markersizes[count],\n",
    "            'marker':self.markers[count],\n",
    "            'markerfacecolor':'white',\n",
    "#            'markeredgecolor':'black' if not self.fillstyles[count] else None,\n",
    "            'label':label,\n",
    "           'markevery':nevery,\n",
    "           'errorevery':nevery,\n",
    "           'markeredgewidth':1.75,\n",
    "            'linewidth':1, \n",
    "           'barsabove':None,\n",
    "           'capsize':5,\n",
    "           'capthick':1,\n",
    "           'elinewidth':1,\n",
    "           'fmt':fmt,\n",
    "            'zorder':zorder,\n",
    "          }\n",
    "        return attrs\n",
    "\n",
    "    def GetAttrsScatter(self,count=0,label='',nevery=1,fmt='.-',zorder=1,alpha=0.5):\n",
    "        if count > self.nmax:\n",
    "            print('index out of list bound!')\n",
    "            return \n",
    "        attrs={ 'color':self.colors[count],\n",
    "            's':self.markersizes[count],\n",
    "            'marker':self.markers[count],\n",
    "#            'markerfacecolor':self.colors[count],\n",
    "            'edgecolors':'white', #'black' if not self.fillstyles[count] else None,\n",
    "            'label':label,\n",
    "#            'markevery':nevery,\n",
    "#           'errorevery':nevery,\n",
    "#            'markeredgewidth':1.75,\n",
    "            'linewidth':1, \n",
    "#            'barsabove':None,\n",
    "#            'capsize':5,\n",
    "#            'capthick':1,\n",
    "#            'elinewidth':1,\n",
    "#            'fmt':fmt,\n",
    "             'zorder':zorder,\n",
    "               'alpha':alpha\n",
    "         }\n",
    "        return attrs\n",
    "    \n",
    "    \n",
    "class Legends:\n",
    "    def __init__(self\n",
    "                ):\n",
    "        pass\n",
    "    def Set(self,fontsize=20,\n",
    "                 labelspacing=0,\n",
    "                 **kwargs\n",
    "#                 bbox_to_anchor=(0.5,0.48,0.5,0.5),\n",
    "           ):\n",
    "        self.attrs = {'frameon':False,'fontsize':fontsize,\n",
    "                   'labelspacing':labelspacing,\n",
    "                      'handletextpad':.2,\n",
    "                   'handlelength':1,\n",
    "                    **kwargs,\n",
    "                     }\n",
    "    def Get(self):\n",
    "        return self.attrs\n",
    "\n",
    "DRAW_FRAME=(0.23,0.08,0.12,0.07,0.01)\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    matplotlib.rcParams['text.usetex'] = True #--- comment tex stuff!\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Dump File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InputFile= ../simulations/NiNatom16KTemp1400K/Run0//allconf\n",
      "num_frames= 3\n",
      "frame=0\n",
      "frame=1\n",
      "frame=2\n",
      "output dump file=0.3997995853424072 s\n",
      "parsing dumpFile/dump.xyz\n",
      "reached end of file!\n",
      "time steps: dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.529185</td>\n",
       "      <td>10.993651</td>\n",
       "      <td>42.813454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30.439087</td>\n",
       "      <td>32.206852</td>\n",
       "      <td>33.974621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.206852</td>\n",
       "      <td>35.742386</td>\n",
       "      <td>49.884525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>46.348988</td>\n",
       "      <td>37.510155</td>\n",
       "      <td>51.652290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>39.277920</td>\n",
       "      <td>5.690350</td>\n",
       "      <td>41.045689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  type          x          y          z\n",
       "0   1     1  14.529185  10.993651  42.813454\n",
       "1   2     1  30.439087  32.206852  33.974621\n",
       "2   3     1  32.206852  35.742386  49.884525\n",
       "3   4     1  46.348988  37.510155  51.652290\n",
       "4   5     1  39.277920   5.690350  41.045689"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InputFile= dumpFile/dump.xyz\n",
      "num_frames= 4\n",
      "frame=0\n",
      "frame=1\n",
      "frame=2\n",
      "frame=3\n",
      "output dump file=0.5250022411346436 s\n",
      "parsing dumpFile/neighbors.xyz\n",
      "reached end of file!\n",
      "time steps: dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>StructureType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.529185</td>\n",
       "      <td>10.993651</td>\n",
       "      <td>42.813454</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30.439089</td>\n",
       "      <td>32.206852</td>\n",
       "      <td>33.974621</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.206852</td>\n",
       "      <td>35.742386</td>\n",
       "      <td>49.884525</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>46.348988</td>\n",
       "      <td>37.510155</td>\n",
       "      <td>51.652290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>39.277920</td>\n",
       "      <td>5.690350</td>\n",
       "      <td>41.045689</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  type          x          y          z  StructureType\n",
       "0   1     1  14.529185  10.993651  42.813454            1.0\n",
       "1   2     1  30.439089  32.206852  33.974621            1.0\n",
       "2   3     1  32.206852  35.742386  49.884525            1.0\n",
       "3   4     1  46.348988  37.510155  51.652290            1.0\n",
       "4   5     1  39.277920   5.690350  41.045689            1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!rm -r dumpFile;mkdir dumpFile\n",
    "\n",
    "#--- fetch parameters\n",
    "path = confParser['input files']['input_path']\n",
    "indx = confParser['input files']['fileIndex']\n",
    "dumpFile = '%s/%s'%(path,confParser['input files']['dump file'].split()[int(indx)])\n",
    "datFile = '%s/%s'%(path,confParser['input files']['diffusion file'].split()[int(indx)])\n",
    "lib_path = confParser['input files']['lib_path']\n",
    "outpt = 'dumpFile/dump.xyz'\n",
    "outpt_headers = 'dumpFile/calcResults.txt'\n",
    "\n",
    "#--- parse dump: call ovito\n",
    "t0=time.time()\n",
    "!ovitos $lib_path/OvitosCna.py $dumpFile $outpt 1 7 $outpt_headers\n",
    "print('output dump file=%s s'%(time.time()-t0))\n",
    "\n",
    "\n",
    "#--- parse dump files\n",
    "print('parsing %s'%(outpt))\n",
    "lmpData = lp.ReadDumpFile( '%s'%(outpt) ) \n",
    "lmpData.GetCords( ncount = sys.maxsize, \n",
    "                )\n",
    "print('time steps:',lmpData.coord_atoms_broken.keys())\n",
    "display(lmpData.coord_atoms_broken[0].head())\n",
    "\n",
    "#--- add timescales\n",
    "lmpData.times = np.loadtxt(datFile)[:,0]\n",
    "\n",
    "#--- parse headers\n",
    "lmpData.headers = pd.DataFrame(np.loadtxt(outpt_headers),columns=[\"Barrier\", \"Energy\", \"Step\", \"Time\"])\n",
    "\n",
    "#--- common neighbor analysis\n",
    "dumpFile = 'dumpFile/dump.xyz'\n",
    "outpt = 'dumpFile/neighbors.xyz'\n",
    "t0=time.time()\n",
    "!ovitos $lib_path/OvitosCna.py $dumpFile $outpt 1 0\n",
    "print('output dump file=%s s'%(time.time()-t0))\n",
    "\n",
    "#--- parse dump files\n",
    "print('parsing %s'%(outpt))\n",
    "lmpCna = lp.ReadDumpFile( '%s'%(outpt) ) \n",
    "lmpCna.GetCords( ncount = sys.maxsize, \n",
    "                )\n",
    "print('time steps:',lmpCna.coord_atoms_broken.keys())\n",
    "display(lmpCna.coord_atoms_broken[0].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddRndStrs(df):\n",
    "    df['sxx']=np.random.normal(size=len(df))\n",
    "    df['syy']=np.random.normal(size=len(df))\n",
    "    df['szz']=np.random.normal(size=len(df))\n",
    "\n",
    "#--- add random stress\n",
    "#list( map(lambda x:AddRndStrs(lmpData.coord_atoms_broken[x]),lmpData.coord_atoms_broken.keys()) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘disp’: File exists\n",
      "current_frames= [0 2]\n",
      "reference_frames= [0, 0]\n",
      "InputFile= disp/dump_curr.xyz\n",
      "num_frames= 1\n",
      "frame=0\n",
      "InputFile= disp/dump_curr.xyz\n",
      "num_frames= 1\n",
      "frame=0\n",
      "parsing disp/disp.xyz\n",
      "reached end of file!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>DisplacementX</th>\n",
       "      <th>DisplacementY</th>\n",
       "      <th>DisplacementZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.529185</td>\n",
       "      <td>10.993651</td>\n",
       "      <td>42.813454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30.439087</td>\n",
       "      <td>32.206852</td>\n",
       "      <td>33.974621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.206852</td>\n",
       "      <td>35.742386</td>\n",
       "      <td>49.884525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>46.348988</td>\n",
       "      <td>37.510155</td>\n",
       "      <td>51.652290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>39.277920</td>\n",
       "      <td>5.690350</td>\n",
       "      <td>41.045689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  type          x          y          z  DisplacementX  DisplacementY  \\\n",
       "0   1     1  14.529185  10.993651  42.813454            0.0            0.0   \n",
       "1   2     1  30.439087  32.206852  33.974621            0.0            0.0   \n",
       "2   3     1  32.206852  35.742386  49.884525            0.0            0.0   \n",
       "3   4     1  46.348988  37.510155  51.652290            0.0            0.0   \n",
       "4   5     1  39.277920   5.690350  41.045689            0.0            0.0   \n",
       "\n",
       "   DisplacementZ  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def WrapperDisp(lmpData,reference_frames,current_frames):\n",
    "    '''\n",
    "    invoke disp analysis in ovito\n",
    "    '''\n",
    "    #--- split dump file\n",
    "    for ii0, ii in zip(reference_frames,current_frames):\n",
    "        atom_current = lp.Atoms(**lmpData.coord_atoms_broken[ii])\n",
    "        atom_reference = lp.Atoms(**lmpData.coord_atoms_broken[ii0])\n",
    "        box  = lp.Box( BoxBounds = lmpData.BoxBounds[ii],  AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "        box0 = lp.Box( BoxBounds = lmpData.BoxBounds[ii0], AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "        lpp.WriteDumpFile(atom_current, box).Write('disp/dump_curr.xyz', itime = ii,\n",
    "                 attrs=['id', 'type','x', 'y', 'z'],\n",
    "                 fmt='%i %i %15.14e %15.14e %15.14e')\n",
    "        lpp.WriteDumpFile(atom_reference, box0).Write('disp/dump_ref.xyz', itime=ii0,\n",
    "                 attrs=['id', 'type','x', 'y', 'z'],\n",
    "                 fmt='%i %i %15.14e %15.14e %15.14e')\n",
    "    #    os.system('tar czf dump.gz dump.xyz')\n",
    "        fileCurr = 'disp/dump_curr.xyz'\n",
    "        fileRef = 'disp/dump_ref.xyz'\n",
    "        output = 'disp/disp.%s.xyz'%ii\n",
    "        #--- load to ovito\n",
    "        os.system('ovitos %s/OvitosCna.py %s %s 2 8 %s'%(lib_path,fileCurr,output,fileRef))\n",
    "        #--- concat\n",
    "        os.system('cat %s >> disp/disp.xyz;rm %s'%(output,output))\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "!mkdir disp\n",
    "\n",
    "#--- fetch parameters\n",
    "lib_path = confParser['input files']['lib_path']\n",
    "outpt = 'disp/disp.xyz'\n",
    "!rm $outpt\n",
    "\n",
    "current_frames = np.array(list(lmpData.coord_atoms_broken.keys()))[::2] #--- ignore half steps: comment if void traj. is needed\n",
    "current_frames.sort()\n",
    "print('current_frames=',current_frames)\n",
    "#--- reference\n",
    "reference_frames = [current_frames[0]]*len(current_frames)\n",
    "print('reference_frames=',reference_frames)\n",
    "    \n",
    "    \n",
    "#--- call ovito\n",
    "WrapperDisp(lmpData,reference_frames,current_frames)\n",
    "\n",
    "\n",
    "#--- parse dump files\n",
    "print('parsing %s'%(outpt))\n",
    "lmpDisp = lp.ReadDumpFile( 'disp/disp.xyz' )\n",
    "lmpDisp.GetCords( ncount = sys.maxsize )\n",
    "display(lmpDisp.coord_atoms_broken[0].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_frames= [0 2]\n",
      "reference_frames= [0 0]\n",
      "InputFile= disp/dump_curr.xyz\n",
      "num_frames= 1\n",
      "frame=0\n",
      "InputFile= disp/dump_curr.xyz\n",
      "num_frames= 1\n",
      "frame=0\n",
      "parsing disp/disp.xyz\n",
      "reached end of file!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>DisplacementX</th>\n",
       "      <th>DisplacementY</th>\n",
       "      <th>DisplacementZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.529185</td>\n",
       "      <td>10.993651</td>\n",
       "      <td>42.813454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30.439087</td>\n",
       "      <td>32.206852</td>\n",
       "      <td>33.974621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.206852</td>\n",
       "      <td>35.742386</td>\n",
       "      <td>49.884525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>46.348988</td>\n",
       "      <td>37.510155</td>\n",
       "      <td>51.652290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>39.277920</td>\n",
       "      <td>5.690350</td>\n",
       "      <td>41.045689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  type          x          y          z  DisplacementX  DisplacementY  \\\n",
       "0   1     1  14.529185  10.993651  42.813454            0.0            0.0   \n",
       "1   2     1  30.439087  32.206852  33.974621            0.0            0.0   \n",
       "2   3     1  32.206852  35.742386  49.884525            0.0            0.0   \n",
       "3   4     1  46.348988  37.510155  51.652290            0.0            0.0   \n",
       "4   5     1  39.277920   5.690350  41.045689            0.0            0.0   \n",
       "\n",
       "   DisplacementZ  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#--- refframe = current_frame - 1\n",
    "#--- reference\n",
    "!rm -r disp;mkdir disp\n",
    "print('current_frames=',current_frames)\n",
    "reference_frames = np.concatenate([[0],current_frames[:-1]])\n",
    "print('reference_frames=',reference_frames)\n",
    "    \n",
    "    \n",
    "#--- call ovito\n",
    "WrapperDisp(lmpData,reference_frames,current_frames)\n",
    "\n",
    "\n",
    "#--- parse velocity\n",
    "print('parsing %s'%(outpt))\n",
    "lmpVel = lp.ReadDumpFile( 'disp/disp.xyz' )\n",
    "lmpVel.GetCords( ncount = sys.maxsize )\n",
    "display(lmpVel.coord_atoms_broken[0].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def unwrapped(key0,key1):\n",
    "#     times = list(lmpDisp.coord_atoms_broken.keys())\n",
    "#     times.sort()\n",
    "#     x = np.concatenate([list(map(lambda x:lmpVel.coord_atoms_broken[x][key0],times))],axis=0).T\n",
    "#     x=x.cumsum(axis=1)\n",
    "#     x= (x.T + np.array(lmpVel.coord_atoms_broken[0][key1])).T\n",
    "#     return x\n",
    "\n",
    "# x=unwrapped('DisplacementX','x')\n",
    "# y=unwrapped('DisplacementY','y')\n",
    "# z=unwrapped('DisplacementZ','z')\n",
    "\n",
    "# times = list(lmpDisp.coord_atoms_broken.keys())\n",
    "# times.sort()\n",
    "# count=0\n",
    "# #xsum_concat=np.array([0,0,0])\n",
    "# for itime in times:\n",
    "#     filtr = lmpCna.coord_atoms_broken[itime]['StructureType'] == 0.0\n",
    "#     xsum = np.array([x[:,itime][filtr].mean(), y[:,itime][filtr].mean(), z[:,itime][filtr].mean()])\n",
    "#     xsum_concat = xsum.copy() if itime == 0 else np.c_[xsum_concat,xsum]\n",
    "#     count += 1\n",
    "# xsum_concat = xsum_concat.T\n",
    "# xsum_concat\n",
    "\n",
    "# !rm void.xyz\n",
    "# for itime in range(xsum_concat.shape[0]):\n",
    "#     sfile=open('void.xyz','a')\n",
    "#     utl.PrintOvito(pd.DataFrame(np.c_[xsum_concat[itime,:]].reshape(1,3),columns=['x','y','z']), \n",
    "#                    sfile, 'itime=%s'%itime, attr_list=['x', 'y', 'z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## msd vs. time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘msd’: File exists\n",
      "[0, 2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MsDisp:\n",
    "    \n",
    "    def __init__(self, lmpDisp, lmpVel, lmpCna, filtr):\n",
    "        '''\n",
    "        returns mean-squared displacements\n",
    "        '''\n",
    "        self.disp = lmpDisp.coord_atoms_broken\n",
    "        self.veloc = lmpVel.coord_atoms_broken\n",
    "        self.cna = lmpCna.coord_atoms_broken\n",
    "        \n",
    "        self.times = list(lmpDisp.coord_atoms_broken.keys())\n",
    "        self.times.sort()\n",
    "        print(self.times)\n",
    "        self.filtr=filtr\n",
    "        \n",
    "    def Get(self,LOG=False):\n",
    "        '''\n",
    "        returns msd (no temporal window)\n",
    "        '''\n",
    "        if not LOG: #---  mean\n",
    "            msd = list(map(lambda x:(self.disp[x]['DisplacementX']**2+\\\n",
    "                         self.disp[x]['DisplacementY']**2+\\\n",
    "                         self.disp[x]['DisplacementZ']**2).mean(),\n",
    "                    self.times))\n",
    "        else: #--- geometric mean\n",
    "            msd = list(map(lambda x:10**((np.log10(self.disp[x]['DisplacementX']**2+\\\n",
    "                         self.disp[x]['DisplacementY']**2+\\\n",
    "                         self.disp[x]['DisplacementZ']**2)).mean()),\n",
    "                    self.times))\n",
    "        return np.array(msd)\n",
    "        \n",
    "    def GetPdfJumps(self):\n",
    "        '''\n",
    "        pdf's of jumps\n",
    "        '''\n",
    "        for itime in self.times:\n",
    "            df=self.veloc[itime]\n",
    "            if itime == 0:\n",
    "                df_concat = np.c_[df[['DisplacementX','DisplacementY','DisplacementZ']]]\n",
    "            else:\n",
    "                df_concat = np.concatenate([df_concat,df[['DisplacementX','DisplacementY','DisplacementZ']]],axis=0) \n",
    "        df_abs = np.abs(df_concat.flatten())\n",
    "        filtr = df_abs > 0.0\n",
    "        \n",
    "        hist, bin_edges, err = utl.GetPDF(df_abs[filtr],n_per_decade=4)\n",
    "        utl.PltErr(bin_edges,hist, yerr=err,\n",
    "                  yscale='log',\n",
    "                   xscale='log',\n",
    "        #           ylim=(1e-6,1e4)\n",
    "                  )\n",
    "        #\n",
    "        with open('msd/event_jumps.txt','w') as fp:\n",
    "            np.savetxt(fp,np.c_[bin_edges,hist,err],header='bin_edges hist err')\n",
    "\n",
    "        \n",
    "    def WindowAverage(self,ttime,bins_per_decade=4,LOG=False):\n",
    "        '''\n",
    "        returnd msd (include temporal windows)\n",
    "        '''\n",
    "        for shift in range(1,len(self.times)): #-1):\n",
    "    #        shift = 1 #--- time index  shift\n",
    "            dt = zip(self.times,self.times[shift:]) #--- time tuples\n",
    "            dt_real = list(map(lambda x: x[1]-x[0], zip(ttime,ttime[shift:]))) #--- real time difference\n",
    "            if not LOG: #---  mean\n",
    "                disp = list(map(lambda x: ((self.disp[x[1]]['DisplacementX'][self.filtr]-self.disp[x[0]]['DisplacementX'][self.filtr])**2+\\\n",
    "                              (self.disp[x[1]]['DisplacementY'][self.filtr]-self.disp[x[0]]['DisplacementY'][self.filtr])**2+\\\n",
    "                              (self.disp[x[1]]['DisplacementZ'][self.filtr]-self.disp[x[0]]['DisplacementZ'][self.filtr])**2).mean(),\n",
    "                    zip(self.times,self.times[shift:])))\n",
    "            else:\n",
    "                disp = list(map(lambda x: 10**((np.log10((self.disp[x[1]]['DisplacementX'][self.filtr]-self.disp[x[0]]['DisplacementX'][self.filtr])**2+\\\n",
    "                              (self.disp[x[1]]['DisplacementY'][self.filtr]-self.disp[x[0]]['DisplacementY'][self.filtr])**2+\\\n",
    "                              (self.disp[x[1]]['DisplacementZ'][self.filtr]-self.disp[x[0]]['DisplacementZ'][self.filtr])**2)).mean()),\n",
    "                    zip(self.times,self.times[shift:])))\n",
    "            \n",
    "#            print(np.array(disp).shape)\n",
    "            if shift == 1:\n",
    "                tr_mat=np.c_[dt_real,disp]\n",
    "            else:    \n",
    "                tr_mat = np.concatenate([tr_mat,np.c_[dt_real,disp]],axis=0)\n",
    "                \n",
    "        #--- remove dt == 0\n",
    "        filtr = tr_mat[:,0] > 0\n",
    "        tr_mat = tr_mat[filtr]\n",
    "#        print('dt_min=',tr_mat[:,0].min())\n",
    "#        pdb.set_trace()\n",
    "\n",
    "        return self.Binning(tr_mat,bins_per_decade)\n",
    "\n",
    "#         #--- binning\n",
    "#         xmin = 0.99*tr_mat[:,0].min()\n",
    "#         xmax = 1.01*tr_mat[:,0].max()\n",
    "#         n_decades = int(np.ceil(np.log10(xmax/xmin)))\n",
    "#         bins = np.logspace(np.log10(xmin),np.log10(xmax),n_decades*bins_per_decade)\n",
    "#         #\n",
    "#         ysum, edges = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,1])\n",
    "#         ysum_sq, edges = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,1]*tr_mat[:,1])\n",
    "#         xsum, edges = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,0])\n",
    "#         count, edges = np.histogram(tr_mat[:,0],bins=bins)\n",
    "#         #\n",
    "# #        filtr = count > 1\n",
    "#         filtr = count > 0\n",
    "#         ysum = ysum[filtr]\n",
    "#         ysum_sq = ysum_sq[filtr]\n",
    "#         xsum = xsum[filtr]\n",
    "#         count = count[filtr]\n",
    "#         assert not np.any(count == 0), 'incerease bin size!'\n",
    "#         #\n",
    "#         ysum_sq /= count\n",
    "#         ysum /= count\n",
    "#         xsum /= count\n",
    "#         ysum_sq -= (ysum * ysum)\n",
    "# #        assert not np.any(ysum_sq < 0.0), 'print %s'%ysum_sq\n",
    "        \n",
    "#         return np.c_[xsum,ysum,(ysum_sq/count)**0.5]\n",
    "    \n",
    "    def VacancyDynamics(self, title='void.xyz'):\n",
    "        '''\n",
    "        return xyz coordinates associated with vacancy \n",
    "        '''\n",
    "        #--- unwrapped coordinates\n",
    "        times = self.times[1:]\n",
    "        times_ref = self.times[:-1]\n",
    "        xsum_concat=np.array([0,0,0])\n",
    "        for itime, itime_ref in zip(times,times_ref):\n",
    "            filtr = self.cna[itime_ref]['StructureType'] == 0.0 #--- neighboring atoms\n",
    "            xsum = -np.array(self.veloc[itime][filtr] #--- disp\n",
    "                            [['DisplacementX','DisplacementY','DisplacementZ']].sum())\n",
    "            xsum_concat = np.c_[xsum_concat,xsum]\n",
    "        xsum_concat = xsum_concat.T\n",
    "        xv = xsum_concat.cumsum(axis=0) #--- integrate\n",
    "#        utl.PltErr(xv[:,0],xv[:,1])\n",
    "        #--- add initial position\n",
    "        itime=times_ref[0]\n",
    "        filtr = self.cna[itime]['StructureType'] == 0.0\n",
    "        rc = np.array(self.veloc[itime][filtr]\n",
    "                        [['x','y','z']].mean())\n",
    "        #--- print\n",
    "        try:\n",
    "            os.system('rm msd/%s'%title)\n",
    "        except:\n",
    "            pass\n",
    "        for itime in range(xv.shape[0]):\n",
    "            sfile=open('msd/%s'%title,'a')\n",
    "            utl.PrintOvito(pd.DataFrame(np.c_[xv[itime,:]+rc].reshape(1,3),columns=['x','y','z']), \n",
    "                       sfile, 'itime=%s'%itime, attr_list=['x', 'y', 'z'])\n",
    "            \n",
    "        self.xv = xv\n",
    "        self.dxv = xsum_concat\n",
    "        \n",
    "    def msdVacancy(self,ttime,bins_per_decade=4,LOG=False):\n",
    "        '''\n",
    "        returnd msd(t) associated with motion of the vacancy\n",
    "        '''\n",
    "        \n",
    "        time_indices = np.arange(len(self.times))\n",
    "        for shift in range(1,len(self.times)):\n",
    "    #        shift = 1 #--- time index  shift\n",
    "            dt = zip(self.times,self.times[shift:]) #--- time tuples\n",
    "            dt_real = list(map(lambda x: x[1]-x[0], zip(ttime,ttime[shift:]))) #--- real time difference\n",
    "            disp = list(map(lambda x: np.mean((self.xv[x[1]]-self.xv[x[0]])*(self.xv[x[1]]-self.xv[x[0]])),\n",
    "                    zip(time_indices,time_indices[shift:])))\n",
    "            \n",
    "#            print(np.array(disp).shape)\n",
    "            if shift == 1:\n",
    "                tr_mat=np.c_[dt_real,disp]\n",
    "            else:    \n",
    "                tr_mat = np.concatenate([tr_mat,np.c_[dt_real,disp]],axis=0)\n",
    "                \n",
    "        #--- remove dt == 0\n",
    "        filtr = tr_mat[:,0] > 0\n",
    "        tr_mat = tr_mat[filtr]\n",
    "        return self.Binning(tr_mat,bins_per_decade)\n",
    "#        print('dt_min=',tr_mat[:,0].min())\n",
    "#        pdb.set_trace()\n",
    "\n",
    "\n",
    "    def Binning(self,tr_mat,bins_per_decade):\n",
    "        #--- binning\n",
    "        xmin = 0.99*tr_mat[:,0].min()\n",
    "        xmax = 1.01*tr_mat[:,0].max()\n",
    "        n_decades = int(np.ceil(np.log10(xmax/xmin)))\n",
    "        bins = np.logspace(np.log10(xmin),np.log10(xmax),n_decades*bins_per_decade)\n",
    "        #\n",
    "        ysum, edges = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,1])\n",
    "        ysum_sq, edges = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,1]*tr_mat[:,1])\n",
    "        xsum, edges = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,0])\n",
    "        count, edges = np.histogram(tr_mat[:,0],bins=bins)\n",
    "        #\n",
    "#        filtr = count > 1\n",
    "        filtr = count > 0\n",
    "        ysum = ysum[filtr]\n",
    "        ysum_sq = ysum_sq[filtr]\n",
    "        xsum = xsum[filtr]\n",
    "        count = count[filtr]\n",
    "        assert not np.any(count == 0), 'incerease bin size!'\n",
    "        #\n",
    "        ysum_sq /= count\n",
    "        ysum /= count\n",
    "        xsum /= count\n",
    "        ysum_sq -= (ysum * ysum)\n",
    "#        assert not np.any(ysum_sq < 0.0), 'print %s'%ysum_sq\n",
    "        \n",
    "        return np.c_[xsum,ysum,(ysum_sq/count)**0.5]\n",
    "    \n",
    "\n",
    "!mkdir msd\n",
    "msd = MsDisp( lmpDisp, lmpVel, lmpCna,\n",
    "              np.ones(lmpDisp.coord_atoms_broken[0].shape[0],dtype=bool) #--- filter \n",
    "            )\n",
    "#\n",
    "msd.GetPdfJumps() #--- jump distributions\n",
    "\n",
    "#--- vacancy\n",
    "msd.VacancyDynamics(title='void2.xyz')\n",
    "vac_data = msd.msdVacancy(lmpData.headers['Time'][::2],bins_per_decade=4,LOG=False)\n",
    "\n",
    "#\n",
    "ans = msd.WindowAverage(lmpData.headers['Time'][::2],bins_per_decade=4,LOG=False) #---msd\n",
    "ans_logAveraged = msd.WindowAverage(lmpData.headers['Time'][::2],bins_per_decade=4,LOG=True)\n",
    "#\n",
    "#\n",
    "with open('msd/msd.txt','w') as fp:\n",
    "    np.savetxt(fp,ans,header='t\\tmsd\\terr')\n",
    "#\n",
    "with open('msd/msd_logAveraged.txt','w') as fp:\n",
    "    np.savetxt(fp,ans_logAveraged,header='t\\tmsd\\terr')\n",
    "#\n",
    "with open('msd/event_times.txt','w') as fp:\n",
    "    np.savetxt(fp,lmpData.times,header='t')\n",
    "#\n",
    "with open('msd/timeseries.txt','w') as fp:\n",
    "    np.savetxt(fp,np.c_[lmpData.headers],header='Barrier Energy Step Time')\n",
    "#\n",
    "with open('msd/msd_vac.txt','w') as fp:\n",
    "    np.savetxt(fp,vac_data,header='t\\tmsd\\terr')\n",
    "    \n",
    "#--- filter based on atom types\n",
    "# types = list(set(lmpDisp.coord_atoms_broken[0]['type']))\n",
    "# for itype in types:\n",
    "#     filtr = lmpDisp.coord_atoms_broken[0]['type'] == itype\n",
    "#     msd = MsDisp( lmpDisp, lmpVel,\n",
    "#               filtr #--- filter \n",
    "#             )\n",
    "#     ans = msd.WindowAverage(lmpData.times,bins_per_decade=4)\n",
    "#     #--- print\n",
    "#     with open('msd/msd_type%s.txt'%itype,'w') as fp:\n",
    "#         np.savetxt(fp,ans,header='t\\tmsd\\terr')\n",
    "#     with open('msd/event_times_type%s.txt'%itype,'w') as fp:\n",
    "#         np.savetxt(fp,lmpData.times,header='t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy barriers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnergyBarrier:\n",
    "    '''\n",
    "    return energy barriers corresponding to diffusional hopping\n",
    "    '''\n",
    "    def __init__(self,events_directory,evlist_directory,lmpData):\n",
    "        self.events_dir = events_directory\n",
    "        self.evlist_dir = evlist_directory\n",
    "        self.lmpData = lmpData.coord_atoms_broken[0]\n",
    "        \n",
    "    def Parse(self):\n",
    "        '''\n",
    "        parse event files\n",
    "        '''\n",
    "        self.events_id_energy = self.ParseEvents_dir()\n",
    "        self.catalog = self.ParseEvList_dir()\n",
    "        \n",
    "        \n",
    "    def ParseEvents_dir(self):\n",
    "        files = os.listdir(self.events_dir)\n",
    "        d=[]\n",
    "        for sfile in files:\n",
    "            if not '.xyz' in sfile: #--- skip .xyz files \n",
    "                try:\n",
    "                    filee=open('%s/%s'%(self.events_dir,sfile)) #--- open file\n",
    "                    xstrs = filee.readlines()\n",
    "                    event_id = int(xstrs[0].split()[-1]) #--- event id\n",
    "                    barrier = float(xstrs[2].split()[-1]) #--- energy\n",
    "                    ncluster =  int(xstrs[15].split()[-1])                 \n",
    "                    shape_cluster_atoms =  int(xstrs[16].split()[-1])\n",
    "                    atom_id = int(xstrs[17+ncluster].split()[0])\n",
    "                    #print(atom_id)\n",
    "                    d = np.c_[event_id,atom_id,barrier] if len(d) == 0 else\\\n",
    "                    np.concatenate([d,np.c_[event_id,atom_id,barrier]])\n",
    "#                    d.setdefault(event_id,[]).append(barrier) #--- store\n",
    "                except:\n",
    "        #            traceback.print_exc()\n",
    "                    continue\n",
    "            \n",
    "        #--- extract types\n",
    "        df=self.lmpData\n",
    "        atom_ids = d[:,1]\n",
    "        types = utl.FilterDataFrame(df, \n",
    "                    key='id', \n",
    "                    val=atom_ids\n",
    "                   )['type']\n",
    "\n",
    "        return pd.DataFrame(np.c_[types,d],columns=['atom_type','event_id','atom_id','barrier'])\n",
    "\n",
    "    def ParseEvList_dir(self):\n",
    "        files = os.listdir(self.evlist_dir)\n",
    "        events={}\n",
    "        for sfile in files:\n",
    "            try:\n",
    "                kmc_step = int(sfile.split('_')[-1])\n",
    "        #        print(kmc_step)\n",
    "                filee=open('%s/%s'%(self.evlist_dir,sfile)) #--- open file\n",
    "                events[kmc_step] = pd.read_csv(filee,delim_whitespace=True).iloc[1:]#delimiter='')\n",
    "            except:\n",
    "                continue\n",
    "        return events\n",
    "        \n",
    "    def SplitByType(self):\n",
    "        '''\n",
    "        return energies (parsed from catalogs) slipt by atom types\n",
    "        '''\n",
    "        kmc_steps = list(self.catalog.keys())\n",
    "        kmc_steps.sort()\n",
    "\n",
    "\n",
    "        #--- dict based on types\n",
    "        df_concat = {}\n",
    "        types = list(set(self.lmpData.type))\n",
    "        for itype in types:\n",
    "            df_concat[str(itype)] = {}\n",
    "\n",
    "        for kmc_step in kmc_steps: #--- kmc loop\n",
    "            df = self.catalog[kmc_step]\n",
    "            sdict=df.groupby(by='#TypeId').groups #--- group by type\n",
    "            for itype in sdict:\n",
    "                indices = sdict[itype] #--- row index: atoms with  '#TypeId' == itype\n",
    "                cond = len(df_concat[itype]) == 0 #--- empty key?\n",
    "                df_concat[itype] = np.c_[df.loc[indices]] if cond else\\\n",
    "                np.concatenate([df_concat[itype],np.c_[df.loc[indices]]],axis=0)\n",
    "\n",
    "        self.energyByType = {}\n",
    "        for itype in df_concat:\n",
    "             self.energyByType[ itype ] = pd.DataFrame(df_concat[itype],columns=list(df.keys()))        \n",
    "\n",
    "eb = EnergyBarrier('%s/EVENTS_DIR'%confParser['input files']['input_path'],\n",
    "                   '%s/EVLIST_DIR'%confParser['input files']['input_path'],\n",
    "                   lmpData\n",
    "                  \n",
    "                  )\n",
    "eb.Parse()\n",
    "eb.SplitByType()\n",
    "\n",
    "#eb.events_id_energy extract from Events_dir\n",
    "#self.energyByType extract from catalogs\n",
    "\n",
    "#--- write to file\n",
    "with open('msd/eventID_barrier.txt','w') as fp:\n",
    "    np.savetxt(fp,\n",
    "               np.c_[eb.events_id_energy],\n",
    "               header='atom_type event_id atom_id barrier')\n",
    "\n",
    "#--- write to file: energy from catalogs\n",
    "for itype in eb.energyByType.keys():\n",
    "    with open('msd/eventID_barrier_catalog_type%s.txt'%itype,'w') as fp:\n",
    "    #--- concat different types\n",
    "        sarr = np.c_[eb.energyByType[itype][['AtomId','eventId','barrier']]].astype(float)\n",
    "        np.savetxt(fp,\n",
    "                   sarr,\n",
    "                   header='AtomId eventId barrier'\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sarr = np.concatenate(list(d.values()))\n",
    "# hist,edges,err=utl.GetPDF(sarr,n_per_decade=8)\n",
    "# utl.PltErr(edges,hist,yerr=err,xscale='log',yscale='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- assert events in catalogs are included in event dir\n",
    "\n",
    "\n",
    "    #    Energy_type[int(keys)] = np.c_[df.loc[indices]]\n",
    "    #    Energy_type[int(keys)].setdefault()\n",
    "    # for kmc_step in kmc_steps:\n",
    "    #     print(kmc_step)\n",
    "    #     trueFalse = list(map(lambda x: int(x) in eb.events_id_energy.keys() ,eb.catalog[kmc_step]['eventId']))\n",
    "    #     assert np.all(trueFalse),'modes %s are missing!'%(list(eb.catalog[kmc_step]['eventId'][~np.array(trueFalse)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- plot energy per atom\n",
    "# d={}\n",
    "# for kmc_step in kmc_steps:\n",
    "#     for items in np.c_[eb.catalog[kmc_step][['AtomId','barrier']]]:\n",
    "#         d.setdefault(int(items[0]),[]).append(float(items[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# itime=90\n",
    "# #filtr = msd.cna[itime].StructureType==0.0\n",
    "# filtr=msd.veloc[itime].DisplacementX.abs() > 0.1\n",
    "# assert np.any(filtr)\n",
    "# idd = msd.veloc[itime][filtr].id.iloc[0]\n",
    "# #msd.veloc[itime][filtr]\n",
    "\n",
    "# times=list(msd.disp.keys())\n",
    "# times.sort()\n",
    "# #idd=10\n",
    "# dispx={}\n",
    "# itimec=itime\n",
    "# for itime in times:\n",
    "#     filtr= msd.disp[itime].id==idd\n",
    "#     dispx[itime]=msd.disp[itime].DisplacementX[filtr]\n",
    "# tt=lmpData.headers.Time.iloc[0::2]\n",
    "# utl.PltErr(tt,\n",
    "#            list(map(lambda x:dispx[x],times[0::2])),\n",
    "# #           attrs={'fmt':'.'},\n",
    "#            xlim=(tt[itimec-2],tt[itimec+2]),\n",
    "#            attrs={'marker':'o',\n",
    "#                   'markersize':6,\n",
    "#                   'drawstyle':'steps-post'}\n",
    "           \n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tt=lmpData.headers.Time.iloc[0::2]\n",
    "# utl.PltErr(tt,msd.xv[:,0][0::2],\n",
    "#             xlim=(tt[100],tt[130]),\n",
    "#             ylim=(5,22),\n",
    "#            attrs={'marker':'o',\n",
    "#                   'markersize':8,\n",
    "#                   'drawstyle':'steps-post'}\n",
    "#           )\n",
    "\n",
    "# # utl.PltErr(tt,msd.xv[:,1][0::2],\n",
    "# # #            xlim=(tt[100],tt[130]),\n",
    "# # #            ylim=(5,25),\n",
    "# #            attrs={'marker':'o',\n",
    "# #                   'markersize':8,\n",
    "# #                   'drawstyle':'steps-post'}\n",
    "# #           )\n",
    "\n",
    "# # utl.PltErr(tt,msd.xv[:,2][0::2],\n",
    "# # #            xlim=(tt[100],tt[130]),\n",
    "# # #            ylim=(5,25),\n",
    "# #            attrs={'marker':'o',\n",
    "# #                   'markersize':8,\n",
    "# #                   'drawstyle':'steps-post'}\n",
    "# #           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tt=lmpData.headers.Time.iloc[0::2]\n",
    "# utl.PltErr(tt,msd.xv[:,0][0::2],\n",
    "#             xlim=(tt[0],tt[50]),\n",
    "#             ylim=(0,10),\n",
    "#            attrs={'marker':'s',\n",
    "#                   'markersize':8,\n",
    "#                   'drawstyle':'steps-post'}\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data = np.loadtxt('xxbarriers.txt')[:,1]\n",
    "\n",
    "# hist, bin_edges, err = utl.GetPDF(data,n_per_decade=16)\n",
    "# symbols=utl.Symbols()\n",
    "# #--- plot\n",
    "# utl.PltErr(bin_edges,hist,\n",
    "#               yerr=err,\n",
    "#        attrs=symbols.GetAttrs(),\n",
    "#            xscale='log',\n",
    "#            yscale='log'\n",
    "#               )\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmpData.headers #.Time.iloc[0::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmpData.coord_atoms_broken.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir png\n",
    "symbols=utl.Symbols()\n",
    "\n",
    "# ans=ans_tot\n",
    "ax=utl.PltErr(ans_logAveraged[:,0],ans_logAveraged[:,1],\n",
    "           yerr=ans_logAveraged[:,2],\n",
    "           attrs=symbols.GetAttrs(count=0),\n",
    "           Plot=False,\n",
    "          )\n",
    "\n",
    "ax=utl.PltErr(ans[:,0],ans[:,1],\n",
    "           yerr=ans[:,2],\n",
    "           ax = ax,\n",
    "           attrs=symbols.GetAttrs(count=1),\n",
    "           Plot=False,\n",
    "          )\n",
    "utl.PltErr(None,#lmpData.times[1:],\n",
    "           None, #msd.Get()[1:],\n",
    "          xscale='log',\n",
    "          yscale='log',\n",
    "           attrs={'fmt':'-'},\n",
    "           ax=ax,\n",
    "#           ylim=(1e-4,1e-1),\n",
    "           xstr=r'$t\\mathrm{(s)}$',\n",
    "           ystr=r'msd(A$^2$)',\n",
    "           title='png/msd.png'\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## arrhenius law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘png’: File exists\n",
      "Parsing: data.shape is (15, 3)\n",
      "limits: 1e-11 inf\n",
      "filtr= [False False False False  True  True  True  True  True  True  True  True\n",
      "  True  True  True]\n",
      "{'p0': [[0.01, 1000000.0, 1.0]]}\n",
      "Temp=1200,y0,c0,alpha [0.003063928461922196, 17315706.780723397, 0.9311741194903839] [[3.37363349e-06 8.77743372e+03 2.70614510e-05]\n",
      " [8.77743372e+03 4.94203164e+13 1.50090066e+05]\n",
      " [2.70614510e-05 1.50090066e+05 4.56074775e-04]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Temperature:\n",
    "    \n",
    "    def __init__(self,temp_range,nrun,verbose=False):\n",
    "        self.temps =  temp_range\n",
    "        self.nrun = nrun\n",
    "        t,r=np.meshgrid(self.temps,np.arange(nrun),indexing='ij')\n",
    "        self.temps_runs = np.array(list(zip(t.flatten(),r.flatten())))\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def Parse(self,dirs):\n",
    "#         print('dirs:',dirs)\n",
    "        self.data=list(map(lambda x:np.loadtxt(x,ndmin=2),dirs))\n",
    "        if self.verbose:\n",
    "            list(map(lambda x:print('Parsing: data.shape is',x.shape),self.data))\n",
    "#        print('np.array(self.data):',np.array(self.data))\n",
    "\n",
    "        \n",
    "    def Plot(self,**kwargs):\n",
    "#        print(list(self.temps_runs))\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs\n",
    "                    else (1.0,0.5,0.5,0.5)\n",
    "                   )\n",
    "        for data, temp_run, count in zip(self.data,self.temps_runs,range(len(self.data))): \n",
    "            temp = temp_run[0]\n",
    "            try:\n",
    "                utl.PltErr(data[:,0],data[:,1],\n",
    "                       yerr=data[:,2],\n",
    "                       ax = self.ax,\n",
    "                       attrs=symbols.GetAttrs(count=count%7,label=r'$%s$'%temp),\n",
    "                       Plot=False,\n",
    "                      )\n",
    "            except:\n",
    "                continue\n",
    "        #\n",
    "        utl.PltErr(None,\n",
    "                   None,\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "#                 legend=legends.Get(),\n",
    "                   **kwargs\n",
    "                  )\n",
    "        \n",
    "    def EnsAverage(self,log_scale=False,n_bins_per_decade=6):\n",
    "        kount = 0\n",
    "        self.data_averaged = {} #np.zeros(len(self.temps))\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp\n",
    "            data = self.data[kount:kount+self.nrun]\n",
    "            if self.verbose:\n",
    "                print('data.shape:',np.array(data).shape)\n",
    "#             print('np.array(data):',np.array(data))\n",
    "#             pdb.set_trace()\n",
    "    \n",
    "            filtr = list(map(lambda x:x.shape[0] > 0,data)) #--- filter empty arrays\n",
    "    \n",
    "            data = np.concatenate(np.array(data)[filtr]) #,axis=0)\n",
    "            self.data_averaged[ temp ] = self.hist(data,log_scale,n_bins_per_decade=n_bins_per_decade)\n",
    "            kount += self.nrun\n",
    "\n",
    "    def hist(self,data,log_scale,n_bins_per_decade=6):\n",
    "        n_thresh = 2\n",
    "            #--- average\n",
    "        xdata = data[:,0]\n",
    "        ydata = data[:,1]\n",
    "        xmin = np.floor(np.log10(xdata).min())\n",
    "        xmax = np.ceil(np.log10(xdata).max())\n",
    "        n_decades = int((xmax - xmin))\n",
    "        bins = np.logspace(xmin,xmax,n_decades*n_bins_per_decade)\n",
    "        #\n",
    "        count, _ = np.histogram(xdata,bins=bins)\n",
    "        xsum, _  = np.histogram(xdata,bins=bins,weights=xdata)\n",
    "        weights = ydata if not log_scale else np.log10(ydata)\n",
    "        ysum, _  = np.histogram(xdata,bins=bins,weights=weights)\n",
    "        ysum_sq, _  = np.histogram(xdata,bins=bins,weights=weights*weights)\n",
    "        #\n",
    "        xsum = xsum[count>n_thresh]\n",
    "        ysum = ysum[count>n_thresh]\n",
    "        ysum_sq = ysum_sq[count>n_thresh]\n",
    "        count = count[count>n_thresh]\n",
    "        #\n",
    "        xsum /= count\n",
    "        ysum /= count\n",
    "        ysum_sq /= count\n",
    "        std = np.sqrt((ysum_sq - ysum * ysum)/count)\n",
    "        if log_scale:\n",
    "            ysum = 10 ** ysum\n",
    "            std = 0.5 * ysum * (1+2*std*np.log(10))\n",
    "        return np.c_[xsum,ysum,std]\n",
    "        \n",
    "        \n",
    "#            utl.PltErr(xsum,ysum,ax=self.ax)\n",
    "            \n",
    "\n",
    "    def PlotAverage(self,rescale=False,**kwargs):\n",
    "#        print(list(self.temps_runs))\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "        for temp, count in zip(self.temps,range(len(self.temps))): \n",
    "            data = self.data_averaged[ temp ]\n",
    "            xdata = data[:,0]\n",
    "            ydata = data[:,1]\n",
    "            yerr = data[:,2]\n",
    "            if rescale:\n",
    "                ydata /= xdata\n",
    "                yerr /= xdata\n",
    "            utl.PltErr(xdata,ydata,\n",
    "                   yerr=yerr,\n",
    "                   ax = self.ax,\n",
    "                   attrs=symbols.GetAttrs(count=count%7,label=r'$%s$'%temp,nevery=1),\n",
    "                   Plot=False,\n",
    "                  )\n",
    "\n",
    "        utl.PltErr(None,\n",
    "                   None, \n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "#                    legend=legends.Get(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "        \n",
    "        \n",
    "    def func2nd(self,x,y0,c0,alpha):\n",
    "#        return y0+c0*(x/x0)**alpha\n",
    "        return y0+c0*x**alpha\n",
    "#     def func2nd(self,x,y0,m0):\n",
    "#         return y0+m0*x\n",
    "\n",
    "    def Fit(self,Plot=None,\n",
    "            shift = False,\n",
    "#             SIGMA=False,\n",
    "            plotAttrs=None,\n",
    "            bounds=(-np.inf, np.inf),\n",
    "            xlo=float('-inf'),xhi=float('inf'),\n",
    "            **kwargs):\n",
    "        self.Diffusion = {}\n",
    "        self.exponent = {}\n",
    "        pref=1e-10*1e-10 #--- ang^2 to m^2\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=plotAttrs['bbox_to_anchor'] if 'bbox_to_anchor' in plotAttrs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "\n",
    "        if Plot:\n",
    "            ax = utl.PltErr(None,None,\n",
    "                            Plot=False)\n",
    "        #\n",
    "        for temp, count in zip(self.temps,range(len(self.temps))): \n",
    "            self.smat = smat = self.data_averaged[ temp ] if self.nrun > 1 else self.data[count]\n",
    "\n",
    "            xdata=smat[:,0]\n",
    "            ydata=smat[:,1]\n",
    "            yerr = smat[:,2]\n",
    "#             print(smat)\n",
    "\n",
    "        \n",
    "            #--- set limits:\n",
    "            if self.verbose:\n",
    "                print('limits:',xlo,xhi)\n",
    "\n",
    "            filtr = np.ones(xdata.shape[0],dtype=bool)\n",
    "            filtr = np.all([filtr,xdata > xlo],axis=0)\n",
    "            filtr = np.all([filtr,xdata <= xhi],axis=0)\n",
    "            assert np.any(filtr), 'empty arrays!'\n",
    "            if self.verbose:\n",
    "                print('filtr=',filtr)\n",
    "            \n",
    "            #--- error in y\n",
    "            if 'sigma' in kwargs:\n",
    "                kwargs['sigma'] = yerr[filtr]\n",
    "\n",
    "            #--- fit\n",
    "            print(kwargs)\n",
    "            popt, pcov = curve_fit(self.func2nd, xdata[filtr], ydata[filtr],\n",
    "#                                   bounds=(0, [1e-2, 1e7,2.0]), #[(4e-3, 1e5,0.5), (1e-2, 1e7,2.0)],#bounds,\n",
    "                                    **kwargs\n",
    "                                    )\n",
    "            self.popt = popt\n",
    "            self.filtr = filtr\n",
    "            #--- uncertainties\n",
    "            if self.verbose:\n",
    "                print('Temp=%s,y0,c0,alpha'%temp,list(popt),pcov)\n",
    "            y0=popt[0]\n",
    "            alpha=popt[2]\n",
    "            err_alpha = pcov[2,2]**0.5\n",
    "            c0=popt[1]\n",
    "            dc = pcov[1,1]**0.5\n",
    "            tau=1#popt[0]\n",
    "            dtau=0#pcov[0,0]**0.5\n",
    "            self.time_scale = tau * (y0/c0)**(1/alpha)\n",
    "#             self.Diffusion[temp] = [pref*c0/tau,pref*c0/tau,pref*c0/tau]\n",
    "            self.Diffusion[temp] = [pref*c0/(tau)**alpha, pref*(c0+dc)/(tau-dtau)**alpha, \n",
    "                                    pref*(c0-dc)/(tau+dtau)**alpha]\n",
    "            self.exponent[temp] = [alpha,alpha+err_alpha,alpha-err_alpha]\n",
    "            if Plot:\n",
    "                #---fit\n",
    "                xdata_shift = xdata*20**count if shift else xdata\n",
    "                utl.PltErr(xdata_shift,\n",
    "                                (self.func2nd(xdata,*popt)),#-y0)/xdata_shift,\n",
    "                                attrs={'fmt':'-.','color':symbols.colors[count%7]},\n",
    "                           Plot=False,ax=ax)\n",
    "                #--- points\n",
    "#                temp= [1000,1200,1400,1600,1800,2000][count]\n",
    "                utl.PltErr(xdata_shift,\n",
    "                           (ydata),#-y0)/xdata_shift,\n",
    "                           yerr=(yerr),#-y0),#/xdata_shift,\n",
    "                           attrs=symbols.GetAttrs(count=count%7,label=r'$%s$'%temp,fmt='.'),\n",
    "                           ax=ax,\n",
    "                           Plot=False,\n",
    "                          )\n",
    "        if Plot:\n",
    "            utl.PltErr(None,\n",
    "                       None, \n",
    "                       ax=ax,\n",
    "                       Plot=False,\n",
    "#                      legend=legends.Get(),\n",
    "                       DrawFrame=DRAW_FRAME,\n",
    "                       **plotAttrs\n",
    "                      )\n",
    "\n",
    "    def PlotDiff(self,**kwargs):\n",
    "        symbols=utl.Symbols()\n",
    "        utl.PltErr(1.0/np.array(self.temps),\n",
    "                   list(map(lambda x:self.Diffusion[x][0],self.temps)),\n",
    "                   yerr=list(map(lambda x:(self.Diffusion[x][1]-self.Diffusion[x][2])/2,self.temps)),\n",
    "                   attrs=symbols.GetAttrs(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "\n",
    "    def PlotExponent(self,**kwargs):\n",
    "        symbols=utl.Symbols()\n",
    "        ax=utl.PltErr([0.5e-3,1e-3],[1,1],attrs={'fmt':'-.r'},Plot=False)\n",
    "        utl.PltErr(1.0/np.array(self.temps),\n",
    "                   list(map(lambda x:self.exponent[x][0],self.temps)),\n",
    "                   yerr=list(map(lambda x:1.0*(self.exponent[x][1]-self.exponent[x][2]),self.temps)),\n",
    "                   attrs=symbols.GetAttrs(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   ax=ax,\n",
    "                   **kwargs\n",
    "                  )\n",
    "\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    #--- temp object\n",
    "    temp = Temperature(\n",
    "#        [1000,1200,1400,1600,1800,2000],8,\n",
    "        [1200],1,\n",
    "#        [1000,1200,1400,1600,1800,2000],8,\n",
    "#       [1000,1200,1400,1600,1800,2000],1,\n",
    "#        np.arange(1000,1440,80),1,\n",
    "         verbose = True,\n",
    "                     )\n",
    "    #\n",
    "    #--- parse data\n",
    "#    temp.Parse(['./msd/msd.txt'])\n",
    "#    temp.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "#    temp.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "#    temp.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "    temp.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "                        temp.temps_runs ))\n",
    "             )\n",
    "    #\n",
    "    #--- plot\n",
    "#     print('single realizations')\n",
    "#     temp.Plot(**{\n",
    "#                   'xscale':'log',\n",
    "#                   'yscale':'log',\n",
    "#                    'attrs':{'fmt':'-'},\n",
    "# #                   'xlim':(1e-10,1e-3),\n",
    "#                    'ylim':(1e-5,1e-1),\n",
    "# #                   'xstr':r'$t\\mathrm{(s)}$',\n",
    "# #                   'ystr':r'msd(A$^2$)',\n",
    "# #                   'title':'png/msd_temp_ni.png',\n",
    "#         'bbox_to_anchor':(0.01,0.3,0.5,0.5)\n",
    "#     })\n",
    "    #\n",
    "    #--- plot average\n",
    "    #\n",
    "    if temp.nrun > 1:\n",
    "        print('ensemble average')\n",
    "        temp.EnsAverage(log_scale=False,n_bins_per_decade=4)\n",
    "#         temp.PlotAverage(**{\n",
    "#                   'yscale':'log',\n",
    "#                   'xscale':'log',\n",
    "# #                   'xlim':(1e-10,1e-3),\n",
    "# #                    'ylim':(1e-4,1e-1),\n",
    "# #                     'xstr':r'$t\\mathrm{(s)}$',\n",
    "# #                   'ystr':r'msd(A$^2$)',\n",
    "#                    'title':'png/msd_temp_cantor.png',\n",
    "#         })\n",
    "\n",
    "    #\n",
    "    #--- fit\n",
    "    #\n",
    "    temp.Fit(Plot=True,\n",
    "             shift=True,\n",
    "#             bounds=([4e-3, 1e5,0.5], [1e-2, 1e7,2.0]),\n",
    "            p0=[[1e-2, 1e6, 1.0]],\n",
    " #           p0=[[1e-2, 1e6, 1.0]],\n",
    "#             sigma=True, #--- comment for ni\n",
    "             xlo=4e-11,\n",
    "             plotAttrs={'yscale':'log',\n",
    "                  'xscale':'log',\n",
    "#                   'xlim':(4e-13,8e-4),\n",
    "#                   'ylim':(1e-4,1e-1),\n",
    "#                     'xstr':r'$t\\mathrm{(s)}$',\n",
    "#                   'ystr':r'msd(A$^2$)',\n",
    "                        'ndecade_x':2,\n",
    "                    'bbox_to_anchor':(-0.05,0.23,0.5,0.5),\n",
    "                   'title':'png/msd_temp_nicocr_fit.png'},\n",
    "            )\n",
    "    \n",
    "#     temp.PlotDiff(**{\n",
    "#                   'yscale':'log',\n",
    "# #                   'xlim':(1e-12,1e-3),\n",
    "# #                   'ylim':(1e-4,1e-1),\n",
    "# #                   xstr=r'$1/T(K^{-1})$',\n",
    "# #                   ystr=r'$D(m^2/s)$',\n",
    "#                     'title':'png/D_temp_cantor.png',\n",
    "#                     }\n",
    "#                 )\n",
    "\n",
    "    temp.PlotExponent(**{\n",
    "#                  'yscale':'log',\n",
    "#                   'xlim':(1e-10,1e-3),\n",
    "                   'ylim':(.5,1.1),\n",
    "#                   xstr=r'$1/T(K^{-1})$',\n",
    "#                   ystr=r'$D(m^2/s)$',\n",
    "                    'title':'png/alpha_temp_nicocr.png',\n",
    "                    }\n",
    "                )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function curve_fit in module scipy.optimize.minpack:\n",
      "\n",
      "curve_fit(f, xdata, ydata, p0=None, sigma=None, absolute_sigma=False, check_finite=True, bounds=(-inf, inf), method=None, jac=None, **kwargs)\n",
      "    Use non-linear least squares to fit a function, f, to data.\n",
      "    \n",
      "    Assumes ``ydata = f(xdata, *params) + eps``.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    f : callable\n",
      "        The model function, f(x, ...). It must take the independent\n",
      "        variable as the first argument and the parameters to fit as\n",
      "        separate remaining arguments.\n",
      "    xdata : array_like or object\n",
      "        The independent variable where the data is measured.\n",
      "        Should usually be an M-length sequence or an (k,M)-shaped array for\n",
      "        functions with k predictors, but can actually be any object.\n",
      "    ydata : array_like\n",
      "        The dependent data, a length M array - nominally ``f(xdata, ...)``.\n",
      "    p0 : array_like, optional\n",
      "        Initial guess for the parameters (length N). If None, then the\n",
      "        initial values will all be 1 (if the number of parameters for the\n",
      "        function can be determined using introspection, otherwise a\n",
      "        ValueError is raised).\n",
      "    sigma : None or M-length sequence or MxM array, optional\n",
      "        Determines the uncertainty in `ydata`. If we define residuals as\n",
      "        ``r = ydata - f(xdata, *popt)``, then the interpretation of `sigma`\n",
      "        depends on its number of dimensions:\n",
      "    \n",
      "            - A 1-D `sigma` should contain values of standard deviations of\n",
      "              errors in `ydata`. In this case, the optimized function is\n",
      "              ``chisq = sum((r / sigma) ** 2)``.\n",
      "    \n",
      "            - A 2-D `sigma` should contain the covariance matrix of\n",
      "              errors in `ydata`. In this case, the optimized function is\n",
      "              ``chisq = r.T @ inv(sigma) @ r``.\n",
      "    \n",
      "              .. versionadded:: 0.19\n",
      "    \n",
      "        None (default) is equivalent of 1-D `sigma` filled with ones.\n",
      "    absolute_sigma : bool, optional\n",
      "        If True, `sigma` is used in an absolute sense and the estimated parameter\n",
      "        covariance `pcov` reflects these absolute values.\n",
      "    \n",
      "        If False (default), only the relative magnitudes of the `sigma` values matter.\n",
      "        The returned parameter covariance matrix `pcov` is based on scaling\n",
      "        `sigma` by a constant factor. This constant is set by demanding that the\n",
      "        reduced `chisq` for the optimal parameters `popt` when using the\n",
      "        *scaled* `sigma` equals unity. In other words, `sigma` is scaled to\n",
      "        match the sample variance of the residuals after the fit. Default is False.\n",
      "        Mathematically,\n",
      "        ``pcov(absolute_sigma=False) = pcov(absolute_sigma=True) * chisq(popt)/(M-N)``\n",
      "    check_finite : bool, optional\n",
      "        If True, check that the input arrays do not contain nans of infs,\n",
      "        and raise a ValueError if they do. Setting this parameter to\n",
      "        False may silently produce nonsensical results if the input arrays\n",
      "        do contain nans. Default is True.\n",
      "    bounds : 2-tuple of array_like, optional\n",
      "        Lower and upper bounds on parameters. Defaults to no bounds.\n",
      "        Each element of the tuple must be either an array with the length equal\n",
      "        to the number of parameters, or a scalar (in which case the bound is\n",
      "        taken to be the same for all parameters). Use ``np.inf`` with an\n",
      "        appropriate sign to disable bounds on all or some parameters.\n",
      "    \n",
      "        .. versionadded:: 0.17\n",
      "    method : {'lm', 'trf', 'dogbox'}, optional\n",
      "        Method to use for optimization. See `least_squares` for more details.\n",
      "        Default is 'lm' for unconstrained problems and 'trf' if `bounds` are\n",
      "        provided. The method 'lm' won't work when the number of observations\n",
      "        is less than the number of variables, use 'trf' or 'dogbox' in this\n",
      "        case.\n",
      "    \n",
      "        .. versionadded:: 0.17\n",
      "    jac : callable, string or None, optional\n",
      "        Function with signature ``jac(x, ...)`` which computes the Jacobian\n",
      "        matrix of the model function with respect to parameters as a dense\n",
      "        array_like structure. It will be scaled according to provided `sigma`.\n",
      "        If None (default), the Jacobian will be estimated numerically.\n",
      "        String keywords for 'trf' and 'dogbox' methods can be used to select\n",
      "        a finite difference scheme, see `least_squares`.\n",
      "    \n",
      "        .. versionadded:: 0.18\n",
      "    kwargs\n",
      "        Keyword arguments passed to `leastsq` for ``method='lm'`` or\n",
      "        `least_squares` otherwise.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    popt : array\n",
      "        Optimal values for the parameters so that the sum of the squared\n",
      "        residuals of ``f(xdata, *popt) - ydata`` is minimized.\n",
      "    pcov : 2-D array\n",
      "        The estimated covariance of popt. The diagonals provide the variance\n",
      "        of the parameter estimate. To compute one standard deviation errors\n",
      "        on the parameters use ``perr = np.sqrt(np.diag(pcov))``.\n",
      "    \n",
      "        How the `sigma` parameter affects the estimated covariance\n",
      "        depends on `absolute_sigma` argument, as described above.\n",
      "    \n",
      "        If the Jacobian matrix at the solution doesn't have a full rank, then\n",
      "        'lm' method returns a matrix filled with ``np.inf``, on the other hand\n",
      "        'trf'  and 'dogbox' methods use Moore-Penrose pseudoinverse to compute\n",
      "        the covariance matrix.\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        if either `ydata` or `xdata` contain NaNs, or if incompatible options\n",
      "        are used.\n",
      "    \n",
      "    RuntimeError\n",
      "        if the least-squares minimization fails.\n",
      "    \n",
      "    OptimizeWarning\n",
      "        if covariance of the parameters can not be estimated.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    least_squares : Minimize the sum of squares of nonlinear functions.\n",
      "    scipy.stats.linregress : Calculate a linear least squares regression for\n",
      "                             two sets of measurements.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    With ``method='lm'``, the algorithm uses the Levenberg-Marquardt algorithm\n",
      "    through `leastsq`. Note that this algorithm can only deal with\n",
      "    unconstrained problems.\n",
      "    \n",
      "    Box constraints can be handled by methods 'trf' and 'dogbox'. Refer to\n",
      "    the docstring of `least_squares` for more information.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> from scipy.optimize import curve_fit\n",
      "    \n",
      "    >>> def func(x, a, b, c):\n",
      "    ...     return a * np.exp(-b * x) + c\n",
      "    \n",
      "    Define the data to be fit with some noise:\n",
      "    \n",
      "    >>> xdata = np.linspace(0, 4, 50)\n",
      "    >>> y = func(xdata, 2.5, 1.3, 0.5)\n",
      "    >>> rng = np.random.default_rng()\n",
      "    >>> y_noise = 0.2 * rng.normal(size=xdata.size)\n",
      "    >>> ydata = y + y_noise\n",
      "    >>> plt.plot(xdata, ydata, 'b-', label='data')\n",
      "    \n",
      "    Fit for the parameters a, b, c of the function `func`:\n",
      "    \n",
      "    >>> popt, pcov = curve_fit(func, xdata, ydata)\n",
      "    >>> popt\n",
      "    array([2.56274217, 1.37268521, 0.47427475])\n",
      "    >>> plt.plot(xdata, func(xdata, *popt), 'r-',\n",
      "    ...          label='fit: a=%5.3f, b=%5.3f, c=%5.3f' % tuple(popt))\n",
      "    \n",
      "    Constrain the optimization to the region of ``0 <= a <= 3``,\n",
      "    ``0 <= b <= 1`` and ``0 <= c <= 0.5``:\n",
      "    \n",
      "    >>> popt, pcov = curve_fit(func, xdata, ydata, bounds=(0, [3., 1., 0.5]))\n",
      "    >>> popt\n",
      "    array([2.43736712, 1.        , 0.34463856])\n",
      "    >>> plt.plot(xdata, func(xdata, *popt), 'g--',\n",
      "    ...          label='fit: a=%5.3f, b=%5.3f, c=%5.3f' % tuple(popt))\n",
      "    \n",
      "    >>> plt.xlabel('x')\n",
      "    >>> plt.ylabel('y')\n",
      "    >>> plt.legend()\n",
      "    >>> plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(curve_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Robustness(Temperature):\n",
    "    \n",
    "    def __init__(self,temp_range,nrun,verbose=False):\n",
    "        Temperature.__init__(self,temp_range,nrun,verbose=verbose)\n",
    "\n",
    "    def FitRange(self,decades=9):\n",
    "        self.Fit(Plot=False,shift=False,\n",
    "                    p0=[[1e-2, 1e6, 1.0]],\n",
    "                 sigma=True, #--- comment for ni\n",
    "                     plotAttrs={'bbox_to_anchor':(-0.05,0.23,0.5,0.5)}\n",
    "                )\n",
    "\n",
    "        self.xlo = np.floor(np.log2(self.smat[:,0].min()))\n",
    "        xhii = np.ceil(np.log2(self.smat[:,0].max()))\n",
    "        self.xrange = 2**np.arange(xhii+1,xhii-decades,-1)\n",
    "        \n",
    "    def Fitting(self):\n",
    "        #--- bounds\n",
    "        self.exponents = np.zeros(len(self.xrange))\n",
    "        self.error = np.zeros(len(self.xrange))\n",
    "        self.npoin = np.zeros(len(self.xrange))\n",
    "        \n",
    "        npoint_filtrd0 = self.smat.shape[0]\n",
    "        for xhi, indx in zip(self.xrange,range(len(self.xrange))):\n",
    "            self.Fit(Plot=True,\n",
    "                     shift=False,\n",
    "        #             bounds=([0, 0, 0,0.999], [1e-2, 1e-3, 1,1.001]),\n",
    "                        p0=[[1e-2, 1e6, 1.0]],\n",
    "                     sigma=True, #--- comment for ni\n",
    "                     xlo=2**self.xlo,xhi=xhi,\n",
    "                     plotAttrs={'yscale':'log',\n",
    "                          'xscale':'log',\n",
    "        #                   'xlim':(4e-13,8e-4),\n",
    "        #                   'ylim':(1e-4,1e-1),\n",
    "        #                     'xstr':r'$t\\mathrm{(s)}$',\n",
    "        #                   'ystr':r'msd(A$^2$)',\n",
    "                                'ndecade_x':2,\n",
    "                            'bbox_to_anchor':(-0.05,0.23,0.5,0.5),\n",
    "    #                       'title':'png/msd_temp_nicocr_fit.png'\n",
    "                               },\n",
    "                    )\n",
    "            \n",
    "            #--- check if decrease in tc leads to fewere points\n",
    "#             npoint_filtrd = np.sum(self.filtr)\n",
    "#             if self.verbose:\n",
    "#                 print('npoint_filtrd=',npoint_filtrd)\n",
    "#             #if indx > 0:\n",
    "#             if npoint_filtrd == npoint_filtrd0 and indx > 0:\n",
    "#                 continue\n",
    "# #                    , '%s >= %sdecrease ndecades!'%(npoint_filtrd,npoint_filtrd0)\n",
    "#             npoint_filtrd0 = npoint_filtrd\n",
    "            \n",
    "            #--- assign\n",
    "            self.npoin[indx] = np.sum(self.filtr)\n",
    "            if self.npoin[indx] == self.npoin[indx-1] and indx > 0:\n",
    "                continue\n",
    "            self.exponents[indx] = self.popt[-1]\n",
    "            x = self.temps[ 0 ]\n",
    "            self.error[indx] = 0.5*(self.exponent[x][1]-self.exponent[x][2])\n",
    "        \n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "\n",
    "    symbols = utl.Symbols()\n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "\n",
    "    temps = [1200] #[1000,1200,1400,1600,1800,2000]\n",
    "    indices = [1] #range(10)\n",
    "    for temperature, indx in zip(temps,indices):\n",
    "        try:\n",
    "            rb = Robustness([temperature],8,\n",
    "#                            verbose = True\n",
    "\n",
    "                            )\n",
    "\n",
    "            #--- parse data\n",
    "#            rb.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "            rb.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "#            rb.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "                                rb.temps_runs ))\n",
    "                     )\n",
    "\n",
    "            #--- plot average\n",
    "            if rb.nrun > 1:\n",
    "                print('ensemble average')\n",
    "                rb.EnsAverage(log_scale=False,n_bins_per_decade=4)\n",
    "#                 rb.PlotAverage(**{\n",
    "#                           'yscale':'log',\n",
    "#                           'xscale':'log',\n",
    "#         #                   'xlim':(1e-10,1e-3),\n",
    "#         #                   'ylim':(1e-4,1e-1),\n",
    "#         #                     'xstr':r'$t\\mathrm{(s)}$',\n",
    "#         #                   'ystr':r'msd(A$^2$)',\n",
    "# #                            'title':'png/msd_temp_cantor.png',\n",
    "#                 })\n",
    "            #\n",
    "            #--- fit\n",
    "            #\n",
    "            rb.FitRange(decades=10)\n",
    "            rb.Fitting()\n",
    "\n",
    "\n",
    "            #--- get data\n",
    "            filtr = np.all([rb.exponents>0,rb.exponents<2],axis=0)\n",
    "            utl.PltErr(rb.xrange[filtr],rb.exponents[filtr],yerr=rb.error[filtr],\n",
    "                       attrs=symbols.GetAttrs(count=indx%7),\n",
    "                       ax=ax,\n",
    "                        Plot=False,\n",
    "                      )\n",
    "        except:\n",
    "            print('increase fit range!')\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "\n",
    "    utl.PltErr(ax.axis()[:2],[1,1],Plot=False,ax=ax,\n",
    "                attrs={'fmt':'-.','color':'red'},\n",
    "                       ylim=(0,2),\n",
    "                      xscale='log',\n",
    "                       DrawFrame=DRAW_FRAME,\n",
    "                       title='png/exponentH_ni_T%sK.png'%temperature,\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### per type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "    symbols=utl.Symbols()\n",
    "    legends = Legends()\n",
    "    legends.Set(bbox_to_anchor=(1.0,0.5,0.5,0.5))\n",
    " \n",
    "                       \n",
    "    ntype = 5\n",
    "    for itype in range(1,ntype+1):\n",
    "        temp = Temperature(#[1000],3\n",
    "                           list(map(int,np.linspace(1000,1400,11))),3\n",
    "                          )\n",
    "        temp.Parse( list(map(lambda x:'CantorNatom16KTemp%sK_ensemble/Run%s/msd/msd_type%s.txt'%(x[0],x[1],itype),\n",
    "                            temp.temps_runs ))\n",
    "                  )\n",
    "        #\n",
    "  #      print('single realizations')\n",
    "  #      temp.Plot()\n",
    "        #\n",
    "        print('ensemble average: type %s'%itype)\n",
    "        temp.EnsAverage()\n",
    "#         temp.PlotAverage()\n",
    "#         #\n",
    "        temp.Fit(#Plot=True,\n",
    "        #         verbose=True\n",
    "        )\n",
    "#         temp.PlotDiff()\n",
    "        \n",
    "        #--- plot\n",
    "        utl.PltErr(1/np.array(list(temp.Diffusion.keys())),\n",
    "                   list(map(lambda x:temp.Diffusion[x],list(temp.Diffusion.keys()))),\n",
    "                       Plot=False,\n",
    "                   ax=ax,\n",
    "                   attrs=symbols.GetAttrs(count=(itype-1)%7,label=r'$%s$'%temp),\n",
    "                 )\n",
    "    utl.PltErr(None,None,\n",
    "               ax=ax,\n",
    "               yscale='log',\n",
    "               ylim=(1e-15,1e-11),\n",
    "              xstr=r'$1/T(K^{-1})$',\n",
    "              ystr=r'$D(m^2/s)$',\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tauu = temp.time_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wait times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stats(Temperature):\n",
    "    def __init__(self,temp_range,nrun,verbose=False):\n",
    "        Temperature.__init__(self,temp_range,nrun)\n",
    "        self.verbose = verbose\n",
    "    #\n",
    "    def PlotWaitTimes(self,scale=False,\n",
    "                      scalePowerLaw=False,\n",
    "                      shift=False,\n",
    "                      n_per_decade=6,\n",
    "                      **kwargs):\n",
    "        #\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=(1.0,0.5,0.5,0.5))\n",
    "        #\n",
    "        self.mean_rate = {}\n",
    "        kount = 0\n",
    "        #\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp\n",
    "            data = self.data[kount:kount+self.nrun]\n",
    "            data = list(map(lambda x:self.GetWaitTimes(x),data))\n",
    "            if self.verbose:\n",
    "                print('data.shape (per temperature):',np.array(data).shape)\n",
    "            data = np.concatenate(data) #,axis=0)\n",
    "            rate = 1.0 / data.mean()\n",
    "            self.mean_rate[temp] = [ rate, rate*(1/len(data)**0.5)]\n",
    "            if scale:\n",
    "                data /= data.mean() \n",
    "            if self.verbose:\n",
    "                print('data.shape (concatenated):',data.shape)\n",
    "            #--- histogram\n",
    "            hist, bin_edges, err = utl.GetPDF(data,n_per_decade=n_per_decade)\n",
    "            if scalePowerLaw:\n",
    "                alpha = 2 #1.5\n",
    "                hist *= bin_edges ** alpha \n",
    "                err *= bin_edges ** alpha \n",
    "            #--- plot\n",
    "            if shift:\n",
    "                hist *= 10 ** indx \n",
    "                err *= 10 ** indx \n",
    "            utl.PltErr(bin_edges,hist,\n",
    "                          yerr=err,\n",
    "                   attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp,fmt='.'),\n",
    "                   ax = self.ax,\n",
    "                   Plot=False,\n",
    "                          )\n",
    "            kount += self.nrun\n",
    "        self.data_regr = np.c_[bin_edges,hist,err]\n",
    "        #\n",
    "        xhi=self.ax.axis()[1]\n",
    "        xarr = np.logspace(np.log10(xhi)-5.0,np.log10(xhi),32)\n",
    "        utl.PltErr( None,#[tauu,tauu],#None,#xarr if scale else None,\n",
    "                   None,#self.ax.axis()[2:4],#None,#np.exp(-xarr) if scale else None,\n",
    "                   attrs={'fmt':'-.r','lw':2},\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "                   \n",
    "#                    legend=legends.Get(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "            \n",
    "    def PlotAverageRate(self,**kwargs):\n",
    "#        print(list(self.temps_runs))\n",
    "#         self.ax = utl.PltErr(None,#ans[:,0],\n",
    "#                         None,#1e8*ans[:,0],\n",
    "#                         attrs={'fmt':'-.r'},Plot=False)\n",
    "\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=(1.0,0.5,0.5,0.5))\n",
    "        data = list(map(lambda x:self.mean_rate[ x ][0], self.temps))\n",
    "        err = list(map(lambda x:self.mean_rate[ x ][1], self.temps))\n",
    "#             utl.PltErr(data[:,0],data[:,1],\n",
    "#                    yerr=data[:,2],\n",
    "#                    ax = self.ax,\n",
    "#                    attrs=symbols.GetAttrs(count=count%7,label=r'$%s$'%temp),\n",
    "#                    Plot=False,\n",
    "#                   )\n",
    "\n",
    "        utl.PltErr(1.0/np.array(self.temps),\n",
    "                   data,\n",
    "                   yerr=err,\n",
    "                   attrs=symbols.GetAttrs(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "            \n",
    "    \n",
    "    def GetWaitTimes(self,times):\n",
    "#         times = np.array(np.c_[self.lmpData.headers['Time'].iloc[0::2]].flatten())\n",
    "        dtt = times[1:]-times[:-1]\n",
    "        assert not np.any(dtt<0.0)\n",
    "        filtr = dtt > 0.0\n",
    "        return dtt[filtr]\n",
    "\n",
    "    #\n",
    "    def Barries(self):\n",
    "        Barrier = self.lmpData.headers['Barrier'].iloc[1::2]        \n",
    "        hist, bin_edges, err = utl.GetPDF(Barrier,linscale=True,n_per_decade=16)\n",
    "        utl.PltErr(bin_edges,hist,\n",
    "                  yerr=err,\n",
    "                   attrs=symbols.GetAttrs(),\n",
    "                   #yscale='log',\n",
    "                   #xscale='log',\n",
    "                   xstr=r'$\\Delta E$',\n",
    "                   ystr=r'$P(\\Delta E)$'\n",
    "                  )\n",
    "\n",
    "    def func(self,x,k,alpha,beta,t0):\n",
    "        return k*(x/t0)**(-alpha)/(1+(x/t0)**(beta-alpha))\n",
    "    \n",
    "    \n",
    "    def fit(self,edge,hist,err):\n",
    "        xdata=edge\n",
    "        ydata=hist\n",
    "        yerr=err\n",
    "        popt, pcov = curve_fit(self.func,xdata,ydata,\n",
    "                              p0=(1.0,0.4,2,1.0),\n",
    "                               sigma=yerr,\n",
    "                              )\n",
    "\n",
    "        ax=utl.PltErr(edge,hist,yerr=err,\n",
    "                   yscale='log',xscale='log',\n",
    "                      Plot=False\n",
    "                  )\n",
    "        utl.PltErr(edge,self.func(edge,*popt),attrs={'fmt':'-.r'},\n",
    "                   yscale='log',xscale='log',\n",
    "                   ax=ax,\n",
    "                   ylim=(1e-5,1000),\n",
    "                  )\n",
    "#        assert popt[-1]>0\n",
    "        print('k,alpha,beta,t0',popt)\n",
    "        return popt[0]\n",
    "\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    \n",
    "    stats = Stats(\n",
    "         [1000,1200,1400,1600,1800,2000],8,\n",
    "#        [1000,1200,1400,1600,1800,2000],1,\n",
    "#        [2000],8,\n",
    "#        np.arange(1000,1440,80),1,\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse(['msd/event_times.txt'])\n",
    "    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/event_times.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/event_times.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/event_times.txt'%(x[0],x[1]),\n",
    "                        stats.temps_runs ))\n",
    "              )\n",
    "    stats.PlotWaitTimes(scale=True,shift=True,scalePowerLaw=False,\n",
    "                        n_per_decade=6,\n",
    "                        **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "                    'xlim':(1e-3,100),\n",
    "                    'ylim':(1e-8,1e6), #(1e-5,1e2),\n",
    "                    'ndecade_y':2,\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "                   'title':'png/waitTimes_unscaled_cantor.png'},\n",
    "\n",
    "                       )\n",
    "#     stats.PlotWaitTimes(scale=True,scalePowerLaw=True,\n",
    "#                         **{'xscale':'log',\n",
    "#                   'yscale':'log',\n",
    "# #                   'xlim':(1e-9,1e-3),\n",
    "#                    'ylim':(1e-5,1e0), #(1e-5,1e2),\n",
    "# #                           'xstr':r'$\\Delta t$',\n",
    "# #                           'ystr':r'$P(\\Delta t)$',\n",
    "#                    'title':'png/waitTimes_rescaled_ni.png'},\n",
    "#                       )\n",
    "    stats.PlotAverageRate(\n",
    "                **{\n",
    "                    'fontsize':36,\n",
    "#                  'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "#                   'xlim':(1e-9,1e-3),\n",
    "                   'ylim':(1e10,1e13), #(1e-5,1e2),\n",
    "#                           'xstr':r'$1/T$',\n",
    "#                           'ystr':r'$\\lambda$',\n",
    "                   'title':'png/eventRate_cantor.png'},\n",
    "    \n",
    "    )\n",
    "    #\n",
    "#    stats.fit(stats.data_regr[:,0],stats.data_regr[:,1],stats.data_regr[:,2])\n",
    "    #stats.Barries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JumpStats(Temperature):\n",
    "    def __init__(self,temp_range,nrun,verbose=False):\n",
    "        Temperature.__init__(self,temp_range,nrun)\n",
    "        self.verbose = verbose\n",
    "    #\n",
    "    def PlotPdf(self,scale=False,**kwargs):\n",
    "        #\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "        #\n",
    "        self.mean_rate = {}\n",
    "        kount = 0\n",
    "        #\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp\n",
    "            data = self.data[kount:kount+self.nrun][0]\n",
    "            if self.verbose:\n",
    "                print('data.shape (per temperature):',np.array(data).shape)\n",
    "            if self.verbose:\n",
    "                print('data.shape (concatenated):',data.shape)\n",
    "            #--- histogram\n",
    "#            data = np.array(data).flatten()\n",
    "            hist = data[:,1]\n",
    "            bin_edges = data[:,0]\n",
    "            err = data[:,2]\n",
    "            \n",
    "            #--- remove count == 1\n",
    "            filtr = err == hist\n",
    "            hist = hist[~filtr]\n",
    "            bin_edges = bin_edges[~filtr]\n",
    "            err = err[~filtr]\n",
    "            \n",
    "            self.data_regr = np.c_[bin_edges,hist,err]\n",
    "            if scale:\n",
    "                hist *= bin_edges ** self.alpha\n",
    "                err  *= bin_edges ** self.alpha\n",
    "        #--- plot\n",
    "#            temp= [1000,1200,1400,1600,1800,2000][indx]\n",
    "            utl.PltErr(bin_edges,hist,\n",
    "                          yerr=err,\n",
    "                   attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp,fmt='.'),\n",
    "                   ax = self.ax,\n",
    "                   Plot=False,\n",
    "                          )\n",
    "            kount+=self.nrun\n",
    "        #\n",
    "        utl.PltErr(None,\n",
    "                   None,\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "#                     legend=legends.Get(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "            \n",
    "    def func(self,x,k,alpha):\n",
    "        return k*x**alpha\n",
    "    \n",
    "    \n",
    "    def fit(self,edge,hist,err):\n",
    "        xdata=edge\n",
    "        ydata=hist\n",
    "        yerr=err\n",
    "        popt, pcov = curve_fit(self.func,xdata,ydata,\n",
    "                               p0=(1.0e-4,-2.0),\n",
    "                               sigma=2*yerr,\n",
    "                              )\n",
    "\n",
    "        ax=utl.PltErr(edge,hist,yerr=2*err,fmt='.',\n",
    "                   yscale='log',xscale='log',\n",
    "                      Plot=False\n",
    "                  )\n",
    "        utl.PltErr(edge,self.func(edge,*popt),attrs={'fmt':'-.r'},\n",
    "                   yscale='log',xscale='log',\n",
    "                   ax=ax,\n",
    "#                   ylim=(1e-5,1000),\n",
    "                  )\n",
    "#        assert popt[-1]>0\n",
    "        print('k,alpha',popt)\n",
    "        return popt[0]\n",
    "    \n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    \n",
    "    stats = JumpStats(\n",
    "        [1000,1200,1400,1600,1800,2000],\n",
    "#        [1000,1200,1400,1600,1800,2000],\n",
    "#        np.arange(1000,1440,80),\n",
    "        1,\n",
    "#        verbose=True\n",
    "                     )\n",
    "    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/event_jumps.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/event_jumps.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/event_jumps.txt'%(x[0],x[1]),\n",
    "                         stats.temps_runs ))\n",
    "               )\n",
    "    stats.PlotPdf(scale=False,\n",
    "                        **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "                   'xlim':(1e-8,4e0),\n",
    "#                   'ylim':(1e-3,1e1), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "                        'ndecade_x':2,'ndecade_y':2,\n",
    "                    'bbox_to_anchor':(0.56,0.27,0.5,0.5),\n",
    "                   'title':'png/jumpsPdf_cantor.png'},\n",
    "\n",
    "                       )\n",
    "    \n",
    "    #--- rescale\n",
    "    stats.alpha = 2.5 #2.8 #3.0#2.5\n",
    "    stats.PlotPdf(scale=True,\n",
    "                **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "                   'fontsize':32,\n",
    "#                   'xlim':(1e-8,2e0),\n",
    "#                   'ylim':(1e-3,1e1), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "                        'ndecade_x':2,'ndecade_y':2,\n",
    "                   'title':'png/jumpsPdf_rescaled_cantor.png'},\n",
    "\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    stats = JumpStats(\n",
    "        [1000],1,\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/event_jumps.txt'%(x[0],x[1]),\n",
    "    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/event_jumps.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/event_jumps.txt'%(x[0],x[1]),\n",
    "                         stats.temps_runs ))\n",
    "               )\n",
    "    stats.PlotPdf(scale=False,\n",
    "                        **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "                   'xlim':(1e-8,4e0),\n",
    "#                   'ylim':(1e-3,1e1), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "                        'ndecade_x':2,'ndecade_y':2,\n",
    "                    'bbox_to_anchor':(0.56,0.27,0.5,0.5),\n",
    "#                    'title':'png/jumpsPdf_nicocr.png'\n",
    "                          },\n",
    "\n",
    "                       )\n",
    "    filtr = np.all([stats.data_regr[:,0]>1e-3,stats.data_regr[:,0]<2e-1],axis=0)\n",
    "    stats.fit(stats.data_regr[:,0][filtr],stats.data_regr[:,1][filtr],stats.data_regr[:,2][filtr])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Energy = lmpData.headers['Energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            data = self.data[kount:kount+self.nrun]\n",
    "            if self.verbose:\n",
    "                print('data.shape:',np.array(data).shape)\n",
    "#             print('np.array(data):',np.array(data))\n",
    "#             pdb.set_trace()\n",
    "    \n",
    "            filtr = list(map(lambda x:x.shape[0] > 0,data)) #--- filter empty arrays\n",
    "    \n",
    "            data = np.concatenate(np.array(data)[filtr]) #,axis=0)\n",
    "            self.data_averaged[ temp ] = self.hist(data,log_scale)\n",
    "            kount += self.nrun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sampled energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class EnergyStats(Temperature):\n",
    "    def __init__(self,temp_range,nrun,verbose=False):\n",
    "        Temperature.__init__(self,temp_range,nrun)\n",
    "        self.verbose = verbose\n",
    "    #\n",
    "    def GetWaitTimes(self,times):\n",
    "        times = times[0::2]\n",
    "        dtt = times[1:]-times[:-1]\n",
    "        assert not np.any(dtt<0.0)\n",
    "#        filtr = dtt > 0.0\n",
    "        return dtt#[filtr]\n",
    "    #\n",
    "    def PlotPdf(self,shift=False,column_energy = 0,n_per_decade=8,\n",
    "                **kwargs):\n",
    "        #\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs #plotAttrs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "        #\n",
    "        self.mean_rate = {}\n",
    "        #\n",
    "        kount = 0\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp            \n",
    "            data = np.concatenate(list(map(lambda x: self.data[x][:,column_energy],range(kount,kount+self.nrun))))\n",
    "            #--- remove zeros\n",
    "            data = data[data > 0.0]\n",
    "            if self.verbose:\n",
    "                print('data.shape (per temperature):',np.array(data).shape)\n",
    "            if self.verbose:\n",
    "                print('data.shape (concatenated):',data.shape)\n",
    "            #--- histogram\n",
    "#            data = np.array(data).flatten()\n",
    "            #--- histogram\n",
    "            hist, bin_edges, err = utl.GetPDF(data,n_per_decade=n_per_decade)\n",
    "        \n",
    "            #--- filtr\n",
    "            filtr = hist == err\n",
    "            hist = hist[~filtr]\n",
    "            bin_edges = bin_edges[~filtr]\n",
    "            err = err[~filtr]\n",
    "        #--- plot\n",
    "            if shift:\n",
    "                hist *= 100**indx if shift else 1\n",
    "                err *= 100**indx if shift else 1\n",
    "\n",
    "            utl.PltErr(bin_edges,hist,\n",
    "                          yerr=err,\n",
    "                   attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp), #,fmt='.'),\n",
    "                   ax = self.ax,\n",
    "                   Plot=False,\n",
    "                          )\n",
    "            kount += self.nrun\n",
    "        #\n",
    "        utl.PltErr(None,\n",
    "                   None,\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "                   \n",
    "#                    legend=legends.Get(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "        \n",
    "    def PlotPdfConcat(self,scale=False,\n",
    "                      column_energy = 0,\n",
    "                      type_column=0,\n",
    "                      splitByType=True,\n",
    "                      n_per_decade = 8,\n",
    "                      **kwargs):\n",
    "        #\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs #plotAttrs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "        #\n",
    "        self.mean_rate = {}\n",
    "        kount = 0\n",
    "        #\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp            \n",
    "#            data = np.concatenate(list(map(lambda x: self.data[x][:,column_energy],range(indx,indx+self.nrun))))\n",
    "            data = np.concatenate(list(map(lambda x: self.data[x],range(kount,kount+self.nrun))))\n",
    "#             types = np.concatenate(list(map(lambda x: self.data[x][:,type_column],range(indx,indx+self.nrun))))\n",
    "            #--- remove zeros\n",
    "#            data = data[data > 0.0]\n",
    "            if self.verbose:\n",
    "                print('data.shape (per temperature):',np.array(data).shape)\n",
    "            if self.verbose:\n",
    "                print('data.shape (concatenated):',data.shape)\n",
    "            #--- histogram\n",
    "#            data = np.array(data).flatten()\n",
    "            #--- histogram\n",
    "            data_concat = data.copy() if indx ==0 else np.concatenate([data_concat,data]) #np.c_[types,data] if indx ==0 else\\\n",
    "                        #np.concatenate([data_concat,np.c_[types,data]])\n",
    "            kount += self.nrun\n",
    "        if self.verbose:\n",
    "            print('type.shape (concatenated):',data_concat.shape)\n",
    "        \n",
    "        #--- split by type\n",
    "        if splitByType:\n",
    "            df=pd.DataFrame(np.c_[data_concat[:,type_column],data_concat[:,column_energy]],\n",
    "                            columns=['type','dE'])\n",
    "            types=df.groupby(by='type').groups\n",
    "            for itype in types:\n",
    "                indices = types[itype]\n",
    "                elist = np.array(df['dE'].iloc[indices])\n",
    "                if self.verbose:\n",
    "                    print('elist.shape:',elist.shape)\n",
    "\n",
    "                #--- histogram\n",
    "                hist, bin_edges, err = utl.GetPDF(elist,n_per_decade=n_per_decade)\n",
    "\n",
    "                #--- filtr\n",
    "                filtr = hist == err\n",
    "                hist = hist[~filtr]\n",
    "                bin_edges = bin_edges[~filtr]\n",
    "                err = err[~filtr]\n",
    "                #--- plot\n",
    "                if scale:\n",
    "                    hist *= 1000**int(itype)\n",
    "                    err *= 1000**int(itype)\n",
    "                utl.PltErr(bin_edges,hist,\n",
    "                              yerr=err,\n",
    "                       attrs=symbols.GetAttrs(count=int(itype-1)%7,label=r'$%s$'%itype), #,fmt='.'),\n",
    "                       ax = self.ax,\n",
    "                       Plot=False,\n",
    "                              )\n",
    "        else:\n",
    "                data = data_concat[:,column_energy]\n",
    "                data = data[data > 0.0]\n",
    "\n",
    "                #--- histogram\n",
    "                hist, bin_edges, err = utl.GetPDF(data,n_per_decade=n_per_decade)\n",
    "\n",
    "                #--- filtr\n",
    "                filtr = hist == err\n",
    "                hist = hist[~filtr]\n",
    "                bin_edges = bin_edges[~filtr]\n",
    "                err = err[~filtr]\n",
    "                #--- plot\n",
    "#                 if scale:\n",
    "#                     hist *= 100**int(itype)\n",
    "#                     err *= 100**int(itype)\n",
    "                utl.PltErr(bin_edges,hist,\n",
    "                              yerr=err,\n",
    "                       attrs=symbols.GetAttrs(count=0), #,label=r'$%s$'%itype),#,fmt='.'),\n",
    "                       ax = self.ax,\n",
    "                       Plot=False,\n",
    "                              )\n",
    "        #\n",
    "        utl.PltErr(None,\n",
    "                   None,\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "\n",
    "#                        legend=legends.Get(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "\n",
    "    def Scatter(self,shift=False,nevery=1,**kwargs):\n",
    "        kb_inv=8.61732814974056e05\n",
    "        \n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=Symbols(markersizes=np.array([10,10,10,12,12,12,10])*8)\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs #plotAttrs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "\n",
    "        #\n",
    "        column_energy = 0\n",
    "        column_time = 3\n",
    "        kount = 0\n",
    "        for indx in range(0,len(self.temps),nevery):\n",
    "            temp = self.temps[indx]\n",
    "            #--- concat. data for each temp            \n",
    "            data_energy = np.concatenate(list(map(lambda x: self.GetEnergy(self.data[x][:,column_energy]),\n",
    "                                                  range(kount,kount+self.nrun))))\n",
    "            #--- wait_times\n",
    "            data = self.data[indx:indx+self.nrun]\n",
    "            data_waitTimes = np.concatenate(list(map(lambda x: self.GetWaitTimes(self.data[x][:,column_time]),\n",
    "                                                     range(kount,kount+self.nrun))))\n",
    "\n",
    "            if self.verbose:\n",
    "                print('data_energy.shape (per temperature):',np.array(data_energy).shape)\n",
    "                print('data_waitTimes.shape (per temperature):',np.array(data_waitTimes).shape)\n",
    "            #--- plot scatter\n",
    "            scale = 1e2 ** indx if shift else 1\n",
    "            filtr = data_waitTimes > 0\n",
    "#             utl.PltErr(data_energy[filtr]*kb_inv/temp,scale*data_waitTimes[filtr],\n",
    "#                         attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp,fmt='.',alpha=1.0),\n",
    "#                         ax = self.ax,\n",
    "#                         Plot=False,\n",
    "#                         )\n",
    "            self.ax.scatter(data_energy[filtr]*kb_inv/temp,scale*data_waitTimes[filtr],\n",
    "                        **symbols.GetAttrsScatter(count=indx%7,label=r'$%s$'%temp,fmt='.',alpha=0.1/2),\n",
    "                       )\n",
    "            kount += self.nrun\n",
    "            #--- plot average\n",
    "#             nbins = 8\n",
    "#             count, _=np.histogram(data_energy[filtr],bins=nbins)\n",
    "#             xsum, _=np.histogram(data_energy[filtr],weights=data_energy[filtr],bins=nbins)\n",
    "#             ysum, _=np.histogram(data_energy[filtr],weights=data_waitTimes[filtr],bins=nbins)\n",
    "#             ysum /= count\n",
    "# #            ysum =10 ** ysum \n",
    "#             xsum /= count\n",
    "#             #---\n",
    "#             utl.PltErr(xsum,ysum,\n",
    "#                         attrs=symbols.GetAttrs(count=(indx)%7,label=r'$%s$'%temp,fmt='.'),\n",
    "#                         ax = self.ax,\n",
    "#                         Plot=False,\n",
    "#                         )\n",
    "        \n",
    "        \n",
    "        utl.PltErr(None,\n",
    "                   None,\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "                    legend=legends.Get(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "\n",
    "    def GetEnergy(self,slist):\n",
    "        n=len(slist)\n",
    "        return slist[1:n:2]\n",
    "            \n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    \n",
    "    stats = EnergyStats(\n",
    "        [1000,1200,1400,1600,1800,2000],8,\n",
    "#        [1000,1400,1800,2000],8,\n",
    "#        [1000, 1400,1800],8,\n",
    "        #        np.arange(1000,1440,40),1,\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "                         stats.temps_runs ))\n",
    "               )\n",
    "    stats.PlotPdf(shift=True,n_per_decade=10,\n",
    "                        **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "#                   'xlim':(1e-3,1e0),\n",
    "#                   'ylim':(1e-2,1e2), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "                        'ndecade_y':2,\n",
    "                   'title':'png/BarrierPdf_cantor.png'},\n",
    "\n",
    "                       )\n",
    "    \n",
    "#     stats.PlotPdfConcat(scale=False,\n",
    "#                         splitByType = False,\n",
    "#                         **{'xscale':'log',\n",
    "#                       'yscale':'log',\n",
    "#     #                   'xlim':(1e-3,1e0),\n",
    "# #                        'ylim':(1e-2,1e2), #(1e-5,1e2),\n",
    "#     #                           'xstr':r'$\\Delta t$',\n",
    "#     #                           'ystr':r'$P(\\Delta t)$',\n",
    "#     #                        'ndecade_x':2,'ndecade_y':2,\n",
    "#     #                   'title':'png/BarrierPdf_cantor.png'\n",
    "#                           },\n",
    "#                        )\n",
    "\n",
    "    stats.Scatter(nevery=2, shift = True,                        \n",
    "                **{'xscale':'linear',\n",
    "                  'yscale':'log',\n",
    "#                   'xlim':(1e-3,1),\n",
    "#                   'ylim':(1e-3,1e1), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "#                     'bbox_to_anchor':(0.56,0.27,0.5,0.5),\n",
    "                        'ndecade_y':2,\n",
    "                   'title':'png/twVsEnergy_nicocr.png',\n",
    "                  }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    \n",
    "    stats = EnergyStats(\n",
    "        [1000,1200,1400,1600,1800,2000],8,\n",
    "#        [2000],8,\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "                         stats.temps_runs ))\n",
    "               )\n",
    "    stats.PlotPdf(shift=True,column_energy=3,\n",
    "                        **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "#                   'xlim':(1e-3,1e-1),\n",
    "#                    'ylim':(1e-2,1e0), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "                        'ndecade_x':1,'ndecade_y':2,\n",
    "                    'bbox_to_anchor':(0.4,0.13,0.5,0.5),\n",
    "                   'title':'png/BarrierPdf_nicocr.png'},\n",
    "\n",
    "                       )\n",
    "\n",
    "#     stats.PlotPdfConcat(scale=True, \n",
    "#                         column_energy=3,\n",
    "#                         splitByType = False,\n",
    "#                         n_per_decade=10,\n",
    "#                         **{'xscale':'log',\n",
    "#                   'yscale':'log',\n",
    "# #                   'xlim':(1e-3,1e-1),\n",
    "# #                   'ylim':(1e-2,1e0), #(1e-5,1e2),\n",
    "# #                           'xstr':r'$\\Delta t$',\n",
    "# #                           'ystr':r'$P(\\Delta t)$',\n",
    "# #                        'ndecade_x':2,'ndecade_y':2,\n",
    "# #                   'title':'png/BarrierPdf_cantor.png'\n",
    "#                           },\n",
    "\n",
    "#                        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#alpha=-0.4\n",
    "\n",
    "Emin=1e-2\n",
    "Emax=1e1\n",
    "n=100000\n",
    "for alpha in [-1]:\n",
    "    xmax=1/Emin**alpha\n",
    "    xmin=1/Emax**alpha\n",
    "    x=np.random.uniform(low=xmin,high=xmax,size=n)\n",
    "    #E=np.exp(-E)\n",
    "    E=x**-(1/alpha)\n",
    "    hist, edge,err = utl.GetPDF(E,n_per_decade=4)\n",
    "    ax=utl.PltErr(edge,hist,yerr=err,\n",
    "               yscale='log',xscale='log',Plot=False,\n",
    "              )\n",
    "\n",
    "    utl.PltErr(edge,1/edge**(1+alpha),yerr=err,attrs={'fmt':'-.r'},\n",
    "               yscale='log',xscale='log',\n",
    "               ax=ax\n",
    "              )\n",
    "\n",
    "    #\n",
    "    lambdaa=np.exp(-E)\n",
    "    lambdaa = lambdaa[lambdaa>0]\n",
    "    hist, edge,err = utl.GetPDF(lambdaa,n_per_decade=32)\n",
    "    utl.PltErr(edge,hist,yerr=err,\n",
    "               yscale='log',xscale='log',\n",
    "               xlim=(1e-10,1),\n",
    "              )\n",
    "\n",
    "    sarr = np.c_[list(map(lambda x:np.random.exponential(1/x,size=1),lambdaa))].flatten()\n",
    "    hist, edge,err = utl.GetPDF(sarr,n_per_decade=4)\n",
    "    ax=utl.PltErr(edge,hist*edge**0,yerr=err*edge**0,\n",
    "               yscale='log',xscale='log',\n",
    "                  Plot=False\n",
    "              )\n",
    "    utl.PltErr(edge,1/edge**(1.5+alpha),attrs={'fmt':'-.r'},\n",
    "               yscale='log',xscale='log',\n",
    "               ax=ax\n",
    "              )\n",
    "    beta=fit(edge,hist,err)\n",
    "    print(beta)\n",
    "    plt.scatter(alpha,beta)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x,beta,k,x0,x1):\n",
    "#    return k/(1+(x/x0)**beta)\n",
    "    return k*np.exp(-x/x1)/(1+(x/x0)**beta)\n",
    "    \n",
    "def fit(edge,hist,err):\n",
    "    xdata=edge\n",
    "    ydata=hist\n",
    "    yerr=err\n",
    "    popt, pcov = curve_fit(func,xdata,ydata,\n",
    "                          p0=(2,1,10,1e3),\n",
    "                           sigma=yerr,\n",
    "                          )\n",
    "\n",
    "    ax=utl.PltErr(edge,hist,yerr=err,\n",
    "               yscale='log',xscale='log',\n",
    "                  Plot=False\n",
    "              )\n",
    "    utl.PltErr(edge,func(edge,*popt),attrs={'fmt':'-.r'},\n",
    "               yscale='log',xscale='log',\n",
    "               ax=ax,\n",
    "               ndecade_x=4,\n",
    "              )\n",
    "    assert popt[-1]>0\n",
    "    return popt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbt=1000*8.61732814974056e-05\n",
    "E=5e-2\n",
    "print('%e'%(1.0/(1e-13*np.exp(E/kbt))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(utl.GetPDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "help(np.random.exponential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    \n",
    "    stats = EnergyStats(\n",
    "#        [1000,1200,1400,1600,1800,2000],8,\n",
    "        [2000],8\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/eventID_barrier_catalog_type5.txt'%(x[0],x[1]),\n",
    "    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/eventID_barrier_catalog_type3.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "                         stats.temps_runs ))\n",
    "               )\n",
    "\n",
    "    stats.PlotPdf( \n",
    "                        column_energy=2,\n",
    "                        splitByType = False,\n",
    "                        n_per_decade = 8,\n",
    "                        **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "#                   'xlim':(1e-3,1e0),\n",
    "#                   'ylim':(1e-3,1e2), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "#                        'ndecade_x':2,'ndecade_y':2,\n",
    "#                   'title':'png/BarrierPdf_cantor.png'\n",
    "                          },\n",
    "\n",
    "                       )\n",
    "\n",
    "    \n",
    "\n",
    "#     stats.Scatter(nevery=2,                        \n",
    "#                 **{'xscale':'linear',\n",
    "#                   'yscale':'log',\n",
    "#                    'xlim':(0,1),\n",
    "# #                   'ylim':(1e-3,1e1), #(1e-5,1e2),\n",
    "# #                           'xstr':r'$\\Delta t$',\n",
    "# #                           'ystr':r'$P(\\Delta t)$',\n",
    "#                         'ndecade_y':2,\n",
    "#                    'title':'png/twVsEnergy_cantor.png',\n",
    "#                   }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times=lmpData.headers['Time']\n",
    "plt.plot(times,np.ones(len(times)),'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt=np.array(times.iloc[0:-1:2])\n",
    "dt=tt[1:]-tt[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Barrier=lmpData.headers['Barrier']\n",
    "\n",
    "plt.plot(Barrier,'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barrier.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barrier = np.array(Barrier.iloc[1:-1:2])\n",
    "plt.scatter(dt,barrier[:-1])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lmpData.headers['Time'],Energy,'-o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "497.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
