{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parsing configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "confParser = configparser.ConfigParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf. file sections: ['parameters', 'flags', 'MsdAnalysis', 'EnergyBarrier', 'SroAnalysis', 'input files', 'Atomic Radius']\n"
     ]
    }
   ],
   "source": [
    "#--- parse conf. file\n",
    "confParser.read('configuration.ini')\n",
    "print('conf. file sections:',confParser.sections())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'LammpsPostProcess' from '../../HeaDef/postprocess/LammpsPostProcess.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(confParser['input files']['lib_path'])\n",
    "\n",
    "#--- system libraries\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "import traceback\n",
    "import os\n",
    "import scipy.interpolate as scp_int\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "import warnings\n",
    "import matplotlib\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "from matplotlib import patches\n",
    "import sys\n",
    "import sklearn\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "import patsy\n",
    "from sklearn import linear_model, mixture\n",
    "import sklearn.mixture as skm\n",
    "from scipy import optimize\n",
    "import scipy\n",
    "import re\n",
    "from functools import reduce\n",
    "import time\n",
    "import fnmatch\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "#\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#--- user modules\n",
    "import LammpsPostProcess as lp\n",
    "#import LammpsPostProcess2nd as lpp\n",
    "#import utilityy as utll\n",
    "import utility as utl\n",
    "#from utility import *\n",
    "import imp\n",
    "#imp.reload(lpp)\n",
    "imp.reload(utl)\n",
    "imp.reload(lp)\n",
    "#imp.reload(utll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Symbols:\n",
    "    def __init__(self,\n",
    "                markersizes=[10,10,10,12,12,12,10],\n",
    "                ):\n",
    "        self.colors = ['black','red','green','blue','cyan','brown','grey','magenta','orange','yellow']\n",
    "        self.fillstyles=['white',None,'white',None,'white',None,'white',None,'white',None,'white',None,'white',None,'white',None]\n",
    "        self.markers=['o','s','D','^','<','>','v']\n",
    "        self.markersizes=markersizes\n",
    "        self.nmax=7\n",
    "        \n",
    "    def GetAttrs(self,count=0,label='',nevery=1,fmt='.-',zorder=1,alpha=1):\n",
    "        if count > self.nmax:\n",
    "            print('index out of list bound!')\n",
    "            return \n",
    "        attrs={ 'color':self.colors[count],\n",
    "            'markersize':self.markersizes[count],\n",
    "            'marker':self.markers[count],\n",
    "            'markerfacecolor':self.colors[count],\n",
    "            'markeredgecolor':'white', #'black' if not self.fillstyles[count] else None,\n",
    "            'label':label,\n",
    "           'markevery':nevery,\n",
    "           'errorevery':nevery,\n",
    "           'markeredgewidth':1.75,\n",
    "            'linewidth':1, \n",
    "           'barsabove':None,\n",
    "           'capsize':5,\n",
    "           'capthick':1,\n",
    "           'elinewidth':1,\n",
    "           'fmt':fmt,\n",
    "             'zorder':zorder,\n",
    "               'alpha':alpha\n",
    "         }\n",
    "        return attrs\n",
    "    \n",
    "    def GetAttrs2nd(self,count=0,label='',nevery=1,fmt='.-',zorder=1):\n",
    "        '''\n",
    "        empty symbols\n",
    "        '''\n",
    "        if count > self.nmax:\n",
    "            print('index out of list bound!')\n",
    "            return \n",
    "        attrs={ 'color':self.colors[count],\n",
    "            'markersize':self.markersizes[count],\n",
    "            'marker':self.markers[count],\n",
    "            'markerfacecolor':'white',\n",
    "#            'markeredgecolor':'black' if not self.fillstyles[count] else None,\n",
    "            'label':label,\n",
    "           'markevery':nevery,\n",
    "           'errorevery':nevery,\n",
    "           'markeredgewidth':1.75,\n",
    "            'linewidth':1, \n",
    "           'barsabove':None,\n",
    "           'capsize':5,\n",
    "           'capthick':1,\n",
    "           'elinewidth':1,\n",
    "           'fmt':fmt,\n",
    "            'zorder':zorder,\n",
    "          }\n",
    "        return attrs\n",
    "\n",
    "    def GetAttrsScatter(self,count=0,label='',nevery=1,fmt='.-',zorder=1,alpha=0.5):\n",
    "        if count > self.nmax:\n",
    "            print('index out of list bound!')\n",
    "            return \n",
    "        attrs={ 'color':self.colors[count],\n",
    "            's':self.markersizes[count],\n",
    "            'marker':self.markers[count],\n",
    "#            'markerfacecolor':self.colors[count],\n",
    "            'edgecolors':'white', #'black' if not self.fillstyles[count] else None,\n",
    "            'label':label,\n",
    "#            'markevery':nevery,\n",
    "#           'errorevery':nevery,\n",
    "#            'markeredgewidth':1.75,\n",
    "            'linewidth':1, \n",
    "#            'barsabove':None,\n",
    "#            'capsize':5,\n",
    "#            'capthick':1,\n",
    "#            'elinewidth':1,\n",
    "#            'fmt':fmt,\n",
    "             'zorder':zorder,\n",
    "               'alpha':alpha\n",
    "         }\n",
    "        return attrs\n",
    "    \n",
    "    \n",
    "class Legends:\n",
    "    def __init__(self\n",
    "                ):\n",
    "        pass\n",
    "    def Set(self,fontsize=20,\n",
    "                 labelspacing=0,\n",
    "                 **kwargs\n",
    "#                 bbox_to_anchor=(0.5,0.48,0.5,0.5),\n",
    "           ):\n",
    "        self.attrs = {'frameon':False,'fontsize':fontsize,\n",
    "                   'labelspacing':labelspacing,\n",
    "                      'handletextpad':.2,\n",
    "                   'handlelength':1,\n",
    "                    **kwargs,\n",
    "                     }\n",
    "    def Get(self):\n",
    "        return self.attrs\n",
    "\n",
    "DRAW_FRAME=(0.23,0.08,0.12,0.07,0.01)\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    matplotlib.rcParams['text.usetex'] = True #--- comment tex stuff!\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Dump File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class ParseConfiguration:\n",
    "    '''\n",
    "    Parse k-art configuration file\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,confParser,verbose=False):\n",
    "\n",
    "        #--- fetch parameters defect_file\n",
    "        self.datFile  = '%s/%s'%(confParser['input files']['input_path'],confParser['input files']['diffusion_file'])\n",
    "        self.lib_path = confParser['input files']['lib_path']\n",
    "        self.nsteps   = eval(confParser['parameters']['kmc_steps']),\n",
    "        self.verbose  = verbose\n",
    "\n",
    "    def Parse(self,fp,nsteps, outpt):\n",
    "        #--- parse dump: call ovito\n",
    "        t0            = time.time()\n",
    "        outpt_headers = 'dumpFile/calcResults.txt'\n",
    "        !ovitos $self.lib_path/OvitosCna.py $fp $outpt 1 7 $outpt_headers\n",
    "        if self.verbose:\n",
    "            print('output dump file=%s s'%(time.time()-t0))\n",
    "\n",
    "        #--- parse dump files\n",
    "        if self.verbose:\n",
    "            print('parsing %s'%(outpt))\n",
    "        t0            = time.time()\n",
    "        self.lmpData  = lp.ReadDumpFile( '%s'%(outpt) ) \n",
    "        self.lmpData.GetCords( ncount = 2*self.nsteps )\n",
    "        if self.verbose:\n",
    "            print('elapsed time=%s s'%(time.time()-t0))\n",
    "            print('time steps:',self.lmpData.coord_atoms_broken.keys())\n",
    "            display(self.lmpData.coord_atoms_broken[0].head())\n",
    "\n",
    "        #--- add timescales\n",
    "        self.lmpData.times = np.loadtxt(self.datFile)[:nsteps,0]\n",
    "\n",
    "        #--- parse headers\n",
    "        data = np.loadtxt(outpt_headers)\n",
    "        if data.shape[1] == 4:\n",
    "            self.lmpData.headers = pd.DataFrame(data,columns=[\"Barrier\", \"Energy\", \"Step\", \"Time\"])\n",
    "        elif data.shape[1] == 2:\n",
    "            self.lmpData.headers = pd.DataFrame(data,columns=[\"Step\", \"Time\"])\n",
    "\n",
    "\n",
    "    def WignerSeitz(self,fp,reference_file):\n",
    "        '''\n",
    "        perform Wigner-Seitz algorithm\n",
    "        '''\n",
    "        outpt = 'dumpFile/dump_defect.xyz'\n",
    "\n",
    "        #--- parse dump: call ovito\n",
    "        if self.verbose:\n",
    "            print('input=',fp)\n",
    "        t0=time.time()\n",
    "        !ovitos $self.lib_path/OvitosCna.py $fp $outpt 1 11 $reference_file\n",
    "        if self.verbose:\n",
    "            print('output dump file=%s s'%(time.time()-t0))\n",
    "\n",
    "        #--- parse dump files\n",
    "        if self.verbose:\n",
    "            print('parsing %s'%(outpt))\n",
    "        t0                  = time.time()\n",
    "        self.lmpData_defect = lp.ReadDumpFile( '%s'%(outpt) ) \n",
    "        self.lmpData_defect.GetCords( ncount = 2*self.nsteps)\n",
    "        if self.verbose:\n",
    "            print('elapsed time=%s s'%(time.time()-t0))\n",
    "\n",
    "        if self.verbose:\n",
    "            print('time steps:',self.lmpData_defect.coord_atoms_broken.keys())\n",
    "            display(self.lmpData_defect.coord_atoms_broken[0].head())\n",
    "\n",
    "        #--- add timescales\n",
    "        self.lmpData_defect.times = np.loadtxt(self.datFile)[:self.nsteps,0]\n",
    "\n",
    "\n",
    "    def Print(self,fout):\n",
    "        '''\n",
    "        dump vacant sites\n",
    "        '''\n",
    "        \n",
    "        times = list( self.lmpData_defect.coord_atoms_broken.keys() )\n",
    "        times.sort()\n",
    "\n",
    "        #--- print dump\n",
    "        !rm $fout\n",
    "        for ii in times:\n",
    "            filtr = self.lmpData_defect.coord_atoms_broken[ii].Occupancy == 0.0\n",
    "            df = self.lmpData_defect.coord_atoms_broken[ii][filtr]\n",
    "            assert df.shape[0] == 1\n",
    "            df.id=1;df.type=1\n",
    "        #    print(df)\n",
    "            atom_current = lp.Atoms(**df)\n",
    "            box  = lp.Box( BoxBounds = self.lmpData_defect.BoxBounds[ii],  AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "            with open(fout,'a') as fp:\n",
    "                lp.WriteDumpFile(atom_current, box).Write(fp, itime = ii,\n",
    "                     attrs=['id', 'type','x', 'y', 'z'],\n",
    "        #                 fmt='%i %i %15.14e %15.14e %15.14e',\n",
    "                                                     )\n",
    "                \n",
    "    def Displacement(self, fp, fout,use_frame_offset=False):\n",
    "        '''\n",
    "        Return total displacements \n",
    "        '''\n",
    "        !rm $fout\n",
    "\n",
    "        #--- fetch parameters\n",
    "        fileCurr = fileRef = fp\n",
    "\n",
    "        #--- call ovito\n",
    "        t0 = time.time()\n",
    "#        pdb.set_trace()\n",
    "        !ovitos $self.lib_path/OvitosCna.py $fileCurr $fout 1 8 $fileRef $use_frame_offset\n",
    "        if self.verbose:\n",
    "            print('output disp:%s s'%(time.time()-t0))\n",
    "\n",
    "        #--- parse disp files\n",
    "        if self.verbose:\n",
    "            print('parsing %s'%fout)\n",
    "        t0 = time.time()\n",
    "        self.lmpDisp = lp.ReadDumpFile( fout )\n",
    "        self.lmpDisp.GetCords( ncount = sys.maxsize )\n",
    "#         if self.verbose:\n",
    "#             print('elapsed time %s s'%(time.time()-t0))\n",
    "#             display(self.lmpDisp.coord_atoms_broken[0].head())\n",
    "\n",
    "    def CommonNeighborAnalysis(self, fp, fout):\n",
    "        '''\n",
    "        common neighbor analysis\n",
    "        '''\n",
    "        !rm fout\n",
    "        !ovitos $self.lib_path/OvitosCna.py $fp $fout 1 0\n",
    "\n",
    "        #--- parse dump files\n",
    "        print('parsing %s'%(fout))\n",
    "        self.lmpCna = lp.ReadDumpFile( '%s'%(fout) ) \n",
    "        self.lmpCna.GetCords( ncount = sys.maxsize, \n",
    "                        )\n",
    "\n",
    "\n",
    "    def Integrate(self):\n",
    "        times = list(self.lmpDisp.coord_atoms_broken.keys())\n",
    "        times.sort()\n",
    "        x=list(map(lambda x:np.c_[self.lmpDisp.coord_atoms_broken[x].DisplacementX].flatten()[0],times))\n",
    "        y=list(map(lambda x:np.c_[self.lmpDisp.coord_atoms_broken[x].DisplacementY].flatten()[0],times))\n",
    "        z=list(map(lambda x:np.c_[self.lmpDisp.coord_atoms_broken[x].DisplacementZ].flatten()[0],times))\n",
    "        X=np.cumsum(x)\n",
    "        Y=np.cumsum(y)\n",
    "        Z=np.cumsum(z)\n",
    "\n",
    "        for itime, indx in zip(times,range(len(times))):\n",
    "            self.lmpDisp.coord_atoms_broken[itime].DisplacementX=X[indx]            \n",
    "            self.lmpDisp.coord_atoms_broken[itime].DisplacementY=Y[indx]\n",
    "            self.lmpDisp.coord_atoms_broken[itime].DisplacementZ=Z[indx]\n",
    "            \n",
    "    def AddZero(self):\n",
    "        self.lmpDisp.coord_atoms_broken[0] = self.lmpDisp.coord_atoms_broken[1]\n",
    "        self.lmpDisp.coord_atoms_broken[0].DisplacementX=0.0\n",
    "        self.lmpDisp.coord_atoms_broken[0].DisplacementY=0.0\n",
    "        self.lmpDisp.coord_atoms_broken[0].DisplacementZ=0.0\n",
    "        \n",
    "    def PrintOvito( self, title ):\n",
    "        #--- save\n",
    "        try:\n",
    "            os.system('rm %s'%title)\n",
    "        except:\n",
    "            pass\n",
    "        times = list( self.lmpDisp_defect.coord_atoms_broken.keys() )\n",
    "        times.sort()\n",
    "        itime0 = times[ 0 ]\n",
    "        rc = np.c_[ self.lmpDisp_defect.coord_atoms_broken[ itime0 ]['x y z'.split()] ]\n",
    "        for itime in times:\n",
    "            sfile        = open(title,'a')\n",
    "            dx           = np.c_[self.lmpDisp_defect.coord_atoms_broken[ itime ]['DisplacementX  DisplacementY  DisplacementZ'.split()]]\n",
    "            utl.PrintOvito(pd.DataFrame(np.c_[dx+rc].reshape(1,3),columns=['x','y','z']), \n",
    "                       sfile, 'itime=%s'%itime, attr_list=['x', 'y', 'z'])\n",
    "            sfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    !rm -r dumpFile; mkdir dumpFile; mkdir disp\n",
    "    \n",
    "    #--- parse allconf\n",
    "    pc = ParseConfiguration(confParser,verbose=True)\n",
    "    #\n",
    "    pc.Parse('%s/%s'%(confParser['input files']['input_path'],confParser['input files']['dump_file']),\n",
    "            'dumpFile/dump.xyz',\n",
    "            )\n",
    "    \n",
    "    #--- vacancy dynamics based on ws analysis\n",
    "    if eval(confParser['MsdAnalysis']['WignerSeitz']):\n",
    "        pc.WignerSeitz('%s/%s'%(confParser['input files']['input_path'],confParser['input files']['dump_file']),\n",
    "                       '%s/%s'%(confParser['input files']['input_path'],confParser['input files']['pure_crystal'])\n",
    "                      )\n",
    "        #--- output vacant sites\n",
    "        pc.Print('dumpFile/dump_vacant.xyz')\n",
    "    \n",
    "    \n",
    "        #--- vacancy disp\n",
    "        pc.Displacement('dumpFile/dump_vacant.xyz',\n",
    "                        'disp_vacant.xyz',\n",
    "                       use_frame_offset = True, #--- velocity\n",
    "                       )\n",
    "        pc.AddZero() #--- add first timestep\n",
    "        pc.Integrate() #--- get displacements\n",
    "        pc.lmpDisp_defect = pc.lmpDisp\n",
    "        pc.PrintOvito('dumpFile/vacancy_trajectories.xyz')\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    #--- total displacements\n",
    "    pc.Displacement('dumpFile/dump.xyz',\n",
    "                     'disp/disp.xyz')\n",
    "\n",
    "    #--- vacant site based on cna analysis\n",
    "#     pc.CommonNeighborAnalysis( 'dumpFile/dump.xyz',\n",
    "#                      'disp/cna.xyz')\n",
    "\n",
    "    #--- parse allconf_defect\n",
    "    #--- vacant site based on defects\n",
    "    pc_defect = ParseConfiguration(confParser,verbose=True)\n",
    "    pc_defect.Parse('%s/%s'%(confParser['input files']['input_path'],confParser['input files']['defect_file']),\n",
    "                    'dumpFile/dump_defects.xyz',\n",
    "\n",
    "                   )\n",
    "\n",
    "    #--- output timeseries\n",
    "    !mkdir msd\n",
    "    with open('msd/event_times.txt','w') as fp:\n",
    "        np.savetxt(fp,pc.lmpData.times,header='t')\n",
    "    #\n",
    "    with open('msd/timeseries.txt','w') as fp:\n",
    "        np.savetxt(fp,np.c_[pc.lmpData.headers],header='Barrier Energy Step Time')\n",
    "\n",
    "\n",
    "    return pc, pc_defect\n",
    "\n",
    "data, data_defect = main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# times = list(data.lmpDisp_defect.coord_atoms_broken.keys())\n",
    "# times.sort()\n",
    "\n",
    "# x=list(map(lambda x:np.c_[data.lmpDisp_defect.coord_atoms_broken[x].DisplacementX].flatten()[0],times))\n",
    "# y=list(map(lambda x:np.c_[data.lmpDisp_defect.coord_atoms_broken[x].DisplacementY].flatten()[0],times))\n",
    "# z=list(map(lambda x:np.c_[data.lmpDisp_defect.coord_atoms_broken[x].DisplacementZ].flatten()[0],times))\n",
    "\n",
    "# ax=utl.PltErr(None,None,Plot=False)\n",
    "# #utl.PltErr(times[:-1],np.diff(x),ax=ax,Plot=False)\n",
    "# utl.PltErr(times,x,ax=ax,Plot=False)\n",
    "# # utl.PltErr(times[:-1],np.diff(y),ax=ax,Plot=False)\n",
    "# # utl.PltErr(times[:-1],np.diff(z),ax=ax,Plot=False)\n",
    "\n",
    "# utl.PltErr(None,None,title='disp/vel.png',ax=ax, yscale='linear',xlim=(0,75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## msd vs. time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MsDisp:\n",
    "    \n",
    "    def __init__(self, lmpDisp,  \n",
    "                 filtr, \n",
    "                 lmpCna = None,\n",
    "                 skip_times = 0):\n",
    "        '''\n",
    "        returns mean-squared displacements\n",
    "        '''\n",
    "        self.disp = lmpDisp.coord_atoms_broken\n",
    "        try:\n",
    "            self.cna = lmpCna.coord_atoms_broken\n",
    "        except:\n",
    "            pass\n",
    "        self.times = list(lmpDisp.coord_atoms_broken.keys())\n",
    "        self.times.sort()\n",
    "        self.times = self.times[ skip_times: ]\n",
    "#        print(self.times)\n",
    "        self.filtr=filtr\n",
    "        \n",
    "    def Get(self,LOG=False):\n",
    "        '''\n",
    "        returns msd (no temporal window)\n",
    "        '''\n",
    "        if not LOG: #---  mean\n",
    "            msd = list(map(lambda x:(self.disp[x]['DisplacementX']**2+\\\n",
    "                         self.disp[x]['DisplacementY']**2+\\\n",
    "                         self.disp[x]['DisplacementZ']**2).mean(),\n",
    "                    self.times))\n",
    "        else: #--- geometric mean\n",
    "            msd = list(map(lambda x:10**((np.log10(self.disp[x]['DisplacementX']**2+\\\n",
    "                         self.disp[x]['DisplacementY']**2+\\\n",
    "                         self.disp[x]['DisplacementZ']**2)).mean()),\n",
    "                    self.times))\n",
    "        return np.array(msd)\n",
    "        \n",
    "    def GetPdfJumps(self):\n",
    "        '''\n",
    "        pdf's of jumps\n",
    "        '''\n",
    "        cols = ['DisplacementX','DisplacementY','DisplacementZ']\n",
    "        for itime, itime0, count in zip(self.times[1:],self.times[:-1],range(len(self.times))):\n",
    "            df=self.disp[itime][self.filtr]\n",
    "            df0=self.disp[itime0][self.filtr]\n",
    "            veloc = df[cols]-df0[cols]\n",
    "            if count == 0:\n",
    "                df_concat = np.c_[veloc]\n",
    "            else:\n",
    "                df_concat = np.concatenate([df_concat,veloc],axis=0) \n",
    "        df_abs = np.abs(df_concat.flatten())\n",
    "        filtr = df_abs > 0.0\n",
    "        \n",
    "        hist, bin_edges, err = utl.GetPDF(df_abs[filtr],n_per_decade=4)\n",
    "        utl.PltErr(bin_edges,hist, yerr=err,\n",
    "                  yscale='log',\n",
    "                   xscale='log',\n",
    "        #           ylim=(1e-6,1e4)\n",
    "                  )\n",
    "        #\n",
    "        with open('msd/event_jumps.txt','w') as fp:\n",
    "            np.savetxt(fp,np.c_[bin_edges,hist,err],header='bin_edges hist err')\n",
    "\n",
    "        \n",
    "    def WindowAverage(self,ttime,bins_per_decade=4,LOG=False,nmin=1):\n",
    "        '''\n",
    "        returnd msd (include temporal windows)\n",
    "        '''\n",
    "        time_keys = np.arange(0,len(self.times),2) #--- ignore half step\n",
    "        assert len(ttime) == len(time_keys), 'must be of the same size!'\n",
    "\n",
    "        t0=time.time()\n",
    "        cols = 'DisplacementX DisplacementY DisplacementZ'.split()\n",
    "        for shift in range(1,len(time_keys)): #-1):\n",
    "            dt = zip(time_keys,time_keys[shift:]) #--- time tuples\n",
    "            dt_real = list(map(lambda x: x[1]-x[0], zip(ttime,ttime[shift:]))) #--- real time difference\n",
    "            disp    = list(map(lambda x: np.c_[self.disp[x[1]][cols]-self.disp[x[0]][cols]].flatten(),zip(time_keys,time_keys[shift:])))\n",
    "            if shift == 1:\n",
    "                tr_mat=np.c_[dt_real,disp]\n",
    "            else:    \n",
    "                tr_mat = np.concatenate([tr_mat,np.c_[dt_real,disp]],axis=0)\n",
    "\n",
    "        print('1st: t=%s'%(time.time()-t0))\n",
    "\n",
    "        #--- remove dt == 0\n",
    "        filtr1 = tr_mat[:,0] > 0\n",
    "        #--- remove dr=0\n",
    "        filtr2 = ~np.all([tr_mat[:,1]==0.0,tr_mat[:,2]==0.0,tr_mat[:,3]==0.0],axis=0)\n",
    "        #---\n",
    "        filtr = np.all([filtr1,filtr2],axis = 0 )\n",
    "        tr_mat = tr_mat[filtr]\n",
    "        \n",
    "        \n",
    "        return self.Binning(tr_mat,bins_per_decade,nmin=nmin)\n",
    "\n",
    "\n",
    "    def WindowAverage2ndMethod(self,ttime,bins_per_decade=4,LOG=False):\n",
    "        '''\n",
    "        returnd msd (include temporal windows)\n",
    "        '''\n",
    "\n",
    "        time_keys = np.arange(0,len(self.times),2) #--- ignore half step\n",
    "        assert len(ttime) == len(time_keys), 'must be of the same size!'\n",
    "        \n",
    "        tij = MsDisp.GetTijMatrix(ttime)\n",
    "        t0 = time.time()\n",
    "        xsq = self.GetXsqMatrix(time_keys,0)\n",
    "        ysq = self.GetXsqMatrix(time_keys,1)\n",
    "        zsq = self.GetXsqMatrix(time_keys,2)\n",
    "#        print(xsq)\n",
    "        print('2nd: t=%s'%(time.time()-t0))\n",
    "\n",
    "                \n",
    "        #--- remove dt == 0\n",
    "        tij_flat = tij.flatten()\n",
    "        filtr = tij_flat > 0.0\n",
    "        usq = (xsq + ysq + zsq).flatten()\n",
    "#         tr_mat = tr_mat[filtr]\n",
    "# #        print('dt_min=',tr_mat[:,0].min())\n",
    "# #        pdb.set_trace()\n",
    "#        print('t,u=',tij_flat[filtr],usq[filtr])\n",
    "\n",
    "        return MsDisp.Binning2nd(tij_flat[filtr],usq[filtr],bins_per_decade),\\\n",
    "               MsDisp.Binning2nd(tij_flat[filtr],usq[filtr],bins_per_decade, LogScale = False)\n",
    "\n",
    "    def GetXsqMatrix(self,tlist, dim):\n",
    "        n = len(tlist)\n",
    "        xijsqMatrix = np.zeros(n*n).reshape((n,n))\n",
    "        atom_indices = self.FiltrdAtoms(tlist) #--- rows corresponding to filtered frame\n",
    "        key = ['DisplacementX','DisplacementY','DisplacementZ'][dim]\n",
    "        for irow in range(n):\n",
    "            for iatom in atom_indices: \n",
    "                x_peratom_timeseries = self.GetTimeSeriesPerAtom(iatom, tlist, key ) \n",
    "                xijsqMatrix[ irow ] +=  (x_peratom_timeseries - x_peratom_timeseries[ irow ])**2\n",
    "        return xijsqMatrix / len(atom_indices)\n",
    "\n",
    "    def GetTimeSeriesPerAtom(self, atomIndx, tlist, key, vacancy = False ):\n",
    "        return list(map(lambda x:self.disp[x][key].iloc[atomIndx], tlist))\n",
    "\n",
    "\n",
    "    def FiltrdAtoms(self,tlist):\n",
    "        time0 = tlist[0]\n",
    "        return self.disp[time0][self.filtr].index\n",
    "\n",
    "    @staticmethod\n",
    "    def GetTijMatrix(tlist):\n",
    "        tlist = np.array(list(tlist))\n",
    "        n = len(tlist)\n",
    "        tijMatrix = np.zeros(n*n).reshape((n,n))\n",
    "        t0 = time.time()\n",
    "        for irow in range(n):\n",
    "            tijMatrix[ irow ] = tlist - tlist[ irow ]\n",
    "        return tijMatrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def Binning2nd(tlist,usq,bins_per_decade, LogScale = True):\n",
    "        #--- binning\n",
    "        xmin = 0.99*tlist.min()\n",
    "        xmax = 1.01*tlist.max()\n",
    "        if LogScale:\n",
    "            n_decades = int(np.ceil(np.log10(xmax/xmin)))\n",
    "            bins = np.logspace(np.log10(xmin),np.log10(xmax),n_decades*bins_per_decade)\n",
    "        else:\n",
    "            bins = np.linspace(xmin,xmax,32)\n",
    "        #\n",
    "        ysum, edges = np.histogram(tlist,bins=bins,weights=usq)\n",
    "        ysum_sq, edges = np.histogram(tlist,bins=bins,weights=usq*usq)\n",
    "        xsum, edges = np.histogram(tlist,bins=bins,weights=tlist)\n",
    "        count, edges = np.histogram(tlist,bins=bins)\n",
    "        #\n",
    "#        filtr = count > 1\n",
    "        filtr = count > 0\n",
    "        ysum = ysum[filtr]\n",
    "        ysum_sq = ysum_sq[filtr]\n",
    "        xsum = xsum[filtr]\n",
    "        count = count[filtr]\n",
    "        assert not np.any(count == 0), 'incerease bin size!'\n",
    "        #\n",
    "        ysum_sq /= count\n",
    "        ysum /= count\n",
    "        xsum /= count\n",
    "        ysum_sq -= (ysum * ysum)\n",
    "#        assert not np.any(ysum_sq < 0.0), 'print %s'%ysum_sq\n",
    "        \n",
    "        return np.c_[xsum,ysum,(ysum_sq/count)**0.5]\n",
    "    \n",
    "    def VacancyDynamics(self, title='void.xyz',\n",
    "                       **kwargs):\n",
    "        '''\n",
    "        return xyz coordinates associated with vacancy \n",
    "        '''\n",
    "        \n",
    "        #--- unwrapped coordinates\n",
    "        times            = self.times[1:]\n",
    "        times_ref        = self.times[:-1]\n",
    "            \n",
    "\n",
    "        cols             = ['DisplacementX','DisplacementY','DisplacementZ']\n",
    "        xsum_concat=np.array([0,0,0])\n",
    "        for itime, itime_ref in zip(times,times_ref):\n",
    "            df           = self.disp[itime]\n",
    "            df0          = self.disp[itime_ref]\n",
    "            veloc        = pd.DataFrame(np.c_[df0['id'],df[cols]-df0[cols]],columns=['id']+cols)\n",
    "            #\n",
    "#            filtr = self.cna[itime_ref]['StructureType'] == 0.0 #--- neighboring atoms\n",
    "        #--- filter atom type\n",
    "            if 'filtr_type' in kwargs:\n",
    "                filtr = self.cna[itime_ref].type == eval(kwargs['filtr_type'])\n",
    "                defect_atoms = self.cna[itime_ref][filtr].id\n",
    "            else:\n",
    "#                defect_atoms = self.cna[itime_ref].id\n",
    "                defect_atoms_ref = self.cna[itime_ref].id\n",
    "                defect_atoms_current = self.cna[itime].id\n",
    "                defect_atoms = list(set(list(defect_atoms_ref)+list(defect_atoms_current)))\n",
    "\n",
    "            veloc        = utl.FilterDataFrame(veloc,key='id',val=defect_atoms)\n",
    "            #\n",
    "            #indx_max     = np.argmax(list(map(lambda x:np.sum(x*x),np.c_[veloc[cols]])))\n",
    "\n",
    "            xsum         = -np.array(veloc[cols].sum()) #---disp\n",
    "            xsum_concat  = np.c_[xsum_concat,xsum]\n",
    "        xsum_concat      = xsum_concat.T\n",
    "        xv               = xsum_concat.cumsum(axis=0) #--- integrate\n",
    "        #--- add initial position\n",
    "        itime            = times_ref[0]\n",
    "        if 'filtr_type' in kwargs:\n",
    "            filtr = self.cna[itime].type == eval(kwargs['filtr_type'])\n",
    "            defect_atoms = self.cna[itime][filtr].id\n",
    "        else:\n",
    "            defect_atoms     = self.cna[itime].id\n",
    "        disps            = utl.FilterDataFrame(self.disp[itime],key='id',val=defect_atoms)\n",
    "        rc               = np.array(disps[['x','y','z']].iloc[0]) #mean())\n",
    "        #--- print\n",
    "        try:\n",
    "            os.system('rm msd/%s'%title)\n",
    "        except:\n",
    "            pass\n",
    "        for itime in range(xv.shape[0]):\n",
    "            sfile        = open('msd/%s'%title,'a')\n",
    "            utl.PrintOvito(pd.DataFrame(np.c_[xv[itime,:]+rc].reshape(1,3),columns=['x','y','z']), \n",
    "                       sfile, 'itime=%s'%itime, attr_list=['x', 'y', 'z'])\n",
    "            sfile.close()\n",
    "        self.xv          = xv\n",
    "        self.dxv         = xsum_concat\n",
    "        \n",
    "    def msdVacancy(self,ttime,bins_per_decade=4,LOG=False,nmin=1):\n",
    "        '''\n",
    "        returnd msd(t) associated with motion of the vacancy\n",
    "        '''\n",
    "        time_keys        =  np.arange(0,len(self.times),2) #--- ignore half step\n",
    "        assert len(ttime)== len(time_keys), 'must be of the same size!'\n",
    "        time_indices     = np.arange(len(time_keys))\n",
    "        for shift in range(1,len(time_keys)):\n",
    "            dt      = zip(time_keys,time_keys[shift:]) #--- time tuples\n",
    "            dt_real = list(map(lambda x: x[1]-x[0], zip(ttime,ttime[shift:]))) #--- real time difference\n",
    "            disp    = list(map(lambda x: self.xv[x[1]]-self.xv[x[0]],zip(time_indices,time_indices[shift:])))\n",
    "            if shift== 1:\n",
    "                tr_mat=np.c_[dt_real,disp]\n",
    "            else:    \n",
    "                tr_mat = np.concatenate([tr_mat,np.c_[dt_real,disp]],axis=0)\n",
    "                \n",
    "        #--- remove dt == 0\n",
    "        filtr = tr_mat[:,0] > 0\n",
    "        tr_mat = tr_mat[filtr]\n",
    "        return self.Binning(tr_mat,bins_per_decade,nmin=nmin)\n",
    "\n",
    "\n",
    "    def Binning(self,tr_mat,bins_per_decade, nmin=1):\n",
    "        #--- binning\n",
    "        xmin       = 0.99*tr_mat[:,0].min()\n",
    "        xmax       = 1.01*tr_mat[:,0].max()\n",
    "        n_decades  = int(np.ceil(np.log10(xmax/xmin)))\n",
    "        bins       = np.logspace(np.log10(xmin),np.log10(xmax),n_decades*bins_per_decade)\n",
    "        \n",
    "        #\n",
    "        count, _   = np.histogram(tr_mat[:,0],bins=bins)\n",
    "        tsum,  _   = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,0])\n",
    "        filtr      = count >= nmin\n",
    "        #  \n",
    "        xsum, _    = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,1])\n",
    "        ysum, _    = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,2])\n",
    "        zsum, _    = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,3])\n",
    "\n",
    "        xsum_sq, _ = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,1]*tr_mat[:,1])\n",
    "        ysum_sq, _ = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,2]*tr_mat[:,2])\n",
    "        zsum_sq, _ = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,3]*tr_mat[:,3])\n",
    "        #\n",
    "        xsum       = xsum[filtr]\n",
    "        ysum       = ysum[filtr]\n",
    "        zsum       = zsum[filtr]\n",
    "        #\n",
    "        xsum_sq    = xsum_sq[filtr]\n",
    "        ysum_sq    = ysum_sq[filtr]\n",
    "        zsum_sq    = zsum_sq[filtr]\n",
    "        #\n",
    "        tsum       = tsum[filtr]\n",
    "        count      = count[filtr]\n",
    "        assert not np.any(count < nmin), 'incerease bin size!'\n",
    "        #\n",
    "        xsum_sq   /= count\n",
    "        ysum_sq   /= count\n",
    "        zsum_sq   /= count\n",
    "        #\n",
    "        xsum      /= count\n",
    "        ysum      /= count\n",
    "        zsum      /= count\n",
    "        #     \n",
    "        tsum      /= count\n",
    "        #\n",
    "        xsum_sq   -= (xsum * xsum)\n",
    "        ysum_sq   -= (ysum * ysum)\n",
    "        zsum_sq   -= (zsum * zsum)\n",
    "        assert np.all(xsum_sq >= 0) and np.all(ysum_sq >= 0) and np.all(zsum_sq >= 0)\n",
    "        #\n",
    "        var        = ( xsum_sq + ysum_sq + zsum_sq ) / 3.0\n",
    "#        assert not np.any(ysum_sq < 0.0), 'print %s'%ysum_sq\n",
    "        \n",
    "        return np.c_[tsum,var, var * np.sqrt(2.0/count) ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def junk(**kwargs):\n",
    "#     print(kwargs)\n",
    "\n",
    "# junk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomChoice(lmpDisp):\n",
    "    natom = lmpDisp.coord_atoms_broken[0].shape[0]\n",
    "    size=np.min([natom,eval(confParser['MsdAnalysis']['natom'])])\n",
    "    indices = np.random.choice(range(natom),replace=False,\n",
    "                               size=size)\n",
    "    assert indices.shape[ 0 ] == size\n",
    "    filtr = np.zeros(natom,dtype=bool)\n",
    "    filtr[ indices ] = True\n",
    "    assert np.sum(filtr) == indices.shape[0], '%s %s' %(np.sum(filtr), indices.shape[0])\n",
    "    \n",
    "    return filtr\n",
    "\n",
    "def main(data):\n",
    "    \n",
    "    if not eval(confParser['MsdAnalysis']['MsdAnalysis']):\n",
    "        return\n",
    "    \n",
    "    \n",
    "    !mkdir msd\n",
    "    \n",
    "    #----------------------------------\n",
    "    #--- msd: dynamics of vacant site \n",
    "    #--- based on the cna analysis\n",
    "    #----------------------------------\n",
    "    msd          = MsDisp(data.lmpDisp, \n",
    "                         RandomChoice(data.lmpDisp), #--- filter \n",
    "                         data_defect.lmpData,\n",
    "                        )\n",
    "    #---  vacancy\n",
    "    if eval(confParser['MsdAnalysis']['vacancy']):\n",
    "        msd.VacancyDynamics(title='void2.xyz', \n",
    "                            **confParser['MsdAnalysis'])\n",
    "        vac_data     = msd.msdVacancy(data.lmpData.headers['Time'][::2],\n",
    "                                      bins_per_decade=4,LOG=False,nmin=10)\n",
    "        #\n",
    "        with open('msd/msd_vac_cna.txt','w') as fp:\n",
    "#             np.savetxt(fp,vac_data,header='t\\tmsd\\terr')\n",
    "             np.savetxt(fp,vac_data,header='t dx dy dz')\n",
    "\n",
    "#    msd.GetPdfJumps() #--- jump distributions\n",
    "\n",
    "     #--- msd\n",
    "    if eval(confParser['MsdAnalysis']['total']):\n",
    "        ans, ans_lin = msd.WindowAverage2ndMethod(data.lmpData.headers['Time'][::2],\n",
    "                                                  bins_per_decade=4,LOG=False) #---msd\n",
    "    \n",
    "        with open('msd/msd.txt','w') as fp:\n",
    "            np.savetxt(fp,ans,header='t\\tmsd\\terr')\n",
    "        with open('msd/msd_lin.txt','w') as fp:\n",
    "            np.savetxt(fp,ans_lin,header='t\\tmsd\\terr')\n",
    "    #\n",
    "\n",
    "        #--- correlated noise\n",
    "    #     xvv = np.c_[list(map(lambda x:msd.dxv[x]+msd.dxv[x+1],range(1,msd.dxv.shape[0],2)))] #--- include half steps\n",
    "    #     with open('msd/noise.txt','w') as fp:\n",
    "    #         np.savetxt(fp,np.c_[lmpData.headers['Time'][1:-1:2],xvv],header='time dx dy dz')\n",
    "\n",
    "        #---  filter based on atom types\n",
    "        types      = list(set(data.lmpDisp.coord_atoms_broken[0]['type']))\n",
    "        for itype in types:\n",
    "            filtr  = data.lmpDisp.coord_atoms_broken[0]['type'] == itype\n",
    "            msd    = MsDisp( data.lmpDisp,\n",
    "                             filtr, #--- filter \n",
    "                             data_defect.lmpData\n",
    "                           )\n",
    "            ans, _ = msd.WindowAverage2ndMethod(data.lmpData.headers['Time'][::2],\n",
    "                                               bins_per_decade=4,LOG=False)\n",
    "            #--- print\n",
    "            with open('msd/msd_type%s.txt'%itype,'w') as fp:\n",
    "                np.savetxt(fp,ans,header='t\\tmsd\\terr')\n",
    "\n",
    "\n",
    "    #--- correlated noise\n",
    "#    xvv = np.c_[list(map(lambda x:msd.dxv[x]+msd.dxv[x+1],range(1,msd.dxv.shape[0],2)))] #--- include half steps\n",
    "#    with open('msd/noise.txt','w') as fp:\n",
    "#        np.savetxt(fp,np.c_[lmpData.headers['Time'][1:-1:2],xvv],header='time dx dy dz')\n",
    "\n",
    "#     with open('msd/msd_logAveraged.txt','w') as fp:\n",
    "#         np.savetxt(fp,ans_logAveraged,header='t\\tmsd\\terr')\n",
    "\n",
    "\n",
    "\n",
    "    #----------------------------------\n",
    "    #--- msd: dynamics of vacant site \n",
    "    #--- based on the ws analysis\n",
    "    #----------------------------------\n",
    "    if eval(confParser['MsdAnalysis']['WignerSeitz']):\n",
    "        start_frame  = 0\n",
    "        msd          = MsDisp( data.lmpDisp_defect, \n",
    "                              np.ones(data.lmpDisp_defect.coord_atoms_broken[start_frame].shape[0],dtype=bool) #--- filter \n",
    "                            )\n",
    "        ans          = msd.WindowAverage(data.lmpData.headers['Time'][start_frame::2],\n",
    "                                         bins_per_decade= 4,\n",
    "                                         LOG            = False,\n",
    "                                         nmin           = 10,\n",
    "                                                 ) #---msd\n",
    "        !mkdir msd\n",
    "        with open('msd/msd_vac_ws.txt','w') as fp:\n",
    "             np.savetxt(fp,ans,header='t\\tmsd\\terr')\n",
    "\n",
    "\n",
    "\n",
    "main(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy barriers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnergyBarrier:\n",
    "    '''\n",
    "    return energy barriers corresponding to diffusional hopping\n",
    "    '''\n",
    "    def __init__(self,events_directory,evlist_directory,lmpData):\n",
    "        self.events_dir = events_directory\n",
    "        self.evlist_dir = evlist_directory\n",
    "        self.lmpData = lmpData.coord_atoms_broken[0]\n",
    "        \n",
    "    def Parse(self):\n",
    "        '''\n",
    "        parse event files\n",
    "        '''\n",
    "        self.events_id_energy = self.ParseEvents_dir()\n",
    "        self.catalog = self.ParseEvList_dir()\n",
    "        \n",
    "        \n",
    "    def ParseEvents_dir(self):\n",
    "        files = os.listdir(self.events_dir)\n",
    "        d=[]\n",
    "        for sfile in files:\n",
    "            if not '.xyz' in sfile: #--- skip .xyz files \n",
    "                try:\n",
    "                    filee=open('%s/%s'%(self.events_dir,sfile)) #--- open file\n",
    "                    xstrs = filee.readlines()\n",
    "                    event_id = int(xstrs[0].split()[-1]) #--- event id\n",
    "                    barrier = float(xstrs[2].split()[-1]) #--- energy\n",
    "                    ncluster =  int(xstrs[15].split()[-1])                 \n",
    "                    shape_cluster_atoms =  int(xstrs[16].split()[-1])\n",
    "                    atom_id = int(xstrs[17+ncluster].split()[0])\n",
    "                    #print(atom_id)\n",
    "                    d = np.c_[event_id,atom_id,barrier] if len(d) == 0 else\\\n",
    "                    np.concatenate([d,np.c_[event_id,atom_id,barrier]])\n",
    "#                    d.setdefault(event_id,[]).append(barrier) #--- store\n",
    "                except:\n",
    "        #            traceback.print_exc()\n",
    "                    continue\n",
    "            \n",
    "        #--- extract types\n",
    "        df=self.lmpData\n",
    "        atom_ids = d[:,1]\n",
    "        types = utl.FilterDataFrame(df, \n",
    "                    key='id', \n",
    "                    val=atom_ids\n",
    "                   )['type']\n",
    "\n",
    "        return pd.DataFrame(np.c_[types,d],columns=['atom_type','event_id','atom_id','barrier'])\n",
    "\n",
    "    def ParseEvList_dir(self):\n",
    "        files = os.listdir(self.evlist_dir)\n",
    "        events={}\n",
    "        for sfile in files:\n",
    "            try:\n",
    "                kmc_step = int(sfile.split('_')[-1])\n",
    "        #        print(kmc_step)\n",
    "                filee=open('%s/%s'%(self.evlist_dir,sfile)) #--- open file\n",
    "                events[kmc_step] = pd.read_csv(filee,delim_whitespace=True).iloc[1:]#delimiter='')\n",
    "            except:\n",
    "                continue\n",
    "        return events\n",
    "        \n",
    "    def SplitByType(self):\n",
    "        '''\n",
    "        return energies (parsed from catalogs) slipt by atom types\n",
    "        '''\n",
    "        kmc_steps = list(self.catalog.keys())\n",
    "        kmc_steps.sort()\n",
    "\n",
    "\n",
    "        #--- dict based on types\n",
    "        df_concat = {}\n",
    "        types = list(set(self.lmpData.type))\n",
    "        for itype in types:\n",
    "            df_concat[str(itype)] = {}\n",
    "\n",
    "        for kmc_step in kmc_steps: #--- kmc loop\n",
    "            df = self.catalog[kmc_step]\n",
    "            sdict=df.groupby(by='#TypeId').groups #--- group by type\n",
    "            for itype in sdict:\n",
    "                indices = sdict[itype] #--- row index: atoms with  '#TypeId' == itype\n",
    "                cond = len(df_concat[itype]) == 0 #--- empty key?\n",
    "                df_concat[itype] = np.c_[df.loc[indices]] if cond else\\\n",
    "                np.concatenate([df_concat[itype],np.c_[df.loc[indices]]],axis=0)\n",
    "\n",
    "        self.energyByType = {}\n",
    "        for itype in df_concat:\n",
    "             self.energyByType[ itype ] = pd.DataFrame(df_concat[itype],columns=list(df.keys()))        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data):\n",
    "    if not eval(confParser['EnergyBarrier']['EnergyBarrier']):\n",
    "        return\n",
    "    \n",
    "    eb = EnergyBarrier('%s/EVENTS_DIR'%confParser['input files']['input_path'],\n",
    "                       '%s/EVLIST_DIR'%confParser['input files']['input_path'],\n",
    "                       data.lmpData\n",
    "\n",
    "                      )\n",
    "    eb.Parse()\n",
    "    eb.SplitByType()\n",
    "\n",
    "    #eb.events_id_energy extract from Events_dir\n",
    "    #self.energyByType extract from catalogs\n",
    "\n",
    "    #--- write to file\n",
    "    !mkdir msd\n",
    "    with open('msd/eventID_barrier.txt','w') as fp:\n",
    "        np.savetxt(fp,\n",
    "                   np.c_[eb.events_id_energy],\n",
    "                   header='atom_type event_id atom_id barrier')\n",
    "\n",
    "    #--- write to file: energy from catalogs\n",
    "    for itype in eb.energyByType.keys():\n",
    "        with open('msd/eventID_barrier_catalog_type%s.txt'%itype,'w') as fp:\n",
    "        #--- concat different types\n",
    "            sarr = np.c_[eb.energyByType[itype][['AtomId','eventId','barrier']]].astype(float)\n",
    "            np.savetxt(fp,\n",
    "                       sarr,\n",
    "                       header='AtomId eventId barrier'\n",
    "                      )\n",
    "main(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## arrhenius law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Temperature:\n",
    "    def __init__(self,temp_range,nrun,verbose=False):\n",
    "        self.temps =  temp_range\n",
    "        self.nrun = nrun\n",
    "        self.verbose = verbose\n",
    "#         pdb.set_trace()\n",
    "#        self.temps_runs = np.concatenate(list(map(lambda x:self.BuildTempRealizationPair([x[0]],np.arange(x[1])),\n",
    "#            zip(self.temps,self.nrun))))\n",
    "\n",
    "        self.temps_runs = np.concatenate(list(map(lambda x:self.BuildTempRealizationPair([x[0]],x[1]),\n",
    "             zip(self.temps,self.nrun))))\n",
    "        \n",
    "    \n",
    "    def BuildTempRealizationPair(self,temps,nrun):\n",
    "        t,r=np.meshgrid(temps,nrun,indexing='ij')\n",
    "        return np.array(list(zip(t.flatten(),r.flatten())))\n",
    "        \n",
    "    def ModifyNrun(self,dirs):\n",
    "        #--- modify dirs\n",
    "        count = -1\n",
    "        dirs_copy = dirs[:]\n",
    "        for _, indx in zip(self.temps,range(len(self.temps))):\n",
    "            nrun_mod = self.nrun[indx][:]\n",
    "            for y in self.nrun[indx]:\n",
    "                count += 1\n",
    "                x = dirs[count]\n",
    "                if not os.path.isfile(x): #--- if false: remove file from \"dirs\"\n",
    "                    dirs_copy.remove(x)\n",
    "                    nrun_mod.remove(y)\n",
    "            self.nrun[indx] = nrun_mod[:]\n",
    "\n",
    "            assert len(self.nrun[indx]) > 0, 'temp = %s has no data!'%(self.temps[indx])\n",
    "                \n",
    "        self.temps_runs = np.concatenate(list(map(lambda x:self.BuildTempRealizationPair([x[0]],x[1]),\n",
    "             zip(self.temps,self.nrun))))\n",
    "        return dirs_copy\n",
    "        \n",
    "    def Parse(self,dirs):\n",
    "            \n",
    "        dirs = self.ModifyNrun(dirs)\n",
    "#         print('dirs:',dirs)\n",
    "        self.data=list(map(lambda x:np.loadtxt(x,ndmin=2),dirs))\n",
    "        if self.verbose:\n",
    "            n = np.array(self.nrun).flatten()\n",
    "            list(map(lambda x:print('Parsing: %s data.shape is: %s'%(x[1],x[0].shape)),zip(self.data,n)))\n",
    "#        print('np.array(self.data):',np.array(self.data))\n",
    "\n",
    "        \n",
    "    def Plot(self,**kwargs):\n",
    "#        print(list(self.temps_runs))\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs\n",
    "                    else (1.0,0.5,0.5,0.5)\n",
    "                   )\n",
    "        for data, temp_run, count in zip(self.data,self.temps_runs,range(len(self.data))): \n",
    "            temp = temp_run[0]\n",
    "            try:\n",
    "                utl.PltErr(data[:,0],data[:,1],\n",
    "                       yerr=data[:,2],\n",
    "                       ax = self.ax,\n",
    "                       attrs=symbols.GetAttrs(count=count%7,label=r'$%s$'%temp),\n",
    "                       Plot=False,\n",
    "                      )\n",
    "            except:\n",
    "                continue\n",
    "        #\n",
    "        utl.PltErr(None,\n",
    "                   None,\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "#                 legend=legends.Get(),\n",
    "                   **kwargs\n",
    "                  )\n",
    "\n",
    "\n",
    "\n",
    "    def Binning(self,tr_mat,bins_per_decade, nmin=1):\n",
    "        #--- binning\n",
    "        xmin       = 0.99*tr_mat[:,0].min()\n",
    "        xmax       = 1.01*tr_mat[:,0].max()\n",
    "        n_decades  = int(np.ceil(np.log10(xmax/xmin)))\n",
    "        bins       = np.logspace(np.log10(xmin),np.log10(xmax),n_decades*bins_per_decade)\n",
    "        \n",
    "        #\n",
    "        count, _   = np.histogram(tr_mat[:,0],bins=bins)\n",
    "        tsum,  _   = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,0])\n",
    "        filtr      = count >= nmin\n",
    "        #  \n",
    "        xsum, _    = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,1])\n",
    "        ysum, _    = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,2])\n",
    "        zsum, _    = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,3])\n",
    "\n",
    "        xsum_sq, _ = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,1]*tr_mat[:,1])\n",
    "        ysum_sq, _ = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,2]*tr_mat[:,2])\n",
    "        zsum_sq, _ = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,3]*tr_mat[:,3])\n",
    "        #\n",
    "        xsum       = xsum[filtr]\n",
    "        ysum       = ysum[filtr]\n",
    "        zsum       = zsum[filtr]\n",
    "        #\n",
    "        xsum_sq    = xsum_sq[filtr]\n",
    "        ysum_sq    = ysum_sq[filtr]\n",
    "        zsum_sq    = zsum_sq[filtr]\n",
    "        #\n",
    "        tsum       = tsum[filtr]\n",
    "        count      = count[filtr]\n",
    "        print('count=',count)\n",
    "        assert not np.any(count < nmin), 'incerease bin size!'\n",
    "        #\n",
    "        xsum_sq   /= count\n",
    "        ysum_sq   /= count\n",
    "        zsum_sq   /= count\n",
    "        #\n",
    "        xsum      /= count\n",
    "        ysum      /= count\n",
    "        zsum      /= count\n",
    "        #     \n",
    "        tsum      /= count\n",
    "        #\n",
    "        xsum_sq   -= (xsum * xsum)\n",
    "        ysum_sq   -= (ysum * ysum)\n",
    "        zsum_sq   -= (zsum * zsum)\n",
    "        assert np.all(xsum_sq >= 0) and np.all(ysum_sq >= 0) and np.all(zsum_sq >= 0)\n",
    "        #\n",
    "        var        = ( xsum_sq + ysum_sq + zsum_sq ) / 3.0\n",
    "#        assert not np.any(ysum_sq < 0.0), 'print %s'%ysum_sq\n",
    "        \n",
    "        return np.c_[tsum,var,np.zeros( len( tsum ) ) ] \n",
    "\n",
    "\n",
    "    def EnsAverage2nd(self,\n",
    "                   log_scale_x=False,log_scale_y=False,\n",
    "                   col_x=0,col_y=1,\n",
    "                   n_bins_per_decade=6,\n",
    "                  n_thresh=0,\n",
    "                   ymin=-sys.maxsize,ymax=sys.maxsize\n",
    "                  ):\n",
    "        kount = 0\n",
    "        self.data_averaged = {} \n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp\n",
    "            nruns = len(self.nrun[indx])\n",
    "            data = self.data[kount:kount+nruns]\n",
    "#             if self.verbose:\n",
    "#                 print('data.shape:',np.array(data).shape)\n",
    "    \n",
    "            filtr = list(map(lambda x:x.shape[0] > 0,data)) #--- filter empty arrays\n",
    "    \n",
    "            data = np.concatenate(np.array(data)[filtr]) #,axis=0)\n",
    "            if self.verbose:\n",
    "                print('data.shape:',np.array(data).shape)\n",
    "#             pdb.set_trace()\n",
    "        \n",
    "            self.data_averaged[ temp ] = self.Binning(data,n_bins_per_decade,nmin=n_thresh)\n",
    "\n",
    "            kount += nruns #self.nrun\n",
    "            \n",
    "    def EnsAverage(self,\n",
    "                   log_scale_x=False,log_scale_y=False,\n",
    "                   col_x=0,col_y=1,\n",
    "                   n_bins_per_decade=6,\n",
    "                  n_thresh=0,\n",
    "                   ymin=-sys.maxsize,ymax=sys.maxsize\n",
    "                  ):\n",
    "        kount = 0\n",
    "        self.data_averaged = {} #np.zeros(len(self.temps))\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp\n",
    "            nruns = len(self.nrun[indx])\n",
    "            data = self.data[kount:kount+nruns]\n",
    "            if self.verbose:\n",
    "                print('data.shape:',np.array(data).shape)\n",
    "#             print('np.array(data):',np.array(data))\n",
    "#             pdb.set_trace()\n",
    "    \n",
    "            filtr = list(map(lambda x:x.shape[0] > 0,data)) #--- filter empty arrays\n",
    "    \n",
    "            data = np.concatenate(np.array(data)[filtr]) #,axis=0)\n",
    "            self.data_averaged[ temp ] = self.hist(data,\n",
    "                                                   log_scale_x,log_scale_y,\n",
    "                                                   n_bins_per_decade=n_bins_per_decade,\n",
    "                                                   col_x = col_x, col_y = col_y,\n",
    "                                                   n_thresh=n_thresh,\n",
    "                                                   ymin=ymin,ymax=ymax\n",
    "                                                  )\n",
    "            kount += nruns #self.nrun\n",
    "\n",
    "    def hist(self,data,\n",
    "             log_scale_x,log_scale_y,\n",
    "             n_bins_per_decade=6,\n",
    "             col_x = 0, col_y = 1,\n",
    "             n_thresh=0,\n",
    "                   ymin=-sys.maxsize,ymax=sys.maxsize\n",
    "            ):\n",
    "        n_thresh = n_thresh\n",
    "#         pdb.set_trace()\n",
    "            #--- average\n",
    "        xdata = data[:,col_x]\n",
    "        ydata = data[:,col_y]\n",
    "        filtr = np.all([ydata>=ymin,ydata<ymax],axis=0)\n",
    "        xdata = xdata[filtr]\n",
    "        ydata = ydata[filtr]\n",
    "        if log_scale_x:\n",
    "            xmin = np.floor(np.log10(xdata).min())\n",
    "            xmax = np.ceil(np.log10(xdata).max())\n",
    "            n_decades = int((xmax - xmin))\n",
    "            bins = np.logspace(xmin,xmax,n_decades*n_bins_per_decade)\n",
    "        else:\n",
    "            xmin = xdata.min()*0.999\n",
    "            xmax = xdata.max()*1.001\n",
    "            bins = np.linspace(xmin,xmax,n_bins_per_decade)\n",
    "            \n",
    "        #\n",
    "        count, _    = np.histogram(xdata,bins=bins)\n",
    "        xsum, _     = np.histogram(xdata,bins=bins,weights=xdata)\n",
    "        weights     = ydata if not log_scale_y else np.log10(ydata)\n",
    "        if log_scale_y and np.any(ydata == 0.0):\n",
    "            print('data has a zero component!')\n",
    "            return\n",
    "        ysum, _     = np.histogram(xdata,bins=bins,weights=weights)\n",
    "        ysum_sq, _  = np.histogram(xdata,bins=bins,weights=weights*weights)\n",
    "        #\n",
    "        xsum = xsum[count>n_thresh]\n",
    "        ysum = ysum[count>n_thresh]\n",
    "        ysum_sq = ysum_sq[count>n_thresh]\n",
    "        count = count[count>n_thresh]\n",
    "        #\n",
    "        xsum /= count\n",
    "        ysum /= count\n",
    "        ysum_sq /= count\n",
    "        assert np.all(ysum_sq - ysum * ysum >= 0.0), 'variance < 0.0!'\n",
    "        std = np.sqrt((ysum_sq - ysum * ysum)/count)\n",
    "        if log_scale_y:\n",
    "            ysum = 10 ** ysum\n",
    "            std = 0.5 * ysum * (1+2*std*np.log(10))\n",
    "        return np.c_[xsum,ysum,std]\n",
    "        \n",
    "        \n",
    "#            utl.PltErr(xsum,ysum,ax=self.ax)\n",
    "            \n",
    "\n",
    "    def PlotAverage(self,rescale=False,**kwargs):\n",
    "#        print(list(self.temps_runs))\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "        for temp, count in zip(self.temps,range(len(self.temps))): \n",
    "            data = self.data_averaged[ temp ]\n",
    "            xdata = data[:,0]\n",
    "            ydata = data[:,1]\n",
    "            yerr = data[:,2]\n",
    "            if rescale:\n",
    "                ydata /= xdata\n",
    "                yerr /= xdata\n",
    "            utl.PltErr(xdata,ydata,\n",
    "                   yerr=yerr,\n",
    "                   ax = self.ax,\n",
    "                   attrs=symbols.GetAttrs(count=count%7 if not 'count' in kwargs else kwargs['count'],label=r'$%s$'%temp,nevery=1),\n",
    "                   Plot=False,\n",
    "                  )\n",
    "\n",
    "        utl.PltErr(None,\n",
    "                   None, \n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "#                    legend=legends.Get(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "        \n",
    "        \n",
    "    def func2nd(self,x,y0,c0,alpha):\n",
    "#        return y0+c0*(x/x0)**alpha\n",
    "        return y0*y0+c0*x**alpha\n",
    "\n",
    "    def func3rd(self,x,c0,alpha):\n",
    "         return c0*x**alpha\n",
    "\n",
    "    def Fit(self,Plot=None,\n",
    "            shift = False,\n",
    "#             SIGMA=False,\n",
    "            plotAttrs=None,\n",
    "            bounds=(-np.inf, np.inf),\n",
    "            xlo=float('-inf'),xhi=float('inf'),\n",
    "            **kwargs):\n",
    "        self.Diffusion = {}\n",
    "        self.exponent = {}\n",
    "        pref=1e-10*1e-10 #--- ang^2 to m^2\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=plotAttrs['bbox_to_anchor'] if 'bbox_to_anchor' in plotAttrs\n",
    "                    else (1.0,0.5,0.5,0.5),\n",
    "                   fontsize=18,\n",
    "                   )\n",
    "\n",
    "        if Plot:\n",
    "            ax = utl.PltErr(None,None,\n",
    "                            Plot=False)\n",
    "        #\n",
    "        for temp, count in zip(self.temps,range(len(self.temps))): \n",
    "            nruns = len(self.nrun[count])\n",
    "\n",
    "            self.smat = smat = self.data_averaged[ temp ] if nruns > 1 else self.data[count]\n",
    "\n",
    "            xdata=smat[:,0]\n",
    "            ydata=smat[:,1]\n",
    "            yerr = smat[:,2]\n",
    "#             print(smat)\n",
    "\n",
    "        \n",
    "            #--- set limits:\n",
    "            if self.verbose:\n",
    "                print('limits:',xlo,xhi)\n",
    "\n",
    "            filtr = np.ones(xdata.shape[0],dtype=bool)\n",
    "            filtr = np.all([filtr,xdata > xlo],axis=0)\n",
    "            filtr = np.all([filtr,xdata <= xhi],axis=0)\n",
    "            assert np.any(filtr), 'empty arrays!'\n",
    "            if self.verbose:\n",
    "                print('filtr=',filtr)\n",
    "            \n",
    "            #--- error in y\n",
    "            if 'sigma' in kwargs:\n",
    "                kwargs['sigma'] = 2*yerr[filtr]\n",
    "\n",
    "            #--- fit\n",
    "#             print(kwargs)\n",
    "            popt, pcov = curve_fit(self.func2nd, xdata[filtr], ydata[filtr],\n",
    "                                   bounds=bounds, #([1e-1, 1e5,0.5], [1e0, 1e7,2.0]), #[(4e-3, 1e5,0.5), (1e-2, 1e7,2.0)],#bounds,\n",
    "                                    **kwargs\n",
    "                                    )\n",
    "            self.popt = popt\n",
    "            self.pcov = pcov\n",
    "            self.filtr = filtr\n",
    "            #--- uncertainties\n",
    "            if self.verbose:\n",
    "                print('Temp=%s,y0,c0,alpha'%temp,list(popt),pcov)\n",
    "                print('alpha=%s'%popt[2])\n",
    "            y0=popt[0]\n",
    "            alpha=popt[2]\n",
    "            err_alpha = pcov[2,2]**0.5\n",
    "            c0=popt[1]\n",
    "            dc = pcov[1,1]**0.5\n",
    "            tau=1#popt[0]\n",
    "            dtau=0#pcov[0,0]**0.5\n",
    "            self.time_scale = tau * (y0/c0)**(1/alpha)\n",
    "            if self.verbose:\n",
    "                print('Temp=%s,tau=%s'%(temp,self.time_scale))\n",
    "                print('err_alpha=%s'%err_alpha)\n",
    "#             self.Diffusion[temp] = [pref*c0/tau,pref*c0/tau,pref*c0/tau]\n",
    "            self.Diffusion[temp] = [pref*c0/(tau)**alpha, pref*(c0+dc)/(tau-dtau)**alpha, \n",
    "                                    pref*(c0-dc)/(tau+dtau)**alpha]\n",
    "            self.exponent[temp] = [alpha,alpha+err_alpha,alpha-err_alpha]\n",
    "            if Plot:\n",
    "                #---fit\n",
    "                y0=0 #kam\n",
    "                xdata_shift = xdata*20**count if shift else xdata\n",
    "                utl.PltErr(xdata_shift,\n",
    "                                (self.func2nd(xdata,*popt)-y0),#-y0)/xdata_shift,\n",
    "                                attrs={'fmt':'-.','color':symbols.colors[count%7],\\\n",
    "                                       'label':r'$\\alpha=%3.2f$'%popt[2]},\n",
    "                           Plot=False,ax=ax)\n",
    "                #--- points\n",
    "#                temp= [1000,1200,1400,1600,1800,2000][count]\n",
    "                utl.PltErr(xdata_shift,\n",
    "                           (ydata-y0),#-y0)/xdata_shift,\n",
    "                           yerr=(yerr),#-y0),#/xdata_shift,\n",
    "#                           attrs=symbols.GetAttrs(count=count%7,label=r'$%s$'%temp,fmt='.'),\n",
    "                           attrs=symbols.GetAttrs(count=count%7,fmt='.'),\n",
    "                           ax=ax,\n",
    "                           Plot=False,\n",
    "                          )\n",
    "        if Plot:\n",
    "            utl.PltErr(None,\n",
    "                       None, \n",
    "                       ax=ax,\n",
    "                       Plot=False,\n",
    "                         legend=legends.Get(),\n",
    "                       DrawFrame=DRAW_FRAME,\n",
    "                       **plotAttrs\n",
    "                      )\n",
    "\n",
    "    def FitLinear(self,Plot=None,\n",
    "            shift = False,\n",
    "#             SIGMA=False,\n",
    "            plotAttrs=None,\n",
    "            y0=0.0,\n",
    "            bounds=(-np.inf, np.inf),\n",
    "            xlo=float('-inf'),xhi=float('inf'),\n",
    "            **kwargs):\n",
    "        self.Diffusion = {}\n",
    "        self.exponent = {}\n",
    "        pref=1e-10*1e-10 #--- ang^2 to m^2\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=plotAttrs['bbox_to_anchor'] if 'bbox_to_anchor' in plotAttrs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "\n",
    "        if Plot:\n",
    "            ax = utl.PltErr(None,None,\n",
    "                            Plot=False)\n",
    "        #\n",
    "        for temp, count in zip(self.temps,range(len(self.temps))): \n",
    "            nruns = len(self.nrun[count])\n",
    "            self.smat = smat = self.data_averaged[ temp ] if nruns > 1 else self.data[count]\n",
    "\n",
    "            xdata=smat[:,0]\n",
    "            ydata=smat[:,1] - y0*y0\n",
    "            yerr = smat[:,2]\n",
    "#             print(smat)\n",
    "\n",
    "        \n",
    "            #--- set limits:\n",
    "            if self.verbose:\n",
    "                print('limits:',xlo,xhi)\n",
    "\n",
    "            filtr = np.ones(xdata.shape[0],dtype=bool)\n",
    "            filtr = np.all([filtr,xdata > xlo],axis=0)\n",
    "            filtr = np.all([filtr,xdata <= xhi],axis=0)\n",
    "            assert np.any(filtr), 'empty arrays!'\n",
    "            if self.verbose:\n",
    "                print('filtr=',filtr)\n",
    "            \n",
    "            #--- error in y\n",
    "            if 'sigma' in kwargs:\n",
    "                kwargs['sigma'] = 2*yerr[filtr]\n",
    "\n",
    "            #--- fit\n",
    "#             print(kwargs)\n",
    "            popt, pcov = curve_fit(self.func3rd, xdata[filtr], ydata[filtr],\n",
    "                                   bounds=bounds, #([1e-1, 1e5,0.5], [1e0, 1e7,2.0]), #[(4e-3, 1e5,0.5), (1e-2, 1e7,2.0)],#bounds,\n",
    "                                    **kwargs\n",
    "                                    )\n",
    "            self.popt = popt\n",
    "            self.filtr = filtr\n",
    "            #--- uncertainties\n",
    "            if self.verbose:\n",
    "                print('Temp=%s,y0,c0,alpha'%temp,list(popt),pcov)\n",
    "#            y0=popt[0]\n",
    "            alpha=popt[1]\n",
    "            err_alpha = pcov[1,1]**0.5\n",
    "            c0=popt[0]\n",
    "            dc = pcov[0,0]**0.5\n",
    "            tau=1#popt[0]\n",
    "            dtau=0#pcov[0,0]**0.5\n",
    "#            self.time_scale = tau * (y0/c0)**(1/alpha)\n",
    "#            if self.verbose:\n",
    "#                print('Temp=%s,tau=%s'%(temp,self.time_scale))\n",
    "#             self.Diffusion[temp] = [pref*c0/tau,pref*c0/tau,pref*c0/tau]\n",
    "            self.Diffusion[temp] = [pref*c0/(tau)**alpha, pref*(c0+dc)/(tau-dtau)**alpha, \n",
    "                                    pref*(c0-dc)/(tau+dtau)**alpha]\n",
    "            self.exponent[temp] = [alpha,alpha+err_alpha,alpha-err_alpha]\n",
    "            if Plot:\n",
    "                #---fit\n",
    "#                y0=0 #kam\n",
    "                xdata_shift = xdata*20**count if shift else xdata\n",
    "                utl.PltErr(xdata_shift,\n",
    "                                self.func3rd(xdata,*popt),\n",
    "                                attrs={'fmt':'-.','color':symbols.colors[count%7]},\n",
    "                           Plot=False,ax=ax)\n",
    "                #--- points\n",
    "#                temp= [1000,1200,1400,1600,1800,2000][count]\n",
    "                utl.PltErr(xdata_shift,\n",
    "                           ydata,\n",
    "                           yerr=yerr,\n",
    "                           attrs=symbols.GetAttrs(count=count%7,label=r'$%s$'%temp,fmt='.'),\n",
    "                           ax=ax,\n",
    "                           Plot=False,\n",
    "                          )\n",
    "        if Plot:\n",
    "            utl.PltErr(None,\n",
    "                       None, \n",
    "                       ax=ax,\n",
    "                       Plot=False,\n",
    "#                       legend=legends.Get(),\n",
    "                       DrawFrame=DRAW_FRAME,\n",
    "                       **plotAttrs\n",
    "                      )\n",
    "            \n",
    "    def PlotDiff(self,**kwargs):\n",
    "        symbols=utl.Symbols()\n",
    "        utl.PltErr(1.0/np.array(self.temps),\n",
    "                   list(map(lambda x:self.Diffusion[x][0],self.temps)),\n",
    "                   yerr=list(map(lambda x:(self.Diffusion[x][1]-self.Diffusion[x][2])/2,self.temps)),\n",
    "                   attrs=symbols.GetAttrs(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "\n",
    "    def PlotExponent(self,**kwargs):\n",
    "        symbols=utl.Symbols()\n",
    "        ax=utl.PltErr([0.5e-3,1e-3],[1,1],attrs={'fmt':'-.r'},Plot=False)\n",
    "        utl.PltErr(1.0/np.array(self.temps),\n",
    "                   list(map(lambda x:self.exponent[x][0],self.temps)),\n",
    "                   yerr=list(map(lambda x:1.0*(self.exponent[x][1]-self.exponent[x][2]),self.temps)),\n",
    "                   attrs=symbols.GetAttrs(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   ax=ax,\n",
    "                   **kwargs\n",
    "                  )\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    if eval(confParser['flags']['RemoteMachine']):\n",
    "        return\n",
    "    !mkdir png\n",
    "    #--- temp object\n",
    "    temp = Temperature(\n",
    "        [1000],[list(range(8))]*10,\n",
    "#          verbose = True,\n",
    "                     )\n",
    "    #\n",
    "    #--- parse data\n",
    "#    temp.Parse(['./msd/msd.txt']) \n",
    "#    temp.Parse( list(map(lambda x:'ni/void5th/Run%s/msd/msd.txt'%(x[1]),\n",
    "    temp.Parse( list(map(lambda x:'ni/kmc/void_2d/Run%s/msd/msd_vac_cna.txt'%(x[1]),\n",
    "#    temp.Parse( list(map(lambda x:'ni/pure/Run%s/msd/msd_vac_cna.txt'%(x[1]),\n",
    "#    temp.Parse( list(map(lambda x:'ni/mlmc/latest_void5th/Run%s/msd/msd_vac_cna.txt'%(x[1]),\n",
    "                         temp.temps_runs ))\n",
    "             )\n",
    "    #\n",
    "    #--- plot\n",
    "    xlim = (1e0,1e6)\n",
    "#     xlim = (1e-10,1e-6)\n",
    "    ylim = (1e-1,1e3)\n",
    "    print('single realizations')\n",
    "    temp.Plot(**{\n",
    "                  'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "                   'attrs':{'fmt':'-'},\n",
    "                  'xlim':xlim,\n",
    "                     'ylim':ylim,\n",
    "                   'title':'png/msd_temp_ni.png',\n",
    "                    'xstr':r'$t(\\mathrm{s})$','ystr':r'$\\mathrm{msd}(\\r{A}^2)$',\n",
    "        'bbox_to_anchor':(0.01,0.3,0.5,0.5)\n",
    "    })\n",
    "    \n",
    "    #\n",
    "    #--- plot average\n",
    "    #\n",
    "    print('ensemble average')\n",
    "    temp.EnsAverage(log_scale_x=True,log_scale_y=True,\n",
    "                   n_thresh=2,\n",
    "                    n_bins_per_decade=4,#32,\n",
    "#                     ymin=1e-3,\n",
    "                   )\n",
    "    temp.PlotAverage(**{\n",
    "                  'yscale':'log',\n",
    "                  'xscale':'log',\n",
    "#                   'count':0,\n",
    "                   'xlim':xlim,\n",
    "                     'ylim':ylim,\n",
    "                    'xstr':r'$t(\\mathrm{s})$','ystr':r'$\\mathrm{msd}(\\r{A}^2)$',\n",
    "                    'title':'png/msd_temp_ni_T%sK.png'%temp.temps[0],\n",
    "         })\n",
    "\n",
    "    #\n",
    "    #--- fit\n",
    "    #\n",
    "    temp.Fit(Plot=True,\n",
    "#              shift=True,\n",
    "#             bounds=([4e-3, 1e5,0.5], [1e-2, 1e7,2.0]),\n",
    "#            p0=[[1e-4, 1e6, 1.0]],\n",
    "            p0=[[1e-1, 1e6, 1.5]],\n",
    "               sigma=True, #--- comment for ni\n",
    "              xlo=xlim[0],\n",
    "             plotAttrs={'yscale':'log',\n",
    "                  'xscale':'log',\n",
    "                   'xlim':xlim,\n",
    "                      'ylim':ylim,\n",
    "                        'ndecade_x':1,\n",
    "                    'bbox_to_anchor':(-0.05,0.33,0.5,0.5),\n",
    "                   'title':'png/msd_temp_ni_fit_inset.png',\n",
    "                    'xstr':r'$t(\\mathrm{s})$','ystr':r'$\\mathrm{msd}(\\r{A}^2)$',\n",
    "#                         'fontsize':24,\n",
    "#              'halfopen':True\n",
    "                       }\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "    temp.PlotExponent(**{\n",
    "                    'title':'png/alpha_temp_ni.png',\n",
    "                    'ylim':(0.5,1.5),\n",
    "                    }\n",
    "                )\n",
    "    \n",
    "    return temp\n",
    "temp = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vacancy dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: png: File exists\n",
      "Parsing: 4 data.shape is: (16, 3)\n",
      "single realizations\n",
      "limits: 1e-11 1e-07\n",
      "filtr= [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True False False False]\n",
      "Temp=1000,y0,c0,alpha [1.3484385630701563, 3473143095.2512836, 0.9840878971482054] [[1.70419437e-02 6.56866434e+07 1.12753418e-03]\n",
      " [6.56866434e+07 6.63428874e+17 1.11598439e+07]\n",
      " [1.12753418e-03 1.11598439e+07 1.88060009e-04]]\n",
      "alpha=0.9840878971482054\n",
      "Temp=1000,tau=2.7348914561085165e-10\n",
      "err_alpha=0.013713497319305046\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    #--- temp object\n",
    "    temp_vac = Temperature(\n",
    "#        [1000,1200,1400,1600,1800,2000],[[8,7,6,5,4,1,0],list(range(8)),list(range(8)),list(range(8)),list(range(8)),list(range(8))],\n",
    "        [1000],[list(range(4,5))]*100,\n",
    "         verbose = True,\n",
    "                     )\n",
    "    #\n",
    "    #--- parse data\n",
    "#    temp_vac.Parse(['./msd/msd_vac.txt'])\n",
    "#    temp_vac.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/msd_vac.txt'%(x[0],x[1]),\n",
    "#    temp_vac.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/msd_vac.txt'%(x[0],x[1]),\n",
    "#    temp_vac.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/msd_vac.txt'%(x[0],x[1]),\n",
    "#    temp_vac.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/msd_vac_cna.txt'%(x[0],x[1]),\n",
    "    temp_vac.Parse( list(map(lambda x:'msd_definition/ni/temp0_2nd/Run%s/msd/msd_vac_ws.txt'%(x[1]),\n",
    "                          temp_vac.temps_runs ))\n",
    "              )\n",
    "    #\n",
    "    #--- plot\n",
    "    print('single realizations')\n",
    "    temp_vac.Plot(**{\n",
    "                  'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "                   'attrs':{'fmt':'-'},\n",
    "#                   'xlim':(1e-10,1e-3),\n",
    "#                    'ylim':(1e-5,1e-1),\n",
    "#                   'xstr':r'$t\\mathrm{(s)}$',\n",
    "#                   'ystr':r'msd(A$^2$)',\n",
    "#                   'title':'png/msd_temp_ni.png',\n",
    "        'bbox_to_anchor':(0.01,0.3,0.5,0.5)\n",
    "    })\n",
    "    #\n",
    "    #--- plot average\n",
    "    #\n",
    "    if len(temp_vac.nrun[0]) > 1:\n",
    "        print('ensemble average')\n",
    "        temp_vac.EnsAverage(log_scale_x=True,log_scale_y=True,n_bins_per_decade=4,n_thresh=1)\n",
    "    #\n",
    "    #--- fit\n",
    "    temp_vac.Fit(Plot=True,\n",
    "             shift=False,\n",
    "             p0=[[0.4, 1e6, 1.1]],\n",
    "             sigma=True, #--- comment for ni\n",
    "               xlo=1e-11, xhi=1e-7,\n",
    "             plotAttrs={'yscale':'log',\n",
    "                  'xscale':'log',\n",
    "                        'ndecade_x':1,\n",
    "                    'bbox_to_anchor':(-0.05,0.4,0.5,0.5),\n",
    "                   'title':'png/msd_temp_ni_fit_vac_cna.png'},\n",
    "            )\n",
    "    \n",
    "#     temp_vac.FitLinear(Plot=True,\n",
    "#              shift=True,\n",
    "# #             bounds=([4e-3, 1e5,0.5], [1e-2, 1e7,2.0]),\n",
    "#             p0=[[1e6, 1.0]],\n",
    "# #             sigma=True, #--- comment for ni\n",
    "# #             xlo=1e-12,\n",
    "#              y0 = 0.7,\n",
    "#              plotAttrs={'yscale':'log',\n",
    "#                   'xscale':'log',\n",
    "# #                   'xlim':(4e-13,8e-4),\n",
    "# #                   'ylim':(1e-6,1e-2),\n",
    "# #                     'xstr':r'$t\\mathrm{(s)}$',\n",
    "# #                   'ystr':r'msd(A$^2$)',\n",
    "#                         'ndecade_x':2,\n",
    "#                     'bbox_to_anchor':(-0.05,0.23,0.5,0.5),\n",
    "#                    'title':'png/msd_temp_cantor_fit.png'},\n",
    "#             )\n",
    "\n",
    "\n",
    "#     temp.PlotDiff(**{\n",
    "#                   'yscale':'log',\n",
    "# #                   'xlim':(1e-12,1e-3),\n",
    "# #                   'ylim':(1e-4,1e-1),\n",
    "# #                   xstr=r'$1/T(K^{-1})$',\n",
    "# #                   ystr=r'$D(m^2/s)$',\n",
    "#                     'title':'png/D_temp_cantor.png',\n",
    "#                     }\n",
    "#                 )\n",
    "\n",
    "#     temp_vac.PlotExponent(**{\n",
    "# #                  'yscale':'log',\n",
    "# #                   'xlim':(1e-10,1e-3),\n",
    "# #                   'ylim':(.9,1.6),\n",
    "# #                   xstr=r'$1/T(K^{-1})$',\n",
    "# #                   ystr=r'$D(m^2/s)$',\n",
    "#                     'title':'png/alpha_temp_ni_vac_cna.png',\n",
    "#                     }\n",
    "#                 )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing: 0 data.shape is: (500404, 4)\n",
      "Parsing: 1 data.shape is: (500395, 4)\n",
      "Parsing: 2 data.shape is: (500400, 4)\n",
      "Parsing: 3 data.shape is: (500393, 4)\n",
      "Parsing: 4 data.shape is: (500395, 4)\n",
      "Parsing: 5 data.shape is: (500408, 4)\n",
      "Parsing: 6 data.shape is: (500388, 4)\n",
      "Parsing: 7 data.shape is: (500387, 4)\n",
      "ensemble average\n",
      "data.shape: (4003170, 4)\n",
      "count= [     32      37      59     124    1853    2031    5644    7545   13382\n",
      "   23326   43881   74796  129898  223353  382742  625406  932991 1102916\n",
      "  433154]\n",
      "16\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.22466465e-04  2.89192802e+09  9.86590352e-01]\n"
     ]
    }
   ],
   "source": [
    "# temp_vac = Temperature(\n",
    "#     [1000],[[0,1,2,3,4,5,6,7]]*100,\n",
    "#      verbose = True,\n",
    "#                  )\n",
    "#     #\n",
    "#     #--- parse data\n",
    "# temp_vac.Parse( list(map(lambda x:'msd_definition/ni/temp0/Run%s/msd/msd_vac_cna.txt'%(x[1]),\n",
    "#                           temp_vac.temps_runs ))\n",
    "#               )\n",
    "#     #\n",
    "#     #\n",
    "#     #--- plot average\n",
    "#     #\n",
    "# #    if len(temp_vac.nrun[0]) > 1:\n",
    "# print('ensemble average')\n",
    "# temp_vac.EnsAverage2nd(log_scale_x=True,log_scale_y=True,n_bins_per_decade=4,n_thresh=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.20695400e-05  4.30119966e+05  4.76806140e-01]\n"
     ]
    }
   ],
   "source": [
    "xdata = temp_vac.data[0][:,0]\n",
    "ydata = temp_vac.data[0][:,1]\n",
    "yerr  = temp_vac.data[0][:,2]\n",
    "filtr = xdata < 1e-1\n",
    "xdata = xdata[filtr]\n",
    "ydata = ydata[filtr]\n",
    "yerr = yerr[filtr]\n",
    "print(len(xdata))\n",
    "ax = utl.PltErr(None,None,Plot=False)\n",
    "utl.PltErr(xdata,ydata, yerr=yerr,\n",
    "           attrs={'fmt':'o','color':'black'},\n",
    "          xscale='log',yscale='log',\n",
    "           ax=ax,\n",
    "           Plot=False\n",
    "          )\n",
    "\n",
    "popt, pcov = curve_fit(temp_vac.func2nd, xdata, ydata,\n",
    "             p0=[[0.4, 1e5, 1.1]],\n",
    "                       ftol=1e-10, xtol=1e-10, gtol=1e-10,\n",
    "                       maxfev=10000,\n",
    "                        )\n",
    "\n",
    "utl.PltErr(xdata,temp_vac.func2nd(xdata,*popt),\n",
    "           attrs={'fmt':'-.','color':'red'},\n",
    "          xscale='log',yscale='log',\n",
    "           ax=ax\n",
    "          )\n",
    "\n",
    "print(popt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('msd/msd_cna.txt',np.c_[temp_vac.data_averaged[1000]])\n",
    "# np.savetxt('msd/msd_cna_opt.txt',np.c_[temp_vac.popt])\n",
    "# np.savetxt('msd/msd_cna_cov.txt',np.c_[temp_vac.pcov])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    symbols=utl.Symbols()\n",
    "    legends = Legends()\n",
    "    legends.Set(bbox_to_anchor=(0.1,0.5,0.5,0.5))\n",
    "    #\n",
    "    ax=utl.PltErr([0.5e-3,1e-3],[1,1],attrs={'fmt':'-.r'},Plot=False)\n",
    "    utl.PltErr(1.0/np.array(temp.temps),\n",
    "               list(map(lambda x:temp.exponent[x][0],temp.temps)),\n",
    "               yerr=list(map(lambda x:1.0*(temp.exponent[x][1]-temp.exponent[x][2]),temp.temps)),\n",
    "               attrs=symbols.GetAttrs(count=0,label=r'$\\mathrm{Total}$'),\n",
    "               ax=ax,\n",
    "               Plot=False,\n",
    "    #           **kwargs\n",
    "              )\n",
    "\n",
    "    utl.PltErr(1.0/np.array(temp_vac.temps),\n",
    "               list(map(lambda x:temp_vac.exponent[x][0],temp_vac.temps)),\n",
    "               yerr=list(map(lambda x:1.0*(temp_vac.exponent[x][1]-temp_vac.exponent[x][2]),temp_vac.temps)),\n",
    "               attrs=symbols.GetAttrs(count=1,label=r'$\\mathrm{Vacancy}$'),\n",
    "               DrawFrame=DRAW_FRAME,\n",
    "               ax=ax,\n",
    "                       ylim=(.5,1.5),\n",
    "#               halfopen=True,\n",
    "#               legend=legends.Get(),\n",
    "                        title='png/alpha_temp_cantor.png',\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Robustness(Temperature):\n",
    "    \n",
    "    def __init__(self,temp_range,nrun,verbose=False):\n",
    "        Temperature.__init__(self,temp_range,nrun,verbose=verbose)\n",
    "\n",
    "    def FitRange(self,decades=9):\n",
    "        self.Fit(Plot=False,shift=False,\n",
    "                    p0=[[1e-2, 1e6, 1.0]],\n",
    "                 sigma=True, #--- comment for ni\n",
    "                     plotAttrs={'bbox_to_anchor':(-0.05,0.23,0.5,0.5)}\n",
    "                )\n",
    "\n",
    "        self.xlo = np.floor(np.log2(self.smat[:,0].min()))\n",
    "        xhii = np.ceil(np.log2(self.smat[:,0].max()))\n",
    "        self.xrange = 2**np.arange(xhii+1,xhii-decades,-1)\n",
    "        \n",
    "    def Fitting(self):\n",
    "        #--- bounds\n",
    "        self.exponents = np.zeros(len(self.xrange))\n",
    "        self.error = np.zeros(len(self.xrange))\n",
    "        self.npoin = np.zeros(len(self.xrange))\n",
    "        \n",
    "        npoint_filtrd0 = self.smat.shape[0]\n",
    "        for xhi, indx in zip(self.xrange,range(len(self.xrange))):\n",
    "            self.Fit(Plot=True,\n",
    "                     shift=False,\n",
    "        #             bounds=([0, 0, 0,0.999], [1e-2, 1e-3, 1,1.001]),\n",
    "                        p0=[[1e-2, 1e6, 1.0]],\n",
    "                     sigma=True, #--- comment for ni\n",
    "                     xlo=2**self.xlo,xhi=xhi,\n",
    "                     plotAttrs={'yscale':'log',\n",
    "                          'xscale':'log',\n",
    "        #                   'xlim':(4e-13,8e-4),\n",
    "        #                   'ylim':(1e-4,1e-1),\n",
    "        #                     'xstr':r'$t\\mathrm{(s)}$',\n",
    "        #                   'ystr':r'msd(A$^2$)',\n",
    "                                'ndecade_x':2,\n",
    "                            'bbox_to_anchor':(-0.05,0.23,0.5,0.5),\n",
    "    #                       'title':'png/msd_temp_nicocr_fit.png'\n",
    "                               },\n",
    "                    )\n",
    "            \n",
    "            #--- check if decrease in tc leads to fewere points\n",
    "#             npoint_filtrd = np.sum(self.filtr)\n",
    "#             if self.verbose:\n",
    "#                 print('npoint_filtrd=',npoint_filtrd)\n",
    "#             #if indx > 0:\n",
    "#             if npoint_filtrd == npoint_filtrd0 and indx > 0:\n",
    "#                 continue\n",
    "# #                    , '%s >= %sdecrease ndecades!'%(npoint_filtrd,npoint_filtrd0)\n",
    "#             npoint_filtrd0 = npoint_filtrd\n",
    "            \n",
    "            #--- assign\n",
    "            self.npoin[indx] = np.sum(self.filtr)\n",
    "            if self.npoin[indx] == self.npoin[indx-1] and indx > 0:\n",
    "                continue\n",
    "            self.exponents[indx] = self.popt[-1]\n",
    "            x = self.temps[ 0 ]\n",
    "            self.error[indx] = 0.5*(self.exponent[x][1]-self.exponent[x][2])\n",
    "        \n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "\n",
    "    symbols = utl.Symbols()\n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "\n",
    "    temps = [1200] #[1000,1200,1400,1600,1800,2000]\n",
    "    indices = [1] #range(10)\n",
    "    for temperature, indx in zip(temps,indices):\n",
    "        try:\n",
    "            rb = Robustness([temperature],8,\n",
    "#                            verbose = True\n",
    "\n",
    "                            )\n",
    "\n",
    "            #--- parse data\n",
    "#            rb.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "            rb.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "#            rb.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "                                rb.temps_runs ))\n",
    "                     )\n",
    "\n",
    "            #--- plot average\n",
    "            if rb.nrun > 1:\n",
    "                print('ensemble average')\n",
    "                rb.EnsAverage(log_scale=False,n_bins_per_decade=4)\n",
    "#                 rb.PlotAverage(**{\n",
    "#                           'yscale':'log',\n",
    "#                           'xscale':'log',\n",
    "#         #                   'xlim':(1e-10,1e-3),\n",
    "#         #                   'ylim':(1e-4,1e-1),\n",
    "#         #                     'xstr':r'$t\\mathrm{(s)}$',\n",
    "#         #                   'ystr':r'msd(A$^2$)',\n",
    "# #                            'title':'png/msd_temp_cantor.png',\n",
    "#                 })\n",
    "            #\n",
    "            #--- fit\n",
    "            #\n",
    "            rb.FitRange(decades=10)\n",
    "            rb.Fitting()\n",
    "\n",
    "\n",
    "            #--- get data\n",
    "            filtr = np.all([rb.exponents>0,rb.exponents<2],axis=0)\n",
    "            utl.PltErr(rb.xrange[filtr],rb.exponents[filtr],yerr=rb.error[filtr],\n",
    "                       attrs=symbols.GetAttrs(count=indx%7),\n",
    "                       ax=ax,\n",
    "                        Plot=False,\n",
    "                      )\n",
    "        except:\n",
    "            print('increase fit range!')\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "\n",
    "    utl.PltErr(ax.axis()[:2],[1,1],Plot=False,ax=ax,\n",
    "                attrs={'fmt':'-.','color':'red'},\n",
    "                       ylim=(0,2),\n",
    "                      xscale='log',\n",
    "                       DrawFrame=DRAW_FRAME,\n",
    "                       title='png/exponentH_ni_T%sK.png'%temperature,\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### per type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "    symbols=utl.Symbols()\n",
    "    legends = Legends()\n",
    "    legends.Set(bbox_to_anchor=(1.0,0.5,0.5,0.5))\n",
    " \n",
    "                       \n",
    "    ntype = 5\n",
    "    for itype in range(1,ntype+1):\n",
    "        temp = Temperature(#[1000],3\n",
    "                           list(map(int,np.linspace(1000,1400,11))),3\n",
    "                          )\n",
    "        temp.Parse( list(map(lambda x:'CantorNatom16KTemp%sK_ensemble/Run%s/msd/msd_type%s.txt'%(x[0],x[1],itype),\n",
    "                            temp.temps_runs ))\n",
    "                  )\n",
    "        #\n",
    "  #      print('single realizations')\n",
    "  #      temp.Plot()\n",
    "        #\n",
    "        print('ensemble average: type %s'%itype)\n",
    "        temp.EnsAverage()\n",
    "#         temp.PlotAverage()\n",
    "#         #\n",
    "        temp.Fit(#Plot=True,\n",
    "        #         verbose=True\n",
    "        )\n",
    "#         temp.PlotDiff()\n",
    "        \n",
    "        #--- plot\n",
    "        utl.PltErr(1/np.array(list(temp.Diffusion.keys())),\n",
    "                   list(map(lambda x:temp.Diffusion[x],list(temp.Diffusion.keys()))),\n",
    "                       Plot=False,\n",
    "                   ax=ax,\n",
    "                   attrs=symbols.GetAttrs(count=(itype-1)%7,label=r'$%s$'%temp),\n",
    "                 )\n",
    "    utl.PltErr(None,None,\n",
    "               ax=ax,\n",
    "               yscale='log',\n",
    "               ylim=(1e-15,1e-11),\n",
    "              xstr=r'$1/T(K^{-1})$',\n",
    "              ystr=r'$D(m^2/s)$',\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tauu = temp.time_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## correlated noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Noise(Temperature):\n",
    "    def __init__(self,temp_range,nrun,verbose=False):\n",
    "        Temperature.__init__(self,temp_range,nrun)\n",
    "        self.verbose = verbose\n",
    "    #\n",
    "    def PlotNoise(self, col_a = 1, col_b=1,\n",
    "                  **kwargs):\n",
    "        #\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=(1.0,0.5,0.5,0.5))\n",
    "        #\n",
    "        self.crltns_mean_ab = {}\n",
    "        self.crltns_mean_ba = {}\n",
    "        self.crltns_err_ab = {}\n",
    "        self.crltns_err_ba = {}\n",
    "        kount = 0\n",
    "        #\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp\n",
    "            data = self.data[kount:kount+self.nrun]\n",
    "            if self.verbose:\n",
    "                print('data.shape (per temperature):',np.array(data).shape)\n",
    "                \n",
    "            #--- correlations\n",
    "            crltns_ab = np.c_[list(map(lambda x: Noise.Crltns(x[:,col_a],x[:,col_b]),data))]\n",
    "            crltns_ba = np.c_[list(map(lambda x: Noise.Crltns(x[:,col_b],x[:,col_a]),data))]\n",
    "            self.crltns_mean_ab[temp] = np.mean(crltns_ab,axis=0)\n",
    "            self.crltns_mean_ba[temp] = np.mean(crltns_ba,axis=0)\n",
    "            self.crltns_err_ab[temp] = np.std(crltns_ab,axis=0)/self.nrun**0.5\n",
    "            self.crltns_err_ba[temp] = np.std(crltns_ba,axis=0)/self.nrun**0.5\n",
    "            kount += self.nrun\n",
    "        #--- plot\n",
    "        irun = 0\n",
    "        smat=data[irun]\n",
    "        for i,j in zip(smat[:,0],smat[:,col_a]):\n",
    "            utl.PltErr([i,i],[0,j],\n",
    "                       attrs={'fmt':'-','color':'C0'},\n",
    "                       ax=self.ax,\n",
    "                       Plot=False,\n",
    "#                       **kwargs\n",
    "                      )\n",
    "        utl.PltErr(self.ax.axis()[:2],[0,0],\n",
    "                        ax=self.ax,\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                       **kwargs\n",
    "                       )\n",
    "\n",
    "            \n",
    "        \n",
    "    def PlotSum(self, col_a = 1, col_b=1,\n",
    "                  **kwargs):\n",
    "        #\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=(1.0,0.5,0.5,0.5))\n",
    "        #\n",
    "        kount = 0\n",
    "        #\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp\n",
    "            data = self.data[kount:kount+self.nrun]\n",
    "            if self.verbose:\n",
    "                print('data.shape (per temperature):',np.array(data).shape)\n",
    "                \n",
    "            #--- correlations\n",
    "            #--- plot\n",
    "            irun = 0\n",
    "            smat=data[irun]\n",
    "            utl.PltErr(smat[:,0],np.cumsum(smat[:,col_a]),\n",
    "                       attrs={'drawstyle':'steps-post'},\n",
    "                       ax=self.ax,\n",
    "                       Plot=False,\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                       **kwargs\n",
    "                      )\n",
    "\n",
    "#             utl.PltErr(lmpData.headers['Time'][1:-1:2],np.cumsum(xvv[:,2]),\n",
    "#                       attrs={'drawstyle':'steps-post'},\n",
    "#                       )\n",
    "\n",
    "            \n",
    "            kount += self.nrun\n",
    "        \n",
    "    @staticmethod        \n",
    "    def Crltns(a,b,n=10):\n",
    "        cr,err=Noise.CrossCr(a,b)\n",
    "        return cr[:n] #np.c_[cr,err]\n",
    "    \n",
    "    def zscore(slist):\n",
    "        slist -= np.mean(slist)\n",
    "        slist /= np.std( slist )\n",
    "        return slist\n",
    "\n",
    "    def CrossCr(x,y, ZSCORE = True):\n",
    "        if ZSCORE:\n",
    "            x -= np.mean( x )\n",
    "            y -= np.mean( y )\n",
    "\n",
    "            x /= np.std( x )\n",
    "            y /= np.std( y )\n",
    "        assert len(x) == len(y), 'len(x)=%s,len(y)=%s'%(len(x),len(y))\n",
    "        n = len(x)\n",
    "        x=np.concatenate([x,np.zeros(n)],axis=0)\n",
    "        y=np.concatenate([y,np.zeros(n)],axis=0)\n",
    "        ones = np.concatenate([np.ones(n),np.zeros(n)],axis=0)\n",
    "\n",
    "        X=np.fft.fft(x)\n",
    "        Y=np.fft.fft(y)\n",
    "        Z=X.conjugate()*Y\n",
    "\n",
    "        cq = np.fft.fft( ones )\n",
    "        count = np.fft.ifft( cq.conjugate()*cq ).real[:n]\n",
    "\n",
    "        z=np.fft.ifft(Z)[:n] / count\n",
    "\n",
    "        return z, 1.0/np.sqrt(count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def PlotCrltns(self,**kwargs):\n",
    "\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=(1.0,0.5,0.5,0.5))\n",
    "        \n",
    "        ax = utl.PltErr(None,None,Plot=False)\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            n=noise.crltns_mean_ba[temp].shape[0]\n",
    "            x=np.concatenate([-np.arange(n-1,-1,-1),np.arange(n)])\n",
    "            indices=np.arange(n-1,-1,-1)\n",
    "            y=np.concatenate([noise.crltns_mean_ba[temp][indices],\n",
    "                              noise.crltns_mean_ab[temp]])\n",
    "            yerr=np.concatenate([noise.crltns_err_ba[temp][indices],\n",
    "                              noise.crltns_err_ab[temp]])\n",
    "\n",
    "\n",
    "            utl.PltErr(x,\n",
    "                       y,\n",
    "                       yerr=2*yerr,\n",
    "                       attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp),\n",
    "                       Plot=False,\n",
    "                       ax=ax,\n",
    "                      )\n",
    "            \n",
    "        utl.PltErr(ax.axis()[:2],[0,0],\n",
    "                   attrs={'fmt':'-.r'},\n",
    "                   Plot=False,\n",
    "            DrawFrame=DRAW_FRAME,\n",
    "                   ax=ax,\n",
    "                       **kwargs\n",
    "                  )\n",
    "    \n",
    "\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    #--- temp object\n",
    "    noise = Noise(\n",
    "#        [1000,1200,1400,1600,1800,2000],8,\n",
    "        [2000],8,\n",
    "#         verbose = True,\n",
    "                     )\n",
    "    #\n",
    "    #--- parse data\n",
    "#    noise.Parse(['./msd/noise.txt'])\n",
    "#    temp.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "    noise.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/noise.txt'%(x[0],x[1]),\n",
    "#    temp.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "#    temp.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "                        noise.temps_runs ))\n",
    "             )\n",
    "    #\n",
    "    #--- plot\n",
    "    noise.PlotNoise(col_a=1,col_b=1,**{\n",
    "#                   'attrs':{'fmt':'-','color':'C0'},\n",
    "#                   'xlim':(0,0.5e-09),\n",
    "#                    'ylim':(-2,2),\n",
    "#                     'xticks':([r'$0$',r'$2$',r'$4$'],[0,2e-10,4e-10]),\n",
    "#                   'title':'png/noise_z_nicocr.png',\n",
    "#                   'bbox_to_anchor':(0.01,0.3,0.5,0.5)\n",
    "    })\n",
    "    #\n",
    "    #--- plot sum\n",
    "#     noise.PlotSum(col_a=1,col_b=1,**{\n",
    "# #                  'xscale':'log',\n",
    "# #                  'yscale':'log',\n",
    "#                    'xlim':(0,1e-09),\n",
    "# #                    'ylim':(1e-5,1e-1),\n",
    "# #                   'xstr':r'$t\\mathrm{(s)}$',\n",
    "# #                   'ystr':r'msd(A$^2$)',\n",
    "# #                   'title':'png/msd_temp_ni.png',\n",
    "#         'bbox_to_anchor':(0.01,0.3,0.5,0.5)\n",
    "#     })\n",
    "\n",
    "    \n",
    "    #\n",
    "    noise.PlotCrltns(\n",
    "        **{\n",
    "#                   'yscale':'log',\n",
    "#                   'xscale':'log',\n",
    "#                   'xlim':(1e-10,1e-3),\n",
    "#                    'ylim':(1e-4,1e-1),\n",
    "#                     'xstr':r'$t\\mathrm{(s)}$',\n",
    "#                   'ystr':r'msd(A$^2$)',\n",
    "                   'title':'png/noiseCrltn_yz_nicocr.png',\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wait times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stats(Temperature):\n",
    "    def __init__(self,temp_range,nrun,verbose=False):\n",
    "        Temperature.__init__(self,temp_range,nrun)\n",
    "        self.verbose = verbose\n",
    "    #\n",
    "    def PlotWaitTimes(self,scale=False,\n",
    "                      scalePowerLaw=False,\n",
    "                      shift=False,\n",
    "                      n_per_decade=6,\n",
    "                      **kwargs):\n",
    "        #\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=(1.0,0.5,0.5,0.5))\n",
    "        #\n",
    "        self.mean_rate = {}\n",
    "        kount = 0\n",
    "        #\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            nruns = len(self.nrun[indx])\n",
    "            #--- concat. data for each temp\n",
    "            data = self.data[kount:kount+nruns]\n",
    "            data = list(map(lambda x:self.GetWaitTimes(x),data))\n",
    "            if self.verbose:\n",
    "                print('data.shape (per temperature):',np.array(data).shape)\n",
    "            data = np.concatenate(data) #,axis=0)\n",
    "            rate = 1.0 / data.mean()\n",
    "            self.mean_rate[temp] = [ rate, rate*(1/len(data)**0.5)]\n",
    "            if scale:\n",
    "                data /= data.mean() \n",
    "            if self.verbose:\n",
    "                print('data.shape (concatenated):',data.shape)\n",
    "            #--- histogram\n",
    "            hist, bin_edges, err = utl.GetPDF(data,n_per_decade=n_per_decade)\n",
    "            if scalePowerLaw:\n",
    "                alpha = 2 #1.5\n",
    "                hist *= bin_edges ** alpha \n",
    "                err *= bin_edges ** alpha \n",
    "            #--- plot\n",
    "            if shift:\n",
    "                hist *= 10 ** indx \n",
    "                err *= 10 ** indx \n",
    "            utl.PltErr(bin_edges,hist,\n",
    "                          yerr=err,\n",
    "                   attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp,fmt='.'),\n",
    "                   ax = self.ax,\n",
    "                   Plot=False,\n",
    "                          )\n",
    "            kount += nruns\n",
    "        self.data_regr = np.c_[bin_edges,hist,err]\n",
    "        #\n",
    "        xhi=self.ax.axis()[1]\n",
    "        xarr = np.logspace(np.log10(xhi)-5.0,np.log10(xhi),32)\n",
    "        utl.PltErr( xarr if scale else None,\n",
    "                   np.exp(-xarr) if scale else None,\n",
    "                   attrs={'fmt':'-.r','lw':2},\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "                   \n",
    "#                    legend=legends.Get(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "            \n",
    "    def PlotAverageRate(self,**kwargs):\n",
    "#        print(list(self.temps_runs))\n",
    "#         self.ax = utl.PltErr(None,#ans[:,0],\n",
    "#                         None,#1e8*ans[:,0],\n",
    "#                         attrs={'fmt':'-.r'},Plot=False)\n",
    "\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=(1.0,0.5,0.5,0.5))\n",
    "        data = list(map(lambda x:self.mean_rate[ x ][0], self.temps))\n",
    "        err = list(map(lambda x:self.mean_rate[ x ][1], self.temps))\n",
    "#             utl.PltErr(data[:,0],data[:,1],\n",
    "#                    yerr=data[:,2],\n",
    "#                    ax = self.ax,\n",
    "#                    attrs=symbols.GetAttrs(count=count%7,label=r'$%s$'%temp),\n",
    "#                    Plot=False,\n",
    "#                   )\n",
    "\n",
    "        utl.PltErr(1.0/np.array(self.temps),\n",
    "                   data,\n",
    "                   yerr=err,\n",
    "                   attrs=symbols.GetAttrs(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "            \n",
    "    \n",
    "    def GetWaitTimes(self,times):\n",
    "#         times = np.array(np.c_[self.lmpData.headers['Time'].iloc[0::2]].flatten())\n",
    "        dtt = times[1:]-times[:-1]\n",
    "        assert not np.any(dtt<0.0)\n",
    "        filtr = dtt > 0.0\n",
    "        return dtt[filtr]\n",
    "\n",
    "    #\n",
    "    def Barries(self):\n",
    "        Barrier = self.lmpData.headers['Barrier'].iloc[1::2]        \n",
    "        hist, bin_edges, err = utl.GetPDF(Barrier,linscale=True,n_per_decade=16)\n",
    "        utl.PltErr(bin_edges,hist,\n",
    "                  yerr=err,\n",
    "                   attrs=symbols.GetAttrs(),\n",
    "                   #yscale='log',\n",
    "                   #xscale='log',\n",
    "                   xstr=r'$\\Delta E$',\n",
    "                   ystr=r'$P(\\Delta E)$'\n",
    "                  )\n",
    "\n",
    "    def func(self,x,k,alpha,beta,t0):\n",
    "        return k*(x/t0)**(-alpha)/(1+(x/t0)**(beta-alpha))\n",
    "    \n",
    "    \n",
    "    def fit(self,edge,hist,err):\n",
    "        xdata=edge\n",
    "        ydata=hist\n",
    "        yerr=err\n",
    "        popt, pcov = curve_fit(self.func,xdata,ydata,\n",
    "                              p0=(1.0,0.4,2,1.0),\n",
    "                               sigma=yerr,\n",
    "                              )\n",
    "\n",
    "        ax=utl.PltErr(edge,hist,yerr=err,\n",
    "                   yscale='log',xscale='log',\n",
    "                      Plot=False\n",
    "                  )\n",
    "        utl.PltErr(edge,self.func(edge,*popt),attrs={'fmt':'-.r'},\n",
    "                   yscale='log',xscale='log',\n",
    "                   ax=ax,\n",
    "                   ylim=(1e-5,1000),\n",
    "                  )\n",
    "#        assert popt[-1]>0\n",
    "        print('k,alpha,beta,t0',popt)\n",
    "        return popt[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    if eval(confParser['flags']['RemoteMachine']):\n",
    "        return \n",
    "    \n",
    "    !mkdir png\n",
    "\n",
    "    stats = Stats(\n",
    "#         [1000,1200,1400,1600,1800,2000],8,\n",
    "        [1000], [list(range(8))]*10,\n",
    "#        [0,1],[list(range(8))]*10,\n",
    "#        np.arange(1000,1440,80),1,\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse(['msd/event_times.txt'])\n",
    "    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/event_times.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/event_times.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/event_times.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/event_times.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'flickers/nicocr/temp0/thresh%s/Run%s/msd/event_times.txt'%(x[0],x[1]),\n",
    "                        stats.temps_runs ))\n",
    "              )\n",
    "    stats.PlotWaitTimes(scale=True,shift=False,scalePowerLaw=False,\n",
    "                        n_per_decade=6,\n",
    "                        **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "#                     'xlim':(1e-3,100),\n",
    "                      'ylim':(1e-5,1e2),#(1e-8,1e6), #,\n",
    "#                    'ndecade_y':2,\n",
    "#                            'xstr':r'$t_w$',\n",
    "#                            'ystr':r'$P(\\lambda t_w)$',\n",
    "                   'title':'png/waitTimes_unscaled_ni.png'},\n",
    "\n",
    "                       )\n",
    "#     stats.PlotWaitTimes(scale=True,scalePowerLaw=True,\n",
    "#                         **{'xscale':'log',\n",
    "#                   'yscale':'log',\n",
    "# #                   'xlim':(1e-9,1e-3),\n",
    "#                    'ylim':(1e-5,1e0), #(1e-5,1e2),\n",
    "# #                           'xstr':r'$\\Delta t$',\n",
    "# #                           'ystr':r'$P(\\Delta t)$',\n",
    "#                    'title':'png/waitTimes_rescaled_ni.png'},\n",
    "#                       )\n",
    "#     stats.PlotAverageRate(\n",
    "#                 **{\n",
    "# #                    'fontsize':36,\n",
    "# #                  'xscale':'log',\n",
    "#                   'yscale':'log',\n",
    "# #                   'xlim':(1e-9,1e-3),\n",
    "# #                   'ylim':(1e9,1e13), #(1e-5,1e2),\n",
    "# #                           'xstr':r'$1/T$',\n",
    "# #                           'ystr':r'$\\lambda$',\n",
    "#                    'title':'png/eventRate_nicocr.png'},\n",
    "\n",
    "#     )\n",
    "    #\n",
    "#    stats.fit(stats.data_regr[:,0],stats.data_regr[:,1],stats.data_regr[:,2])\n",
    "    #stats.Barries()\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### effective E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x,a,b):\n",
    "    return a*np.exp(-b*x)\n",
    "\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    kb=8.61732814974056e-05\n",
    "    xdata = 1/(kb*np.array(stats.temps))\n",
    "    ydata = list(map(lambda x:stats.mean_rate[x][0],stats.temps))\n",
    "    yerr = list(map(lambda x:stats.mean_rate[x][1],stats.temps))\n",
    "    popt,pcov=curve_fit(func,xdata,ydata,\n",
    "             p0=[1e12,1],\n",
    "             sigma=yerr\n",
    "             )\n",
    "    #\n",
    "    ax=utl.PltErr(xdata,ydata,yerr=yerr,\n",
    "               fmt='.',\n",
    "               Plot=False\n",
    "\n",
    "              )\n",
    "    utl.PltErr(xdata,func(xdata,*popt),\n",
    "               yscale='log',\n",
    "               attrs={'fmt':'-.r'},\n",
    "               ax=ax,\n",
    "               xstr=r'$1/k_BT$',ystr=r'$\\lambda$'\n",
    "\n",
    "              )\n",
    "    Tm=[1650,2100][0]\n",
    "    print('energy=%s eV'%popt[1])\n",
    "    print('scaled energy=',popt[1]/kb/Tm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reduced temperature scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    #Tm = 1650\n",
    "    xdata = np.array(stats.temps)\n",
    "    ydata = list(map(lambda x:stats.mean_rate[x][0],stats.temps))\n",
    "    yerr = list(map(lambda x:stats.mean_rate[x][1],stats.temps))\n",
    "    np.savetxt('ni2nd.txt',np.c_[xdata,ydata,yerr],header='T lambda err')\n",
    "\n",
    "    symbols=utl.Symbols()\n",
    "    legends = Legends()\n",
    "    legends.Set(bbox_to_anchor=(1.0,0.5,0.5,0.5))\n",
    "\n",
    "\n",
    "\n",
    "    Tm = 1650\n",
    "    data_nicocr = np.loadtxt('nicocr.txt')\n",
    "    xdata = Tm/data_nicocr[:,0]\n",
    "    ydata = data_nicocr[:,1]\n",
    "    yerr = data_nicocr[:,2]\n",
    "\n",
    "    ax=utl.PltErr(xdata,ydata,yerr=yerr,\n",
    "                    attrs=symbols.GetAttrs(count=1,label=r'nicocr'),\n",
    "              Plot=False,\n",
    "             yscale='log'\n",
    "             )\n",
    "\n",
    "    Tm = 2100\n",
    "    data_ni = np.loadtxt('ni.txt')\n",
    "    xdata = Tm/data_ni[:,0]\n",
    "    ydata = data_ni[:,1]\n",
    "    yerr = data_ni[:,2]\n",
    "\n",
    "    utl.PltErr(xdata,ydata,yerr=yerr,\n",
    "                    attrs=symbols.GetAttrs(count=0,label=r'ni'),\n",
    "            ax=ax,\n",
    "              Plot=False,\n",
    "             yscale='log',\n",
    "                     legend=legends.Get(),\n",
    "               xstr=r'$T_m/T$',ystr=r'$\\lambda$'\n",
    "             )\n",
    "\n",
    "    # Tm = 1607\n",
    "    # data_ni = np.loadtxt('cantor.txt')\n",
    "    # xdata = Tm/data_ni[:,0]\n",
    "    # ydata = data_ni[:,1]\n",
    "    # yerr = data_ni[:,2]\n",
    "\n",
    "    # utl.PltErr(xdata,ydata,yerr=yerr,\n",
    "    # #          fmt='.',\n",
    "    #         ax=ax,\n",
    "    #           Plot=False,\n",
    "    #          yscale='log'\n",
    "    #          )\n",
    "\n",
    "    # Tm = 2100\n",
    "    # data_ni = np.loadtxt('ni2nd.txt')\n",
    "    # xdata = Tm/data_ni[:,0]\n",
    "    # ydata = data_ni[:,1]\n",
    "    # yerr = data_ni[:,2]\n",
    "\n",
    "    # utl.PltErr(xdata,ydata,yerr=yerr,\n",
    "    # #          fmt='.',\n",
    "    #         ax=ax,\n",
    "    #           Plot=False,\n",
    "    #          yscale='log',\n",
    "    #                  legend=legends.Get(),\n",
    "\n",
    "    #          )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    path = '../simulations/NiMultTemp/Temp2000K/Run0'\n",
    "\n",
    "    #--- parse\n",
    "    data = pd.read_csv('%s/thermo.txt'%path,delimiter=' ')\n",
    "\n",
    "    #--- plot\n",
    "    utl.PltErr(data.time,data.vol,ystr='vol')\n",
    "    utl.PltErr(data.time,data.temp,ystr='temp')\n",
    "\n",
    "    #--- mean \n",
    "    filtr = data.time > 100.0\n",
    "    n = np.sum(filtr)\n",
    "    mean_vol = data.vol[filtr].mean()\n",
    "    err_vol = data.vol[filtr].std()/n**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    mean_vol = {}\n",
    "    err_vol = {}\n",
    "    temps = np.linspace(2000,3000,16)\n",
    "    for temp in temps:\n",
    "        path = '../simulations/NiMultTemp/Temp%sK/Run0'%int(temp)\n",
    "\n",
    "        #--- parse\n",
    "        data = pd.read_csv('%s/thermo.txt'%path,delimiter=' ')\n",
    "\n",
    "        #--- plot\n",
    "    #    utl.PltErr(data.time,data.vol,ystr='vol')\n",
    "    #    utl.PltErr(data.time,data.temp,ystr='temp')\n",
    "\n",
    "        #--- mean \n",
    "        filtr = data.time > 100.0\n",
    "        n = np.sum(filtr)\n",
    "        mean_vol[temp] = data.vol[filtr].mean()\n",
    "        err_vol[temp] = data.vol[filtr].std()/n**0.5\n",
    "    \n",
    "    filtr = temps>0\n",
    "    utl.PltErr(temps[filtr],\n",
    "               np.array(list(map(lambda x:mean_vol[x],temps)))[filtr],\n",
    "\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JumpStats(Temperature):\n",
    "    def __init__(self,temp_range,nrun,verbose=False):\n",
    "        Temperature.__init__(self,temp_range,nrun)\n",
    "        self.verbose = verbose\n",
    "    #\n",
    "    def PlotPdf(self,scale=False,**kwargs):\n",
    "        #\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "        #\n",
    "        self.mean_rate = {}\n",
    "        kount = 0\n",
    "        #\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp\n",
    "            data = self.data[kount:kount+self.nrun][0]\n",
    "            if self.verbose:\n",
    "                print('data.shape (per temperature):',np.array(data).shape)\n",
    "            if self.verbose:\n",
    "                print('data.shape (concatenated):',data.shape)\n",
    "            #--- histogram\n",
    "#            data = np.array(data).flatten()\n",
    "            hist = data[:,1]\n",
    "            bin_edges = data[:,0]\n",
    "            err = data[:,2]\n",
    "            \n",
    "            #--- remove count == 1\n",
    "            filtr = err == hist\n",
    "            hist = hist[~filtr]\n",
    "            bin_edges = bin_edges[~filtr]\n",
    "            err = err[~filtr]\n",
    "            \n",
    "            self.data_regr = np.c_[bin_edges,hist,err]\n",
    "            if scale:\n",
    "                hist *= bin_edges ** self.alpha\n",
    "                err  *= bin_edges ** self.alpha\n",
    "        #--- plot\n",
    "#            temp= [1000,1200,1400,1600,1800,2000][indx]\n",
    "            utl.PltErr(bin_edges,hist,\n",
    "                          yerr=err,\n",
    "                   attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp,fmt='.'),\n",
    "                   ax = self.ax,\n",
    "                   Plot=False,\n",
    "                          )\n",
    "            kount+=self.nrun\n",
    "        #\n",
    "        utl.PltErr(None,\n",
    "                   None,\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "#                      legend=legends.Get(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "            \n",
    "    def func(self,x,k,alpha):\n",
    "        return k*x**alpha\n",
    "    \n",
    "    \n",
    "    def fit(self,edge,hist,err):\n",
    "        xdata=edge\n",
    "        ydata=hist\n",
    "        yerr=err\n",
    "        popt, pcov = curve_fit(self.func,xdata,ydata,\n",
    "                               p0=(1.0e-4,-2.0),\n",
    "                               sigma=2*yerr,\n",
    "                              )\n",
    "\n",
    "        ax=utl.PltErr(edge,hist,yerr=2*err,fmt='.',\n",
    "                   yscale='log',xscale='log',\n",
    "                      Plot=False\n",
    "                  )\n",
    "        utl.PltErr(edge,self.func(edge,*popt),attrs={'fmt':'-.r'},\n",
    "                   yscale='log',xscale='log',\n",
    "                   ax=ax,\n",
    "#                   ylim=(1e-5,1000),\n",
    "                  )\n",
    "#        assert popt[-1]>0\n",
    "        print('k,alpha',popt)\n",
    "        return popt[0]\n",
    "    \n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    \n",
    "    stats = JumpStats(\n",
    "        [1000,1200,1400,1600,1800,2000],\n",
    "#        [1000,1200,1400,1600,1800,2000],\n",
    "#        np.arange(1000,1440,80),\n",
    "        1,\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/event_jumps.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/event_jumps.txt'%(x[0],x[1]),\n",
    "    stats.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/event_jumps.txt'%(x[0],x[1]),\n",
    "                         stats.temps_runs ))\n",
    "               )\n",
    "    stats.PlotPdf(scale=False,\n",
    "                        **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "                   'xlim':(1e-8,4e0),\n",
    "#                   'ylim':(1e-3,1e1), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "                        'ndecade_x':2,'ndecade_y':2,\n",
    "                    'bbox_to_anchor':(0.56,0.27,0.5,0.5),\n",
    "                   'title':'png/jumpsPdf_nicocr.png'},\n",
    "\n",
    "                       )\n",
    "    \n",
    "    #--- rescale\n",
    "    stats.alpha = 2.5 #2.8 #3.0#2.5\n",
    "    stats.PlotPdf(scale=True,\n",
    "                **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "                   'fontsize':32,\n",
    "#                   'xlim':(1e-8,2e0),\n",
    "#                   'ylim':(1e-3,1e1), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "                        'ndecade_x':2,'ndecade_y':4,\n",
    "                   'title':'png/jumpsPdf_rescaled_ni.png'},\n",
    "\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "\n",
    "    stats = JumpStats(\n",
    "        [2000],1,\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/event_jumps.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/event_jumps.txt'%(x[0],x[1]),\n",
    "    stats.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/event_jumps.txt'%(x[0],x[1]),\n",
    "                         stats.temps_runs ))\n",
    "               )\n",
    "    stats.PlotPdf(scale=False,\n",
    "                        **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "                   'xlim':(1e-8,4e0),\n",
    "#                   'ylim':(1e-3,1e1), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "                        'ndecade_x':2,'ndecade_y':2,\n",
    "                    'bbox_to_anchor':(0.56,0.27,0.5,0.5),\n",
    "#                    'title':'png/jumpsPdf_nicocr.png'\n",
    "                          },\n",
    "\n",
    "                       )\n",
    "    filtr = np.all([stats.data_regr[:,0]>1e-3,stats.data_regr[:,0]<1e-1],axis=0)\n",
    "    stats.fit(stats.data_regr[:,0][filtr],stats.data_regr[:,1][filtr],stats.data_regr[:,2][filtr])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Energy = lmpData.headers['Energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not eval(confParser['flags']['RemoteMachine']):\n",
    "#             data = self.data[kount:kount+self.nrun]\n",
    "#             if self.verbose:\n",
    "#                 print('data.shape:',np.array(data).shape)\n",
    "# #             print('np.array(data):',np.array(data))\n",
    "# #             pdb.set_trace()\n",
    "    \n",
    "#             filtr = list(map(lambda x:x.shape[0] > 0,data)) #--- filter empty arrays\n",
    "    \n",
    "#             data = np.concatenate(np.array(data)[filtr]) #,axis=0)\n",
    "#             self.data_averaged[ temp ] = self.hist(data,log_scale)\n",
    "#             kount += self.nrun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sampled energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class EnergyStats(Temperature):\n",
    "    def __init__(self,temp_range,nrun,verbose=False):\n",
    "        Temperature.__init__(self,temp_range,nrun)\n",
    "        self.verbose = verbose\n",
    "    #\n",
    "    def GetWaitTimes(self,times):\n",
    "        times = times[0::2]\n",
    "        dtt = times[1:]-times[:-1]\n",
    "        assert not np.any(dtt<0.0)\n",
    "#        filtr = dtt > 0.0\n",
    "        return dtt#[filtr]\n",
    "    #\n",
    "    def PlotPdf(self,shift=False,column_energy = 0,n_per_decade=8,\n",
    "                linscale = False,\n",
    "                **kwargs):\n",
    "        #\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs #plotAttrs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "        #\n",
    "        self.mean_rate = {}\n",
    "        #\n",
    "        kount = 0\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            nruns = len(self.nrun[indx])\n",
    "\n",
    "            #--- concat. data for each temp            \n",
    "            data = np.concatenate(list(map(lambda x: self.data[x][:,column_energy],range(kount,kount+nruns))))\n",
    "            #--- remove zeros\n",
    "            data = data[data > 0.0]\n",
    "            if self.verbose:\n",
    "                print('data.shape (per temperature):',np.array(data).shape)\n",
    "            if self.verbose:\n",
    "                print('data.shape (concatenated):',data.shape)\n",
    "            #--- histogram\n",
    "#            data = np.array(data).flatten()\n",
    "            #--- histogram\n",
    "            hist, bin_edges, err = utl.GetPDF(data,n_per_decade=n_per_decade,linscale=linscale)\n",
    "        \n",
    "            #--- filtr\n",
    "            filtr = hist == err\n",
    "            hist = hist[~filtr]\n",
    "            bin_edges = bin_edges[~filtr]\n",
    "            err = err[~filtr]\n",
    "        #--- plot\n",
    "            if shift:\n",
    "                hist *= 100**indx if shift else 1\n",
    "                err *= 100**indx if shift else 1\n",
    "\n",
    "            utl.PltErr(bin_edges,hist,\n",
    "#                           yerr=err,\n",
    "                    attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp), #,fmt='.'),\n",
    "#                   attrs={'fmt':'-','color':'C0'},\n",
    "                   ax = self.ax,\n",
    "                   Plot=False,\n",
    "                          )\n",
    "            \n",
    "#            self.ax.fill_between(bin_edges, hist)\n",
    "            \n",
    "            kount += nruns #self.nrun\n",
    "        #\n",
    "        utl.PltErr(None,\n",
    "                   None,\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "                   \n",
    "#                    legend=legends.Get(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "        \n",
    "    def PlotPdfConcat(self,scale=False,\n",
    "                      column_energy = 0,\n",
    "                      type_column=0,\n",
    "                      splitByType=True,\n",
    "                      n_per_decade = 8,\n",
    "                      **kwargs):\n",
    "        #\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs #plotAttrs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "        #\n",
    "        self.mean_rate = {}\n",
    "        kount = 0\n",
    "        #\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp            \n",
    "#            data = np.concatenate(list(map(lambda x: self.data[x][:,column_energy],range(indx,indx+self.nrun))))\n",
    "            data = np.concatenate(list(map(lambda x: self.data[x],range(kount,kount+self.nrun))))\n",
    "#             types = np.concatenate(list(map(lambda x: self.data[x][:,type_column],range(indx,indx+self.nrun))))\n",
    "            #--- remove zeros\n",
    "#            data = data[data > 0.0]\n",
    "            if self.verbose:\n",
    "                print('data.shape (per temperature):',np.array(data).shape)\n",
    "            if self.verbose:\n",
    "                print('data.shape (concatenated):',data.shape)\n",
    "            #--- histogram\n",
    "#            data = np.array(data).flatten()\n",
    "            #--- histogram\n",
    "            data_concat = data.copy() if indx ==0 else np.concatenate([data_concat,data]) #np.c_[types,data] if indx ==0 else\\\n",
    "                        #np.concatenate([data_concat,np.c_[types,data]])\n",
    "            kount += self.nrun\n",
    "        if self.verbose:\n",
    "            print('type.shape (concatenated):',data_concat.shape)\n",
    "        \n",
    "        #--- split by type\n",
    "        if splitByType:\n",
    "            df=pd.DataFrame(np.c_[data_concat[:,type_column],data_concat[:,column_energy]],\n",
    "                            columns=['type','dE'])\n",
    "            types=df.groupby(by='type').groups\n",
    "            for itype in types:\n",
    "                indices = types[itype]\n",
    "                elist = np.array(df['dE'].iloc[indices])\n",
    "                if self.verbose:\n",
    "                    print('elist.shape:',elist.shape)\n",
    "\n",
    "                #--- histogram\n",
    "                hist, bin_edges, err = utl.GetPDF(elist,n_per_decade=n_per_decade)\n",
    "\n",
    "                #--- filtr\n",
    "                filtr = hist == err\n",
    "                hist = hist[~filtr]\n",
    "                bin_edges = bin_edges[~filtr]\n",
    "                err = err[~filtr]\n",
    "                #--- plot\n",
    "                if scale:\n",
    "                    hist *= 1000**int(itype)\n",
    "                    err *= 1000**int(itype)\n",
    "                utl.PltErr(bin_edges,hist,\n",
    "                              yerr=err,\n",
    "                       attrs=symbols.GetAttrs(count=int(itype-1)%7,label=r'$%s$'%itype), #,fmt='.'),\n",
    "                       ax = self.ax,\n",
    "                       Plot=False,\n",
    "                              )\n",
    "        else:\n",
    "                data = data_concat[:,column_energy]\n",
    "                data = data[data > 0.0]\n",
    "\n",
    "                #--- histogram\n",
    "                hist, bin_edges, err = utl.GetPDF(data,n_per_decade=n_per_decade)\n",
    "\n",
    "                #--- filtr\n",
    "                filtr = hist == err\n",
    "                hist = hist[~filtr]\n",
    "                bin_edges = bin_edges[~filtr]\n",
    "                err = err[~filtr]\n",
    "                #--- plot\n",
    "#                 if scale:\n",
    "#                     hist *= 100**int(itype)\n",
    "#                     err *= 100**int(itype)\n",
    "                utl.PltErr(bin_edges,hist,\n",
    "                              yerr=err,\n",
    "                       attrs=symbols.GetAttrs(count=0), #,label=r'$%s$'%itype),#,fmt='.'),\n",
    "                       ax = self.ax,\n",
    "                       Plot=False,\n",
    "                              )\n",
    "        #\n",
    "        utl.PltErr(None,\n",
    "                   None,\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "\n",
    "#                        legend=legends.Get(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "\n",
    "    def Scatter(self,shift=False,nevery=1,**kwargs):\n",
    "        kb_inv=8.61732814974056e05\n",
    "        \n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=Symbols(markersizes=np.array([10,10,10,12,12,12,10])*8)\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs #plotAttrs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "\n",
    "        #\n",
    "        column_energy = 0\n",
    "        column_time = 3\n",
    "        kount = 0\n",
    "        for indx in range(0,len(self.temps),nevery):\n",
    "            temp = self.temps[indx]\n",
    "            #--- concat. data for each temp            \n",
    "            data_energy = np.concatenate(list(map(lambda x: self.GetEnergy(self.data[x][:,column_energy]),\n",
    "                                                  range(kount,kount+self.nrun))))\n",
    "            #--- wait_times\n",
    "            data = self.data[indx:indx+self.nrun]\n",
    "            data_waitTimes = np.concatenate(list(map(lambda x: self.GetWaitTimes(self.data[x][:,column_time]),\n",
    "                                                     range(kount,kount+self.nrun))))\n",
    "\n",
    "            if self.verbose:\n",
    "                print('data_energy.shape (per temperature):',np.array(data_energy).shape)\n",
    "                print('data_waitTimes.shape (per temperature):',np.array(data_waitTimes).shape)\n",
    "            #--- plot scatter\n",
    "            scale = 1e2 ** indx if shift else 1\n",
    "            filtr = data_waitTimes > 0\n",
    "#             utl.PltErr(data_energy[filtr]*kb_inv/temp,scale*data_waitTimes[filtr],\n",
    "#                         attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp,fmt='.',alpha=1.0),\n",
    "#                         ax = self.ax,\n",
    "#                         Plot=False,\n",
    "#                         )\n",
    "            self.ax.scatter(data_energy[filtr]*kb_inv/temp,scale*data_waitTimes[filtr],\n",
    "                        **symbols.GetAttrsScatter(count=indx%7,label=r'$%s$'%temp,fmt='.',alpha=0.1/2),\n",
    "                       )\n",
    "            kount += self.nrun\n",
    "            #--- plot average\n",
    "#             nbins = 8\n",
    "#             count, _=np.histogram(data_energy[filtr],bins=nbins)\n",
    "#             xsum, _=np.histogram(data_energy[filtr],weights=data_energy[filtr],bins=nbins)\n",
    "#             ysum, _=np.histogram(data_energy[filtr],weights=data_waitTimes[filtr],bins=nbins)\n",
    "#             ysum /= count\n",
    "# #            ysum =10 ** ysum \n",
    "#             xsum /= count\n",
    "#             #---\n",
    "#             utl.PltErr(xsum,ysum,\n",
    "#                         attrs=symbols.GetAttrs(count=(indx)%7,label=r'$%s$'%temp,fmt='.'),\n",
    "#                         ax = self.ax,\n",
    "#                         Plot=False,\n",
    "#                         )\n",
    "        \n",
    "        \n",
    "        utl.PltErr(None,\n",
    "                   None,\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "#                     legend=legends.Get(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "\n",
    "    def GetEnergy(self,slist):\n",
    "        n=len(slist)\n",
    "        return slist[1:n:2]\n",
    "            \n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    \n",
    "    stats = EnergyStats(\n",
    "        [1000,1200,1400,1600,1800,2000],8,\n",
    "#        [1000,1400,1800,2000],8,\n",
    "#        [1000, 1400,1800],8,\n",
    "        #        np.arange(1000,1440,40),1,\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "                         stats.temps_runs ))\n",
    "               )\n",
    "    stats.PlotPdf(shift=True,n_per_decade=10,\n",
    "                        **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "#                   'xlim':(1e-3,1e0),\n",
    "#                   'ylim':(1e-2,1e2), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "                        'ndecade_y':2,\n",
    "                   'title':'png/BarrierPdf_cantor.png'},\n",
    "\n",
    "                       )\n",
    "    \n",
    "#     stats.PlotPdfConcat(scale=False,\n",
    "#                         splitByType = False,\n",
    "#                         **{'xscale':'log',\n",
    "#                       'yscale':'log',\n",
    "#     #                   'xlim':(1e-3,1e0),\n",
    "# #                        'ylim':(1e-2,1e2), #(1e-5,1e2),\n",
    "#     #                           'xstr':r'$\\Delta t$',\n",
    "#     #                           'ystr':r'$P(\\Delta t)$',\n",
    "#     #                        'ndecade_x':2,'ndecade_y':2,\n",
    "#     #                   'title':'png/BarrierPdf_cantor.png'\n",
    "#                           },\n",
    "#                        )\n",
    "\n",
    "    stats.Scatter(nevery=2, shift = True,                        \n",
    "                **{'xscale':'linear',\n",
    "                  'yscale':'log',\n",
    "#                   'xlim':(1e-3,1),\n",
    "#                   'ylim':(1e-3,1e1), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "#                     'bbox_to_anchor':(0.56,0.27,0.5,0.5),\n",
    "                        'ndecade_y':2,\n",
    "                   'title':'png/twVsEnergy_nicocr.png',\n",
    "                  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# class EnergyStats(Temperature):\n",
    "#     def __init__(self,temp_range,nrun,verbose=False):\n",
    "#         Temperature.__init__(self,temp_range,nrun)\n",
    "#         self.verbose = verbose\n",
    "#     #\n",
    "#     def GetWaitTimes(self,times):\n",
    "#         times = times[0::2]\n",
    "#         dtt = times[1:]-times[:-1]\n",
    "#         assert not np.any(dtt<0.0)\n",
    "# #        filtr = dtt > 0.0\n",
    "#         return dtt#[filtr]\n",
    "#     #\n",
    "#     def PlotPdf(self,shift=False,column_energy = 0,n_per_decade=8,\n",
    "#                 **kwargs):\n",
    "#         #\n",
    "#         self.ax = utl.PltErr(None,#ans[:,0],\n",
    "#                         None,#1e8*ans[:,0],\n",
    "#                         attrs={'fmt':'-.r'},Plot=False)\n",
    "#         symbols=utl.Symbols()\n",
    "#         legends = Legends()\n",
    "#         legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs #plotAttrs\n",
    "#                     else (1.0,0.5,0.5,0.5))\n",
    "#         #\n",
    "#         self.mean_rate = {}\n",
    "#         #\n",
    "#         kount = 0\n",
    "#         for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "#             #--- concat. data for each temp            \n",
    "#             data = np.concatenate(list(map(lambda x: self.data[x][:,column_energy],range(kount,kount+self.nrun))))\n",
    "#             #--- remove zeros\n",
    "#             data = data[data > 0.0]\n",
    "#             if self.verbose:\n",
    "#                 print('data.shape (per temperature):',np.array(data).shape)\n",
    "#             if self.verbose:\n",
    "#                 print('data.shape (concatenated):',data.shape)\n",
    "#             #--- histogram\n",
    "# #            data = np.array(data).flatten()\n",
    "#             #--- histogram\n",
    "#             hist, bin_edges, err = utl.GetPDF(data,n_per_decade=n_per_decade)\n",
    "        \n",
    "#             #--- filtr\n",
    "#             filtr = hist == err\n",
    "#             hist = hist[~filtr]\n",
    "#             bin_edges = bin_edges[~filtr]\n",
    "#             err = err[~filtr]\n",
    "#         #--- plot\n",
    "#             if shift:\n",
    "#                 hist *= 100**indx if shift else 1\n",
    "#                 err *= 100**indx if shift else 1\n",
    "\n",
    "#             utl.PltErr(bin_edges,hist,\n",
    "#                           yerr=err,\n",
    "#                    attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp), #,fmt='.'),\n",
    "#                    ax = self.ax,\n",
    "#                    Plot=False,\n",
    "#                           )\n",
    "#             kount += self.nrun\n",
    "#         #\n",
    "#         utl.PltErr(None,\n",
    "#                    None,\n",
    "#                    ax=self.ax,\n",
    "#                    Plot=False,\n",
    "                   \n",
    "# #                    legend=legends.Get(),\n",
    "#                    DrawFrame=DRAW_FRAME,\n",
    "#                    **kwargs\n",
    "#                   )\n",
    "        \n",
    "#     def PlotPdfConcat(self,scale=False,\n",
    "#                       column_energy = 0,\n",
    "#                       type_column=0,\n",
    "#                       splitByType=True,\n",
    "#                       n_per_decade = 8,\n",
    "#                       **kwargs):\n",
    "#         #\n",
    "#         self.ax = utl.PltErr(None,#ans[:,0],\n",
    "#                         None,#1e8*ans[:,0],\n",
    "#                         attrs={'fmt':'-.r'},Plot=False)\n",
    "#         symbols=utl.Symbols()\n",
    "#         legends = Legends()\n",
    "#         legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs #plotAttrs\n",
    "#                     else (1.0,0.5,0.5,0.5))\n",
    "#         #\n",
    "#         self.mean_rate = {}\n",
    "#         kount = 0\n",
    "#         #\n",
    "#         for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "#             #--- concat. data for each temp            \n",
    "# #            data = np.concatenate(list(map(lambda x: self.data[x][:,column_energy],range(indx,indx+self.nrun))))\n",
    "#             data = np.concatenate(list(map(lambda x: self.data[x],range(kount,kount+self.nrun))))\n",
    "# #             types = np.concatenate(list(map(lambda x: self.data[x][:,type_column],range(indx,indx+self.nrun))))\n",
    "#             #--- remove zeros\n",
    "# #            data = data[data > 0.0]\n",
    "#             if self.verbose:\n",
    "#                 print('data.shape (per temperature):',np.array(data).shape)\n",
    "#             if self.verbose:\n",
    "#                 print('data.shape (concatenated):',data.shape)\n",
    "#             #--- histogram\n",
    "# #            data = np.array(data).flatten()\n",
    "#             #--- histogram\n",
    "#             data_concat = data.copy() if indx ==0 else np.concatenate([data_concat,data]) #np.c_[types,data] if indx ==0 else\\\n",
    "#                         #np.concatenate([data_concat,np.c_[types,data]])\n",
    "#             kount += self.nrun\n",
    "#         if self.verbose:\n",
    "#             print('type.shape (concatenated):',data_concat.shape)\n",
    "        \n",
    "#         #--- split by type\n",
    "#         if splitByType:\n",
    "#             df=pd.DataFrame(np.c_[data_concat[:,type_column],data_concat[:,column_energy]],\n",
    "#                             columns=['type','dE'])\n",
    "#             types=df.groupby(by='type').groups\n",
    "#             for itype in types:\n",
    "#                 indices = types[itype]\n",
    "#                 elist = np.array(df['dE'].iloc[indices])\n",
    "#                 if self.verbose:\n",
    "#                     print('elist.shape:',elist.shape)\n",
    "\n",
    "#                 #--- histogram\n",
    "#                 hist, bin_edges, err = utl.GetPDF(elist,n_per_decade=n_per_decade)\n",
    "\n",
    "#                 #--- filtr\n",
    "#                 filtr = hist == err\n",
    "#                 hist = hist[~filtr]\n",
    "#                 bin_edges = bin_edges[~filtr]\n",
    "#                 err = err[~filtr]\n",
    "#                 #--- plot\n",
    "#                 if scale:\n",
    "#                     hist *= 1000**int(itype)\n",
    "#                     err *= 1000**int(itype)\n",
    "#                 utl.PltErr(bin_edges,hist,\n",
    "#                               yerr=err,\n",
    "#                        attrs=symbols.GetAttrs(count=int(itype-1)%7,label=r'$%s$'%itype), #,fmt='.'),\n",
    "#                        ax = self.ax,\n",
    "#                        Plot=False,\n",
    "#                               )\n",
    "#         else:\n",
    "#                 data = data_concat[:,column_energy]\n",
    "#                 data = data[data > 0.0]\n",
    "\n",
    "#                 #--- histogram\n",
    "#                 hist, bin_edges, err = utl.GetPDF(data,n_per_decade=n_per_decade)\n",
    "\n",
    "#                 #--- filtr\n",
    "#                 filtr = hist == err\n",
    "#                 hist = hist[~filtr]\n",
    "#                 bin_edges = bin_edges[~filtr]\n",
    "#                 err = err[~filtr]\n",
    "#                 #--- plot\n",
    "# #                 if scale:\n",
    "# #                     hist *= 100**int(itype)\n",
    "# #                     err *= 100**int(itype)\n",
    "#                 utl.PltErr(bin_edges,hist,\n",
    "#                               yerr=err,\n",
    "#                        attrs=symbols.GetAttrs(count=0), #,label=r'$%s$'%itype),#,fmt='.'),\n",
    "#                        ax = self.ax,\n",
    "#                        Plot=False,\n",
    "#                               )\n",
    "#         #\n",
    "#         utl.PltErr(None,\n",
    "#                    None,\n",
    "#                    ax=self.ax,\n",
    "#                    Plot=False,\n",
    "\n",
    "# #                        legend=legends.Get(),\n",
    "#                    DrawFrame=DRAW_FRAME,\n",
    "#                    **kwargs\n",
    "#                   )\n",
    "\n",
    "#     def Scatter(self,shift=False,nevery=1,**kwargs):\n",
    "#         kb_inv=8.61732814974056e05\n",
    "        \n",
    "#         self.ax = utl.PltErr(None,#ans[:,0],\n",
    "#                         None,#1e8*ans[:,0],\n",
    "#                         attrs={'fmt':'-.r'},Plot=False)\n",
    "#         symbols=Symbols(markersizes=np.array([10,10,10,12,12,12,10])*8)\n",
    "#         legends = Legends()\n",
    "#         legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs #plotAttrs\n",
    "#                     else (1.0,0.5,0.5,0.5))\n",
    "\n",
    "#         #\n",
    "#         column_energy = 0\n",
    "#         column_time = 3\n",
    "#         kount = 0\n",
    "#         for indx in range(0,len(self.temps),nevery):\n",
    "#             temp = self.temps[indx]\n",
    "#             #--- concat. data for each temp            \n",
    "#             data_energy = np.concatenate(list(map(lambda x: self.GetEnergy(self.data[x][:,column_energy]),\n",
    "#                                                   range(kount,kount+self.nrun))))\n",
    "#             #--- wait_times\n",
    "#             data = self.data[indx:indx+self.nrun]\n",
    "#             data_waitTimes = np.concatenate(list(map(lambda x: self.GetWaitTimes(self.data[x][:,column_time]),\n",
    "#                                                      range(kount,kount+self.nrun))))\n",
    "\n",
    "#             if self.verbose:\n",
    "#                 print('data_energy.shape (per temperature):',np.array(data_energy).shape)\n",
    "#                 print('data_waitTimes.shape (per temperature):',np.array(data_waitTimes).shape)\n",
    "#             #--- plot scatter\n",
    "#             scale = 1e2 ** indx if shift else 1\n",
    "#             filtr = data_waitTimes > 0\n",
    "# #             utl.PltErr(data_energy[filtr]*kb_inv/temp,scale*data_waitTimes[filtr],\n",
    "# #                         attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp,fmt='.',alpha=1.0),\n",
    "# #                         ax = self.ax,\n",
    "# #                         Plot=False,\n",
    "# #                         )\n",
    "#             self.ax.scatter(data_energy[filtr]*kb_inv/temp,scale*data_waitTimes[filtr],\n",
    "#                         **symbols.GetAttrsScatter(count=indx%7,label=r'$%s$'%temp,fmt='.',alpha=0.1/2),\n",
    "#                        )\n",
    "#             kount += self.nrun\n",
    "#             #--- plot average\n",
    "# #             nbins = 8\n",
    "# #             count, _=np.histogram(data_energy[filtr],bins=nbins)\n",
    "# #             xsum, _=np.histogram(data_energy[filtr],weights=data_energy[filtr],bins=nbins)\n",
    "# #             ysum, _=np.histogram(data_energy[filtr],weights=data_waitTimes[filtr],bins=nbins)\n",
    "# #             ysum /= count\n",
    "# # #            ysum =10 ** ysum \n",
    "# #             xsum /= count\n",
    "# #             #---\n",
    "# #             utl.PltErr(xsum,ysum,\n",
    "# #                         attrs=symbols.GetAttrs(count=(indx)%7,label=r'$%s$'%temp,fmt='.'),\n",
    "# #                         ax = self.ax,\n",
    "# #                         Plot=False,\n",
    "# #                         )\n",
    "        \n",
    "        \n",
    "#         utl.PltErr(None,\n",
    "#                    None,\n",
    "#                    ax=self.ax,\n",
    "#                    Plot=False,\n",
    "# #                     legend=legends.Get(),\n",
    "#                    DrawFrame=DRAW_FRAME,\n",
    "#                    **kwargs\n",
    "#                   )\n",
    "\n",
    "#     def GetEnergy(self,slist):\n",
    "#         n=len(slist)\n",
    "#         return slist[1:n:2]\n",
    "            \n",
    "# if not eval(confParser['flags']['RemoteMachine']):\n",
    "#     !mkdir png\n",
    "    \n",
    "#     stats = EnergyStats(\n",
    "#         [1000,1200,1400,1600,1800,2000],8,\n",
    "# #        [1000,1400,1800,2000],8,\n",
    "# #        [1000, 1400,1800],8,\n",
    "#         #        np.arange(1000,1440,40),1,\n",
    "# #        verbose=True\n",
    "#                      )\n",
    "# #    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "#     stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "# #    stats.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "#                          stats.temps_runs ))\n",
    "#                )\n",
    "#     stats.PlotPdf(shift=True,n_per_decade=10,\n",
    "#                         **{'xscale':'log',\n",
    "#                   'yscale':'log',\n",
    "# #                   'xlim':(1e-3,1e0),\n",
    "# #                   'ylim':(1e-2,1e2), #(1e-5,1e2),\n",
    "# #                           'xstr':r'$\\Delta t$',\n",
    "# #                           'ystr':r'$P(\\Delta t)$',\n",
    "#                         'ndecade_y':2,\n",
    "#                    'title':'png/BarrierPdf_cantor.png'},\n",
    "\n",
    "#                        )\n",
    "    \n",
    "# #     stats.PlotPdfConcat(scale=False,\n",
    "# #                         splitByType = False,\n",
    "# #                         **{'xscale':'log',\n",
    "# #                       'yscale':'log',\n",
    "# #     #                   'xlim':(1e-3,1e0),\n",
    "# # #                        'ylim':(1e-2,1e2), #(1e-5,1e2),\n",
    "# #     #                           'xstr':r'$\\Delta t$',\n",
    "# #     #                           'ystr':r'$P(\\Delta t)$',\n",
    "# #     #                        'ndecade_x':2,'ndecade_y':2,\n",
    "# #     #                   'title':'png/BarrierPdf_cantor.png'\n",
    "# #                           },\n",
    "# #                        )\n",
    "\n",
    "#     stats.Scatter(nevery=2, shift = True,                        \n",
    "#                 **{'xscale':'linear',\n",
    "#                   'yscale':'log',\n",
    "# #                   'xlim':(1e-3,1),\n",
    "# #                   'ylim':(1e-3,1e1), #(1e-5,1e2),\n",
    "# #                           'xstr':r'$\\Delta t$',\n",
    "# #                           'ystr':r'$P(\\Delta t)$',\n",
    "# #                     'bbox_to_anchor':(0.56,0.27,0.5,0.5),\n",
    "#                         'ndecade_y':2,\n",
    "#                    'title':'png/twVsEnergy_nicocr.png',\n",
    "#                   }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    \n",
    "    stats = EnergyStats(\n",
    "#        [1000,1200,1400,1600,1800,2000],[list(range(8))]*10,\n",
    "        [1000],[list(range(8))]*10,\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "    stats.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "                         stats.temps_runs ))\n",
    "               )\n",
    "    stats.PlotPdf(shift=False,column_energy=3,\n",
    "                  linscale=True, n_per_decade = 32,\n",
    "                        **{'xscale':'linear',\n",
    "                  'yscale':'log',\n",
    "                   'xlim':(0,4.8),\n",
    "                    'ylim':(1e-4,1e1), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "#                         'ndecade_x':1,'ndecade_y':2,\n",
    "                    'bbox_to_anchor':(0.4,0.13,0.5,0.5),\n",
    "                   'title':'png/BarrierPdf_nicocr.png'},\n",
    "\n",
    "                       )\n",
    "\n",
    "#     stats.PlotPdfConcat(scale=True, \n",
    "#                         column_energy=3,\n",
    "#                         splitByType = False,\n",
    "#                         n_per_decade=10,\n",
    "#                         **{'xscale':'log',\n",
    "#                   'yscale':'log',\n",
    "# #                   'xlim':(1e-3,1e-1),\n",
    "# #                   'ylim':(1e-2,1e0), #(1e-5,1e2),\n",
    "# #                           'xstr':r'$\\Delta t$',\n",
    "# #                           'ystr':r'$P(\\Delta t)$',\n",
    "# #                        'ndecade_x':2,'ndecade_y':2,\n",
    "# #                   'title':'png/BarrierPdf_cantor.png'\n",
    "#                           },\n",
    "\n",
    "#                        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    \n",
    "    stats = EnergyStats(\n",
    "        [2000],8,\n",
    "#        [2000],8,\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "                         stats.temps_runs ))\n",
    "               )\n",
    "    print(stats.data[0][:,3].mean())\n",
    "    stats.PlotPdf(shift=True,column_energy=3,\n",
    "                        **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "#                   'xlim':(1e-3,1e-1),\n",
    "#                    'ylim':(1e-2,1e0), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "                        'ndecade_x':1,'ndecade_y':2,\n",
    "                    'bbox_to_anchor':(0.4,0.13,0.5,0.5),\n",
    "                   'title':'png/BarrierPdf_nicocr.png'},\n",
    "\n",
    "                       )\n",
    "\n",
    "#     stats.PlotPdfConcat(scale=True, \n",
    "#                         column_energy=3,\n",
    "#                         splitByType = False,\n",
    "#                         n_per_decade=10,\n",
    "#                         **{'xscale':'log',\n",
    "#                   'yscale':'log',\n",
    "# #                   'xlim':(1e-3,1e-1),\n",
    "# #                   'ylim':(1e-2,1e0), #(1e-5,1e2),\n",
    "# #                           'xstr':r'$\\Delta t$',\n",
    "# #                           'ystr':r'$P(\\Delta t)$',\n",
    "# #                        'ndecade_x':2,'ndecade_y':2,\n",
    "# #                   'title':'png/BarrierPdf_cantor.png'\n",
    "#                           },\n",
    "\n",
    "#                        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kb=8.61732814974056e-05\n",
    "\n",
    "# 0.9/1650/kb,1.0/2100/kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    #alpha=-0.4\n",
    "\n",
    "    Emin=1e-2\n",
    "    Emax=1e1\n",
    "    n=100000\n",
    "    for alpha in [-1]:\n",
    "        xmax=1/Emin**alpha\n",
    "        xmin=1/Emax**alpha\n",
    "        x=np.random.uniform(low=xmin,high=xmax,size=n)\n",
    "        #E=np.exp(-E)\n",
    "        E=x**-(1/alpha)\n",
    "        hist, edge,err = utl.GetPDF(E,n_per_decade=4)\n",
    "        ax=utl.PltErr(edge,hist,yerr=err,\n",
    "                   yscale='log',xscale='log',Plot=False,\n",
    "                  )\n",
    "\n",
    "        utl.PltErr(edge,1/edge**(1+alpha),yerr=err,attrs={'fmt':'-.r'},\n",
    "                   yscale='log',xscale='log',\n",
    "                   ax=ax\n",
    "                  )\n",
    "\n",
    "        #\n",
    "        lambdaa=np.exp(-E)\n",
    "        lambdaa = lambdaa[lambdaa>0]\n",
    "        hist, edge,err = utl.GetPDF(lambdaa,n_per_decade=32)\n",
    "        utl.PltErr(edge,hist,yerr=err,\n",
    "                   yscale='log',xscale='log',\n",
    "                   xlim=(1e-10,1),\n",
    "                  )\n",
    "\n",
    "        sarr = np.c_[list(map(lambda x:np.random.exponential(1/x,size=1),lambdaa))].flatten()\n",
    "        hist, edge,err = utl.GetPDF(sarr,n_per_decade=4)\n",
    "        ax=utl.PltErr(edge,hist*edge**0,yerr=err*edge**0,\n",
    "                   yscale='log',xscale='log',\n",
    "                      Plot=False\n",
    "                  )\n",
    "        utl.PltErr(edge,1/edge**(1.5+alpha),attrs={'fmt':'-.r'},\n",
    "                   yscale='log',xscale='log',\n",
    "                   ax=ax\n",
    "                  )\n",
    "        beta=fit(edge,hist,err)\n",
    "        print(beta)\n",
    "        plt.scatter(alpha,beta)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x,beta,k,x0,x1):\n",
    "#    return k/(1+(x/x0)**beta)\n",
    "    return k*np.exp(-x/x1)/(1+(x/x0)**beta)\n",
    "    \n",
    "def fit(edge,hist,err):\n",
    "    xdata=edge\n",
    "    ydata=hist\n",
    "    yerr=err\n",
    "    popt, pcov = curve_fit(func,xdata,ydata,\n",
    "                          p0=(2,1,10,1e3),\n",
    "                           sigma=yerr,\n",
    "                          )\n",
    "\n",
    "    ax=utl.PltErr(edge,hist,yerr=err,\n",
    "               yscale='log',xscale='log',\n",
    "                  Plot=False\n",
    "              )\n",
    "    utl.PltErr(edge,func(edge,*popt),attrs={'fmt':'-.r'},\n",
    "               yscale='log',xscale='log',\n",
    "               ax=ax,\n",
    "               ndecade_x=4,\n",
    "              )\n",
    "    assert popt[-1]>0\n",
    "    return popt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kbt=1000*8.61732814974056e-05\n",
    "# E=5e-2\n",
    "# print('%e'%(1.0/(1e-13*np.exp(E/kbt))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    \n",
    "    stats = EnergyStats(\n",
    "#         [1000,1200,1400,1600,1800,2000],[list(range(8))]*10,\n",
    "        [0],[list(range(8))]\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "    stats.Parse( list(map(lambda x:'barrier/ni/kmc/void_2d/Run%s/msd/eventID_barrier_catalog_type1.txt'%(x[1]),\n",
    "                         stats.temps_runs ))\n",
    "               )\n",
    "\n",
    "    stats.PlotPdf( \n",
    "                        column_energy=2,\n",
    "                        splitByType = False,\n",
    "                        n_per_decade = 16,\n",
    "                        **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "                   'xlim':(1e-1,1e1),\n",
    "#                   'ylim':(1e-3,1e2), #(1e-5,1e2),\n",
    "                           'xstr':r'$\\Delta E$',\n",
    "                           'ystr':r'$P(\\Delta E)$',\n",
    "#                        'ndecade_x':2,'ndecade_y':2,\n",
    "                   'title':'png/BarrierPdf_cantor.png'\n",
    "                          },\n",
    "\n",
    "                       )\n",
    "\n",
    "    \n",
    "\n",
    "#     stats.Scatter(nevery=2,                        \n",
    "#                 **{'xscale':'linear',\n",
    "#                   'yscale':'log',\n",
    "#                    'xlim':(0,1),\n",
    "# #                   'ylim':(1e-3,1e1), #(1e-5,1e2),\n",
    "# #                           'xstr':r'$\\Delta t$',\n",
    "# #                           'ystr':r'$P(\\Delta t)$',\n",
    "#                         'ndecade_y':2,\n",
    "#                    'title':'png/twVsEnergy_cantor.png',\n",
    "#                   }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    pref = 1e6\n",
    "    \n",
    "    temp = Temperature(\n",
    "        [1000],[[7]],\n",
    "#        verbose=True\n",
    "                     )\n",
    "    #--- parse data\n",
    "#    temp.Parse(['./msd/msd.txt'])\n",
    "    temp.Parse( list(map(lambda x:'sro/cantor/kmc/cantorNatom1KTemp%sK/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "                        temp.temps_runs ))\n",
    "              )\n",
    "\n",
    "#     temp.EnsAverage(n_bins_per_decade=100000,\n",
    "#                     col_x = 3, col_y = 1,\n",
    "#                     n_thresh=0,\n",
    "#                    )\n",
    "    \n",
    "    symbols = Symbols()\n",
    "    legend=Legends()\n",
    "    legend.Set(bbox_to_anchor=(0.92,0.48,0.5,0.5),labelspacing=.4)\n",
    "\n",
    "    count = 0\n",
    "#     ax = utl.PltErr(None,None,Plot=False)\n",
    "    for irun in temp.nrun[0]:\n",
    "        xdata=temp.data[count][::2,3]\n",
    "        ydata=temp.data[count][::2,1]\n",
    "\n",
    "#         utl.PltErr(xdata, ydata,\n",
    "#                   attrs={'fmt':'-'},\n",
    "#                    ax=ax,\n",
    "#                    Plot=False,\n",
    "#     #                xscale='log' ,\n",
    "# #                      ylim=(-6000,-5900),\n",
    "#                   )\n",
    "        count += 1\n",
    "        \n",
    "    \n",
    "#     timesteps = temp.data_averaged[1000][:,0]\n",
    "#     wc = temp.data_averaged[1000][:,1]\n",
    "#     yerr = temp.data_averaged[1000][:,2]\n",
    "\n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "    utl.PltErr(pref*xdata,ydata,#yerr=yerr,\n",
    "                 ylim=[(-5538,-5530),(-6000,-5920)][0],\n",
    "#                xlim=(0,0.1),\n",
    "                Plot=False,\n",
    "                ax=ax,\n",
    "                attrs={'fmt':'-','color':'C0'},#symbols.GetAttrs(count=0,nevery=8),\n",
    "               title='png/energy_timeseries_cantor.png',\n",
    "                 DrawFrame=DRAW_FRAME,\n",
    "               fontsize=16,\n",
    "             )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SroAnalysis:\n",
    "    \n",
    "    def __init__(self, lmpData, nevery=1, verbose = False ):\n",
    "        !mkdir sroAnalysis\n",
    "        self.lmpData = lmpData\n",
    "        self.verbose = verbose\n",
    "        self.timesteps = list(lmpData.coord_atoms_broken.keys())[::nevery]\n",
    "        self.timesteps.sort()\n",
    "        self.times = list(lmpData.headers['Time'])[::nevery]\n",
    "        self.times.sort()\n",
    "\n",
    "\n",
    "    \n",
    "    def GetNeighList(self):\n",
    "        itime0 = self.timesteps[0]\n",
    "        natoms = min(self.lmpData.coord_atoms_broken[itime0].shape[0],\\\n",
    "                     eval(confParser['SroAnalysis']['natom'])) #--- subset of atoms\n",
    "        atom_indices = range(natoms)\n",
    "        np.savetxt('atom_indices.txt',atom_indices,fmt='%d')\n",
    "        #\n",
    "        cutoff = eval(confParser['SroAnalysis']['cutoff'])\n",
    "        !rm sroAnalysis/neighList.xyz\n",
    "#         path = confParser['input files']['path']\n",
    "#         indx = confParser['input files']['fileIndex']\n",
    "        py_path=confParser['input files']['lib_path']\n",
    "        fileName = 'dumpFile/dump.xyz'\n",
    "        nevery = int(confParser['SroAnalysis']['nevery'])\n",
    "        if self.verbose:\n",
    "            print('get neighbor list ...')     \n",
    "        t0=time.time()\n",
    "        !ovitos $py_path/OvitosCna.py $fileName neighList.xyz $nevery 4 $cutoff atom_indices.txt\n",
    "        if self.verbose:\n",
    "            print('output neighbor list=%s s'%(time.time()-t0))     \n",
    "            \n",
    "        t0=time.time()\n",
    "        self.lmpNeigh = lp.ReadDumpFile( 'neighList.xyz' )\n",
    "        self.lmpNeigh.GetCords( ncount = sys.maxsize)\n",
    "        \n",
    "        #--- update timesteps\n",
    "        self.timesteps = list(self.lmpNeigh.coord_atoms_broken.keys())\n",
    "        self.timesteps.sort()\n",
    "        \n",
    "        #--- clean\n",
    "        !rm neighList.xyz atom_indices.txt\n",
    "\n",
    "        if self.verbose:\n",
    "            print('load neighbor list=%s s'%(time.time()-t0))\n",
    "            print('times=',self.timesteps)\n",
    "            display(self.lmpNeigh.coord_atoms_broken[self.timesteps[0]].head())\n",
    "            \n",
    "\n",
    "        \n",
    "    def WarrenCowleyOrderParameter(self, itime, **kwargs):        \n",
    "        box = lp.Box( BoxBounds = self.lmpData.BoxBounds[itime], AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "        atoms = lp.Atoms( **self.lmpData.coord_atoms_broken[itime].to_dict(orient='series') )\n",
    "        #--- neighbor list\n",
    "        neigh = self.lmpNeigh.coord_atoms_broken[itime]\n",
    "        \n",
    "        #--- radial dist. function\n",
    "        cutoff = eval(confParser['SroAnalysis']['cutoff'])\n",
    "        rdf = lp.ComputeRdf(  atoms, box )\n",
    "        bins = self.GetValleys(itime) if 'bins' not in kwargs else kwargs['bins']\n",
    "        rdf.PairCrltn(  \n",
    "                  bins=bins, \n",
    "                  rlist=neigh.DIST )\n",
    "        \n",
    "        types = list(set(self.lmpData.coord_atoms_broken[0].type))\n",
    "        sro = {}\n",
    "        count = 0\n",
    "        for pairi in types:\n",
    "            for pairj in types:\n",
    "                if pairi > pairj:\n",
    "                    continue\n",
    "                sro[count] = rdf.Sro(neigh,pairi,pairj,bins=bins)\n",
    "                count += 1\n",
    "        return sro\n",
    "\n",
    "    def MultiTimes(self,**kwargs):\n",
    "        bins = kwargs['bins'] if 'bins' in kwargs else self.GetValleys(self.timesteps[0])\n",
    "        self.data =list(map(lambda x:self.WarrenCowleyOrderParameter(x,bins=bins),self.timesteps))\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def quadratic_spline_roots(spl):\n",
    "        roots = []\n",
    "        knots = spl.get_knots()\n",
    "        for a, b in zip(knots[:-1], knots[1:]):\n",
    "            u, v, w = spl(a), spl((a+b)/2), spl(b)\n",
    "            t = np.roots([u+w-2*v, w-u, 2*v])\n",
    "            t = t[np.isreal(t) & (np.abs(t) <= 1)]\n",
    "            roots.extend(t*(b-a)/2 + (b+a)/2)\n",
    "        return np.array(roots)\n",
    "\n",
    "    @staticmethod\n",
    "    def GetExtrema(bin_edges1,hist1,r0,verbose=True):\n",
    "        y_axis=hist1\n",
    "        x_axis=bin_edges1\n",
    "        f = InterpolatedUnivariateSpline(x_axis, y_axis, k=4)\n",
    "\n",
    "        ext=f.derivative().roots() #--- roots\n",
    "        spl_dd=f.derivative().derivative()\n",
    "        valleys=ext[np.all([spl_dd(ext)>0,ext>r0],axis=0)]\n",
    "        peaks=ext[np.all([spl_dd(ext)<0,ext>r0],axis=0)]\n",
    "\n",
    "        if len(valleys) == 0:\n",
    "            cutoff = eval(confParser['SroAnalysis']['cutoff'])\n",
    "            valleys = [cutoff]\n",
    "\n",
    "        rpeak   = peaks[0]\n",
    "        rvalley = valleys[0]\n",
    "        if rvalley > rpeak:\n",
    "            valleys = np.concatenate([np.array([0]),valleys])\n",
    "#         if verbose:\n",
    "#             print('peaks of g(r) at:r=',peaks)\n",
    "#             print('valleys of g(r) at:r=',valleys)\n",
    "\n",
    "        return x_axis, f, valleys\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def GetValleys(self,itime):\n",
    "        bin_edges, hist,_  = self.PairCrltnFunction(itime)\n",
    "        self.bin_edges, self.hist,_  = self.PairCrltnFunction(itime)\n",
    "        x_axis, f, valleys = SroAnalysis.GetExtrema(bin_edges,hist,1.0)\n",
    "        #--- remove valleys that are too close!\n",
    "        filtr = np.diff(valleys,prepend=valleys[-1]) >0.25\n",
    "        valleys = np.append(0,valleys[filtr])\n",
    "        return valleys\n",
    "        \n",
    "    def PairCrltnFunction(self,itime):\n",
    "        box = lp.Box( BoxBounds = self.lmpData.BoxBounds[itime], AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "        atoms = lp.Atoms( **self.lmpData.coord_atoms_broken[itime].to_dict(orient='series') )\n",
    "        neigh = self.lmpNeigh.coord_atoms_broken[itime]\n",
    "\n",
    "\n",
    "        cutoff = eval(confParser['SroAnalysis']['cutoff'])\n",
    "        rdf = lp.ComputeRdf(  atoms, box )\n",
    "        rdf.PairCrltn(  \n",
    "                      bins=np.arange(0.99*neigh.DIST.min(),cutoff,0.01), \n",
    "                      rlist=neigh.DIST,\n",
    "                      regular_r = True,\n",
    "                      )\n",
    "        return rdf.Get()\n",
    "\n",
    "    @staticmethod\n",
    "    def Reshape(sdict):\n",
    "        keys = list(sdict.keys())\n",
    "        keys.sort()\n",
    "        concat = list(map(lambda x:list(np.concatenate([sdict[x][0],sdict[x][1],sdict[x][2]])),keys))\n",
    "        size = (3,len(sdict[keys[0]][0]))\n",
    "        return dict(zip(keys,concat)), size\n",
    "    \n",
    "                \n",
    "    def Print( self, fp ):\n",
    "        rwj = utl.ReadWriteJson()\n",
    "        rwj.Write(self.data, fp,\n",
    "                  timestep=self.timesteps,\n",
    "                  time=self.times\n",
    "                 # junk=sro.timesteps\n",
    "                 )\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['SroAnalysis']['SroAnalysis']):\n",
    "    sro = SroAnalysis( data.lmpData,\n",
    "                       nevery=eval(confParser['SroAnalysis']['nevery']),\n",
    "                        verbose = True,\n",
    "                     )\n",
    "    sro.GetNeighList()\n",
    "#    sro.WarrenCowleyOrderParameter(sro.timesteps[0])\n",
    "    sro.MultiTimes(\n",
    "                    bins=np.array(confParser['SroAnalysis']['sroBins'].split()).astype(float)\n",
    "                  )\n",
    "    sro.Print('sroAnalysis/sro.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not eval(confParser['flags']['RemoteMachine']):\n",
    "\n",
    "#     path = {0:'sro/CantorNatom16KTemp1000KEnsemble8',\n",
    "#             1:'sro/NiCoCrNatom1KTemp1000K',\n",
    "#            }[1]\n",
    "#     rwj = utl.ReadWriteJson()\n",
    "#     data = rwj.Read('%s/Run0/sroAnalysis/sro.json'%path)\n",
    "#     #\n",
    "#     pairIndx = '0'\n",
    "#     rss = 0.20\n",
    "#     #\n",
    "#     symbols = Symbols()\n",
    "# #    ax = utl.PltErr(None,None,Plot=False)\n",
    "#     for items in data:\n",
    "#         timestep = items['timestep']\n",
    "#         bin_edges, wc, err = items[pairIndx]\n",
    "\n",
    "    \n",
    "#     for pairIndx in range(6):\n",
    "#         ax = utl.PltErr(None,None,Plot=False)\n",
    "\n",
    "#         bin_edges, wc, err = items[str(pairIndx)]\n",
    "#         utl.PltErr(bin_edges,wc,yerr=2*np.array(err),\n",
    "#                     Plot=False,\n",
    "#                     ax=ax,\n",
    "#                     attrs=symbols.GetAttrs(count=0,zorder=2),      \n",
    "#                   )\n",
    "\n",
    "\n",
    "#         cutoff = 20.0 #eval(confParser['SroAnalysis']['cutoff'])\n",
    "#         utl.PltErr([0,cutoff],[rss,rss],\n",
    "#                     xlim=[0.0,cutoff],\n",
    "#     #                ylim=[0.1,.7],\n",
    "#                     ax=ax,\n",
    "#                     attrs={'fmt':'-.r'},\n",
    "#                     title='png/wc_nicocr_indx%s.png'%(pairIndx),\n",
    "#                     DrawFrame=DRAW_FRAME,\n",
    "#                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "\n",
    "    path = {0:'sro/CantorNatom16KTemp1000KEnsemble8',\n",
    "            1:'sro/NiCoCrNatom1KTemp1000K',\n",
    "            2:'sro/nicocr/kmc/NiCoCrNatom1KTemp1000K',\n",
    "            3:'.'\n",
    "           }[2]\n",
    "    alloy = 'nicocr'\n",
    "    runs = range(8) #[7] #range(8)\n",
    "    rss = 0.33 #0.2 #0.33\n",
    "    every_nrow = 1 #--- don't change\n",
    "    inn = 2 #--- 1st nearest neighbor\n",
    "    nneighbors = 3 #--- len(sroBins)-1\n",
    "    \n",
    "    indices = {'nicocr':'0 1 2 3 4 5'.split(),\n",
    "               'cantor':' '.join(list(map(str,range(15)))).split()}[alloy]\n",
    "    pairs = {'nicocr':'NiNi NiCo NiCr CoCo CoCr CrCr'.split(),\n",
    "              'cantor':' '.join(list(map(str,range(15)))).split()\n",
    "            }[alloy]\n",
    "    \n",
    "    rwj = utl.ReadWriteJson()\n",
    "    for irun in runs:\n",
    "        data = rwj.Read('%s/Run%s/sroAnalysis/sro.json'%(path,irun))\n",
    "        #\n",
    "        #--- parse\n",
    "        symbols = Symbols()\n",
    "        legend=Legends()\n",
    "        legend.Set(bbox_to_anchor=(0.92,0.48,0.5,0.5),labelspacing=.4)\n",
    "        ax = utl.PltErr(None,None,Plot=False)\n",
    "        for pairIndx, label in zip(indices,pairs):\n",
    "            sro_data = np.concatenate([list(map(lambda x:\n",
    "                                 np.concatenate([np.array([x['time']]),np.array(x[pairIndx]).flatten()]),\n",
    "                                 data))])\n",
    "            timesteps = sro_data[::every_nrow,0]\n",
    "            r = sro_data[::every_nrow,1:1+nneighbors]\n",
    "            wc = sro_data[::every_nrow,1+nneighbors:1+2*nneighbors]/rss-1.0\n",
    "            err = sro_data[::every_nrow,1+2*nneighbors:1+3*nneighbors]\n",
    "\n",
    "\n",
    "            #--- output\n",
    "            np.savetxt('sro/sro_irun%s_indx%s_nn%s.txt'%(irun,pairIndx,inn),np.c_[timesteps,wc[:,inn],err[:,inn]])\n",
    "\n",
    "            utl.PltErr(timesteps,-wc[:,inn],yerr=err[:,inn],\n",
    "                        Plot=False,\n",
    "                        ax=ax,\n",
    "                        attrs=symbols.GetAttrs(count=int(pairIndx)%7,zorder=2,nevery=1280,label=r'$\\mathrm{%s}$'%label),      \n",
    "                      )\n",
    "\n",
    "\n",
    "        utl.PltErr([0,timesteps[-1]],[0,0],\n",
    "                    ax=ax,\n",
    "                    attrs={'fmt':'-.r'},\n",
    "                    legend=legend.Get(),\n",
    "#                     title='png/wc_time_nicocr_nn%s.png'%inn,\n",
    "                    DrawFrame=DRAW_FRAME,\n",
    "                   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    pref = 1e6\n",
    "    indices = {'nicocr':'0 1 2 3 4 5'.split(),\n",
    "               'cantor':'0 5 9 12 14'.split()}[alloy]\n",
    "    pairs = {'nicocr':'NiNi NiCo NiCr CoCo CoCr CrCr'.split(),\n",
    "              'cantor':'NiNi CoCo CrCr FeFe MnMn '.split()\n",
    "            }[alloy]\n",
    "\n",
    "    \n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "    legend=Legends()\n",
    "    legend.Set(bbox_to_anchor=(-0.02,0.52,0.5,0.5),\n",
    "                 labelspacing=.2,\n",
    "                    fontsize=12,\n",
    "              )\n",
    "    count = 0\n",
    "    for sro_indx, label in zip(indices,pairs):\n",
    "        temp_vac = Temperature(\n",
    "                [int(sro_indx)],[runs],\n",
    "        #         verbose = True,\n",
    "                         )\n",
    "        #--- parse data\n",
    "        temp_vac.Parse( list(map(lambda x:'sro/sro_irun%s_indx%s_nn%s.txt'%(x[1],x[0],inn),\n",
    "                              temp_vac.temps_runs ))\n",
    "                  )\n",
    "\n",
    "        temp_vac.EnsAverage(n_bins_per_decade=32)\n",
    "\n",
    "\n",
    "        timesteps = temp_vac.data_averaged[int(sro_indx)][:,0]\n",
    "        wc = temp_vac.data_averaged[int(sro_indx)][:,1]\n",
    "        yerr = temp_vac.data_averaged[int(sro_indx)][:,2]\n",
    "\n",
    "        utl.PltErr(pref*timesteps,-wc,#yerr=yerr,\n",
    "                    Plot=False,\n",
    "                    ax=ax,\n",
    "                    attrs=symbols.GetAttrs(count=count%7,zorder=2,nevery=4,label=r'$\\mathrm{%s}$'%label),      \n",
    "                  )\n",
    "        count += 1\n",
    "\n",
    "    utl.PltErr([0,pref*timesteps[-1]],[0,0],\n",
    "#                        xlim=[0.0,0.1],\n",
    "                    ylim=[-0.3,0.3],\n",
    "                ax=ax,\n",
    "                attrs={'fmt':'-.r','color':'C0'},\n",
    "                  legend=legend.Get(),\n",
    "                title='png/wc_time_cantor_inn%s.png'%inn,\n",
    "                DrawFrame=DRAW_FRAME,\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnnEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "259.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
