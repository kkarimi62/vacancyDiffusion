{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parsing configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "confParser = configparser.ConfigParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf. file sections: ['parameters', 'flags', 'MsdAnalysis', 'EnergyBarrier', 'SroAnalysis', 'input files', 'Atomic Radius']\n"
     ]
    }
   ],
   "source": [
    "#--- parse conf. file\n",
    "confParser.read('configuration.ini')\n",
    "print('conf. file sections:',confParser.sections())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'LammpsPostProcess' from '../../HeaDef/postprocess/LammpsPostProcess.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(confParser['input files']['lib_path'])\n",
    "\n",
    "#--- system libraries\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "import traceback\n",
    "import os\n",
    "import scipy.interpolate as scp_int\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "import warnings\n",
    "import matplotlib\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "from matplotlib import patches\n",
    "import sys\n",
    "import sklearn\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "import patsy\n",
    "from sklearn import linear_model, mixture\n",
    "import sklearn.mixture as skm\n",
    "from scipy import optimize\n",
    "import scipy\n",
    "import re\n",
    "from functools import reduce\n",
    "import time\n",
    "import fnmatch\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "#\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#--- user modules\n",
    "import LammpsPostProcess as lp\n",
    "#import LammpsPostProcess2nd as lpp\n",
    "#import utilityy as utll\n",
    "import utility as utl\n",
    "#from utility import *\n",
    "import imp\n",
    "#imp.reload(lpp)\n",
    "imp.reload(utl)\n",
    "imp.reload(lp)\n",
    "#imp.reload(utll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Symbols:\n",
    "    def __init__(self,\n",
    "                markersizes=[10,10,10,12,12,12,10],\n",
    "                ):\n",
    "        self.colors = ['black','red','green','blue','cyan','brown','grey','magenta','orange','yellow']\n",
    "        self.fillstyles=['white',None,'white',None,'white',None,'white',None,'white',None,'white',None,'white',None,'white',None]\n",
    "        self.markers=['o','s','D','^','<','>','v']\n",
    "        self.markersizes=markersizes\n",
    "        self.nmax=7\n",
    "        \n",
    "    def GetAttrs(self,count=0,label='',nevery=1,fmt='.-',zorder=1,alpha=1):\n",
    "        if count > self.nmax:\n",
    "            print('index out of list bound!')\n",
    "            return \n",
    "        attrs={ 'color':self.colors[count],\n",
    "            'markersize':self.markersizes[count],\n",
    "            'marker':self.markers[count],\n",
    "            'markerfacecolor':self.colors[count],\n",
    "            'markeredgecolor':'white', #'black' if not self.fillstyles[count] else None,\n",
    "            'label':label,\n",
    "           'markevery':nevery,\n",
    "           'errorevery':nevery,\n",
    "           'markeredgewidth':1.75,\n",
    "            'linewidth':1, \n",
    "           'barsabove':None,\n",
    "           'capsize':5,\n",
    "           'capthick':1,\n",
    "           'elinewidth':1,\n",
    "           'fmt':fmt,\n",
    "             'zorder':zorder,\n",
    "               'alpha':alpha\n",
    "         }\n",
    "        return attrs\n",
    "    \n",
    "    def GetAttrs2nd(self,count=0,label='',nevery=1,fmt='.-',zorder=1):\n",
    "        '''\n",
    "        empty symbols\n",
    "        '''\n",
    "        if count > self.nmax:\n",
    "            print('index out of list bound!')\n",
    "            return \n",
    "        attrs={ 'color':self.colors[count],\n",
    "            'markersize':self.markersizes[count],\n",
    "            'marker':self.markers[count],\n",
    "            'markerfacecolor':'white',\n",
    "#            'markeredgecolor':'black' if not self.fillstyles[count] else None,\n",
    "            'label':label,\n",
    "           'markevery':nevery,\n",
    "           'errorevery':nevery,\n",
    "           'markeredgewidth':1.75,\n",
    "            'linewidth':1, \n",
    "           'barsabove':None,\n",
    "           'capsize':5,\n",
    "           'capthick':1,\n",
    "           'elinewidth':1,\n",
    "           'fmt':fmt,\n",
    "            'zorder':zorder,\n",
    "          }\n",
    "        return attrs\n",
    "\n",
    "    def GetAttrsScatter(self,count=0,label='',nevery=1,fmt='.-',zorder=1,alpha=0.5):\n",
    "        if count > self.nmax:\n",
    "            print('index out of list bound!')\n",
    "            return \n",
    "        attrs={ 'color':self.colors[count],\n",
    "            's':self.markersizes[count],\n",
    "            'marker':self.markers[count],\n",
    "#            'markerfacecolor':self.colors[count],\n",
    "            'edgecolors':'white', #'black' if not self.fillstyles[count] else None,\n",
    "            'label':label,\n",
    "#            'markevery':nevery,\n",
    "#           'errorevery':nevery,\n",
    "#            'markeredgewidth':1.75,\n",
    "            'linewidth':1, \n",
    "#            'barsabove':None,\n",
    "#            'capsize':5,\n",
    "#            'capthick':1,\n",
    "#            'elinewidth':1,\n",
    "#            'fmt':fmt,\n",
    "             'zorder':zorder,\n",
    "               'alpha':alpha\n",
    "         }\n",
    "        return attrs\n",
    "    \n",
    "    \n",
    "class Legends:\n",
    "    def __init__(self\n",
    "                ):\n",
    "        pass\n",
    "    def Set(self,fontsize=20,\n",
    "                 labelspacing=0,\n",
    "                 **kwargs\n",
    "#                 bbox_to_anchor=(0.5,0.48,0.5,0.5),\n",
    "           ):\n",
    "        self.attrs = {'frameon':False,'fontsize':fontsize,\n",
    "                   'labelspacing':labelspacing,\n",
    "                      'handletextpad':.2,\n",
    "                   'handlelength':1,\n",
    "                    **kwargs,\n",
    "                     }\n",
    "    def Get(self):\n",
    "        return self.attrs\n",
    "\n",
    "DRAW_FRAME=(0.23,0.08,0.12,0.07,0.01)\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    matplotlib.rcParams['text.usetex'] = True #--- comment tex stuff!\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Dump File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class ParseConfiguration:\n",
    "    '''\n",
    "    Parse k-art configuration file\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,confParser,verbose=False):\n",
    "\n",
    "        #--- fetch parameters defect_file\n",
    "        self.datFile = '%s/%s'%(confParser['input files']['input_path'],confParser['input files']['diffusion_file'])\n",
    "        self.lib_path = confParser['input files']['lib_path']\n",
    "        \n",
    "        self.verbose = verbose\n",
    "\n",
    "    def Parse(self,fp,outpt):\n",
    "        #--- parse dump: call ovito\n",
    "        t0=time.time()\n",
    "        outpt_headers = 'dumpFile/calcResults.txt'\n",
    "        !ovitos $self.lib_path/OvitosCna.py $fp $outpt 1 7 $outpt_headers\n",
    "        if self.verbose:\n",
    "            print('output dump file=%s s'%(time.time()-t0))\n",
    "\n",
    "        #--- parse dump files\n",
    "        if self.verbose:\n",
    "            print('parsing %s'%(outpt))\n",
    "        t0=time.time()\n",
    "        self.lmpData = lp.ReadDumpFile( '%s'%(outpt) ) \n",
    "        self.lmpData.GetCords( ncount = sys.maxsize)\n",
    "        if self.verbose:\n",
    "            print('elapsed time=%s s'%(time.time()-t0))\n",
    "            print('time steps:',self.lmpData.coord_atoms_broken.keys())\n",
    "            display(self.lmpData.coord_atoms_broken[0].head())\n",
    "\n",
    "        #--- add timescales\n",
    "        self.lmpData.times = np.loadtxt(self.datFile)[:,0]\n",
    "\n",
    "        #--- parse headers\n",
    "        data = np.loadtxt(outpt_headers)\n",
    "        if data.shape[1] == 4:\n",
    "            self.lmpData.headers = pd.DataFrame(data,columns=[\"Barrier\", \"Energy\", \"Step\", \"Time\"])\n",
    "        elif data.shape[1] == 2:\n",
    "            self.lmpData.headers = pd.DataFrame(data,columns=[\"Step\", \"Time\"])\n",
    "\n",
    "\n",
    "    def WignerSeitz(self,fp,reference_file):\n",
    "        '''\n",
    "        perform Wigner-Seitz algorithm\n",
    "        '''\n",
    "        outpt = 'dumpFile/dump_defect.xyz'\n",
    "\n",
    "        #--- parse dump: call ovito\n",
    "        if self.verbose:\n",
    "            print('input=',fp)\n",
    "        t0=time.time()\n",
    "        !ovitos $self.lib_path/OvitosCna.py $fp $outpt 1 11 $reference_file\n",
    "        if self.verbose:\n",
    "            print('output dump file=%s s'%(time.time()-t0))\n",
    "\n",
    "        #--- parse dump files\n",
    "        if self.verbose:\n",
    "            print('parsing %s'%(outpt))\n",
    "        t0=time.time()\n",
    "        self.lmpData_defect = lp.ReadDumpFile( '%s'%(outpt) ) \n",
    "        self.lmpData_defect.GetCords( ncount = sys.maxsize)\n",
    "        if self.verbose:\n",
    "            print('elapsed time=%s s'%(time.time()-t0))\n",
    "\n",
    "        if self.verbose:\n",
    "            print('time steps:',self.lmpData_defect.coord_atoms_broken.keys())\n",
    "            display(self.lmpData_defect.coord_atoms_broken[0].head())\n",
    "\n",
    "        #--- add timescales\n",
    "        self.lmpData_defect.times = np.loadtxt(self.datFile)[:,0]\n",
    "\n",
    "\n",
    "    def Print(self,fout):\n",
    "        '''\n",
    "        dump vacant sites\n",
    "        '''\n",
    "        \n",
    "        times = list( self.lmpData_defect.coord_atoms_broken.keys() )\n",
    "        times.sort()\n",
    "\n",
    "        #--- print dump\n",
    "        !rm $fout\n",
    "        for ii in times:\n",
    "            filtr = self.lmpData_defect.coord_atoms_broken[ii].Occupancy == 0.0\n",
    "            df = self.lmpData_defect.coord_atoms_broken[ii][filtr]\n",
    "            assert df.shape[0] == 1\n",
    "            df.id=1;df.type=1\n",
    "        #    print(df)\n",
    "            atom_current = lp.Atoms(**df)\n",
    "            box  = lp.Box( BoxBounds = self.lmpData_defect.BoxBounds[ii],  AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "            with open(fout,'a') as fp:\n",
    "                lp.WriteDumpFile(atom_current, box).Write(fp, itime = ii,\n",
    "                     attrs=['id', 'type','x', 'y', 'z'],\n",
    "        #                 fmt='%i %i %15.14e %15.14e %15.14e',\n",
    "                                                     )\n",
    "                \n",
    "    def Displacement(self, fp, fout,use_frame_offset=False):\n",
    "        '''\n",
    "        Return total displacements \n",
    "        '''\n",
    "        !rm $fout\n",
    "\n",
    "        #--- fetch parameters\n",
    "        fileCurr = fileRef = fp\n",
    "\n",
    "        #--- call ovito\n",
    "        t0 = time.time()\n",
    "#        pdb.set_trace()\n",
    "        !ovitos $self.lib_path/OvitosCna.py $fileCurr $fout 1 8 $fileRef $use_frame_offset\n",
    "        if self.verbose:\n",
    "            print('output disp:%s s'%(time.time()-t0))\n",
    "\n",
    "        #--- parse disp files\n",
    "        if self.verbose:\n",
    "            print('parsing %s'%fout)\n",
    "        t0 = time.time()\n",
    "        self.lmpDisp = lp.ReadDumpFile( fout )\n",
    "        self.lmpDisp.GetCords( ncount = sys.maxsize )\n",
    "#         if self.verbose:\n",
    "#             print('elapsed time %s s'%(time.time()-t0))\n",
    "#             display(self.lmpDisp.coord_atoms_broken[0].head())\n",
    "\n",
    "    def CommonNeighborAnalysis(self, fp, fout):\n",
    "        '''\n",
    "        common neighbor analysis\n",
    "        '''\n",
    "        !rm fout\n",
    "        !ovitos $self.lib_path/OvitosCna.py $fp $fout 1 0\n",
    "\n",
    "        #--- parse dump files\n",
    "        print('parsing %s'%(fout))\n",
    "        self.lmpCna = lp.ReadDumpFile( '%s'%(fout) ) \n",
    "        self.lmpCna.GetCords( ncount = sys.maxsize, \n",
    "                        )\n",
    "\n",
    "\n",
    "    def Integrate(self):\n",
    "        times = list(self.lmpDisp.coord_atoms_broken.keys())\n",
    "        times.sort()\n",
    "        x=list(map(lambda x:np.c_[self.lmpDisp.coord_atoms_broken[x].DisplacementX].flatten()[0],times))\n",
    "        y=list(map(lambda x:np.c_[self.lmpDisp.coord_atoms_broken[x].DisplacementY].flatten()[0],times))\n",
    "        z=list(map(lambda x:np.c_[self.lmpDisp.coord_atoms_broken[x].DisplacementZ].flatten()[0],times))\n",
    "        X=np.cumsum(x)\n",
    "        Y=np.cumsum(y)\n",
    "        Z=np.cumsum(z)\n",
    "\n",
    "        for itime, indx in zip(times,range(len(times))):\n",
    "            self.lmpDisp.coord_atoms_broken[itime].DisplacementX=X[indx]            \n",
    "            self.lmpDisp.coord_atoms_broken[itime].DisplacementY=Y[indx]\n",
    "            self.lmpDisp.coord_atoms_broken[itime].DisplacementZ=Z[indx]\n",
    "            \n",
    "    def AddZero(self):\n",
    "        self.lmpDisp.coord_atoms_broken[0] = self.lmpDisp.coord_atoms_broken[1]\n",
    "        self.lmpDisp.coord_atoms_broken[0].DisplacementX=0.0\n",
    "        self.lmpDisp.coord_atoms_broken[0].DisplacementY=0.0\n",
    "        self.lmpDisp.coord_atoms_broken[0].DisplacementZ=0.0\n",
    "        \n",
    "    def PrintOvito( self, title ):\n",
    "        #--- save\n",
    "        try:\n",
    "            os.system('rm %s'%title)\n",
    "        except:\n",
    "            pass\n",
    "        times = list( self.lmpDisp_defect.coord_atoms_broken.keys() )\n",
    "        times.sort()\n",
    "        itime0 = times[ 0 ]\n",
    "        rc = np.c_[ self.lmpDisp_defect.coord_atoms_broken[ itime0 ]['x y z'.split()] ]\n",
    "        for itime in times:\n",
    "            sfile        = open(title,'a')\n",
    "            dx           = np.c_[self.lmpDisp_defect.coord_atoms_broken[ itime ]['DisplacementX  DisplacementY  DisplacementZ'.split()]]\n",
    "            utl.PrintOvito(pd.DataFrame(np.c_[dx+rc].reshape(1,3),columns=['x','y','z']), \n",
    "                       sfile, 'itime=%s'%itime, attr_list=['x', 'y', 'z'])\n",
    "            sfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    !rm -r dumpFile; mkdir dumpFile; mkdir disp\n",
    "    \n",
    "    #--- parse allconf\n",
    "    pc = ParseConfiguration(confParser,verbose=True)\n",
    "    #\n",
    "    pc.Parse('%s/%s'%(confParser['input files']['input_path'],confParser['input files']['dump_file']),\n",
    "            'dumpFile/dump.xyz',\n",
    "            )\n",
    "    \n",
    "    #--- vacancy dynamics based on ws analysis\n",
    "    if eval(confParser['MsdAnalysis']['WignerSeitz']):\n",
    "        pc.WignerSeitz('%s/%s'%(confParser['input files']['input_path'],confParser['input files']['dump_file']),\n",
    "                       '%s/%s'%(confParser['input files']['input_path'],confParser['input files']['pure_crystal'])\n",
    "                      )\n",
    "        #--- output vacant sites\n",
    "        pc.Print('dumpFile/dump_vacant.xyz')\n",
    "    \n",
    "    \n",
    "        #--- vacancy disp\n",
    "        pc.Displacement('dumpFile/dump_vacant.xyz',\n",
    "                        'disp_vacant.xyz',\n",
    "                       use_frame_offset = True, #--- velocity\n",
    "                       )\n",
    "        pc.AddZero() #--- add first timestep\n",
    "        pc.Integrate() #--- get displacements\n",
    "        pc.lmpDisp_defect = pc.lmpDisp\n",
    "        pc.PrintOvito('dumpFile/vacancy_trajectories.xyz')\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    #--- total displacements\n",
    "    pc.Displacement('dumpFile/dump.xyz',\n",
    "                     'disp/disp.xyz')\n",
    "\n",
    "    #--- vacant site based on cna analysis\n",
    "#     pc.CommonNeighborAnalysis( 'dumpFile/dump.xyz',\n",
    "#                      'disp/cna.xyz')\n",
    "\n",
    "    #--- parse allconf_defect\n",
    "    #--- vacant site based on defects\n",
    "    pc_defect = ParseConfiguration(confParser,verbose=True)\n",
    "    pc_defect.Parse('%s/%s'%(confParser['input files']['input_path'],confParser['input files']['defect_file']),\n",
    "                    'dumpFile/dump_defects.xyz',\n",
    "\n",
    "                   )\n",
    "\n",
    "    #--- output timeseries\n",
    "    !mkdir msd\n",
    "    with open('msd/event_times.txt','w') as fp:\n",
    "        np.savetxt(fp,pc.lmpData.times,header='t')\n",
    "    #\n",
    "    with open('msd/timeseries.txt','w') as fp:\n",
    "        np.savetxt(fp,np.c_[pc.lmpData.headers],header='Barrier Energy Step Time')\n",
    "\n",
    "\n",
    "    return pc, pc_defect\n",
    "\n",
    "data, data_defect = main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# times = list(data.lmpDisp_defect.coord_atoms_broken.keys())\n",
    "# times.sort()\n",
    "\n",
    "# x=list(map(lambda x:np.c_[data.lmpDisp_defect.coord_atoms_broken[x].DisplacementX].flatten()[0],times))\n",
    "# y=list(map(lambda x:np.c_[data.lmpDisp_defect.coord_atoms_broken[x].DisplacementY].flatten()[0],times))\n",
    "# z=list(map(lambda x:np.c_[data.lmpDisp_defect.coord_atoms_broken[x].DisplacementZ].flatten()[0],times))\n",
    "\n",
    "# ax=utl.PltErr(None,None,Plot=False)\n",
    "# #utl.PltErr(times[:-1],np.diff(x),ax=ax,Plot=False)\n",
    "# utl.PltErr(times,x,ax=ax,Plot=False)\n",
    "# # utl.PltErr(times[:-1],np.diff(y),ax=ax,Plot=False)\n",
    "# # utl.PltErr(times[:-1],np.diff(z),ax=ax,Plot=False)\n",
    "\n",
    "# utl.PltErr(None,None,title='disp/vel.png',ax=ax, yscale='linear',xlim=(0,75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## msd vs. time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MsDisp:\n",
    "    \n",
    "    def __init__(self, lmpDisp,  \n",
    "                 filtr, \n",
    "                 lmpCna = None,\n",
    "                 skip_times = 0):\n",
    "        '''\n",
    "        returns mean-squared displacements\n",
    "        '''\n",
    "        self.disp = lmpDisp.coord_atoms_broken\n",
    "        try:\n",
    "            self.cna = lmpCna.coord_atoms_broken\n",
    "        except:\n",
    "            pass\n",
    "        self.times = list(lmpDisp.coord_atoms_broken.keys())\n",
    "        self.times.sort()\n",
    "        self.times = self.times[ skip_times: ]\n",
    "#        print(self.times)\n",
    "        self.filtr=filtr\n",
    "        \n",
    "    def Get(self,LOG=False):\n",
    "        '''\n",
    "        returns msd (no temporal window)\n",
    "        '''\n",
    "        if not LOG: #---  mean\n",
    "            msd = list(map(lambda x:(self.disp[x]['DisplacementX']**2+\\\n",
    "                         self.disp[x]['DisplacementY']**2+\\\n",
    "                         self.disp[x]['DisplacementZ']**2).mean(),\n",
    "                    self.times))\n",
    "        else: #--- geometric mean\n",
    "            msd = list(map(lambda x:10**((np.log10(self.disp[x]['DisplacementX']**2+\\\n",
    "                         self.disp[x]['DisplacementY']**2+\\\n",
    "                         self.disp[x]['DisplacementZ']**2)).mean()),\n",
    "                    self.times))\n",
    "        return np.array(msd)\n",
    "        \n",
    "    def GetPdfJumps(self):\n",
    "        '''\n",
    "        pdf's of jumps\n",
    "        '''\n",
    "        cols = ['DisplacementX','DisplacementY','DisplacementZ']\n",
    "        for itime, itime0, count in zip(self.times[1:],self.times[:-1],range(len(self.times))):\n",
    "            df=self.disp[itime][self.filtr]\n",
    "            df0=self.disp[itime0][self.filtr]\n",
    "            veloc = df[cols]-df0[cols]\n",
    "            if count == 0:\n",
    "                df_concat = np.c_[veloc]\n",
    "            else:\n",
    "                df_concat = np.concatenate([df_concat,veloc],axis=0) \n",
    "        df_abs = np.abs(df_concat.flatten())\n",
    "        filtr = df_abs > 0.0\n",
    "        \n",
    "        hist, bin_edges, err = utl.GetPDF(df_abs[filtr],n_per_decade=4)\n",
    "        utl.PltErr(bin_edges,hist, yerr=err,\n",
    "                  yscale='log',\n",
    "                   xscale='log',\n",
    "        #           ylim=(1e-6,1e4)\n",
    "                  )\n",
    "        #\n",
    "        with open('msd/event_jumps.txt','w') as fp:\n",
    "            np.savetxt(fp,np.c_[bin_edges,hist,err],header='bin_edges hist err')\n",
    "\n",
    "        \n",
    "    def WindowAverage(self,ttime,bins_per_decade=4,LOG=False,nmin=1):\n",
    "        '''\n",
    "        returnd msd (include temporal windows)\n",
    "        '''\n",
    "        time_keys = np.arange(0,len(self.times),2) #--- ignore half step\n",
    "        assert len(ttime) == len(time_keys), 'must be of the same size!'\n",
    "\n",
    "        t0=time.time()\n",
    "        cols = 'DisplacementX DisplacementY DisplacementZ'.split()\n",
    "        for shift in range(1,len(time_keys)): #-1):\n",
    "            dt = zip(time_keys,time_keys[shift:]) #--- time tuples\n",
    "            dt_real = list(map(lambda x: x[1]-x[0], zip(ttime,ttime[shift:]))) #--- real time difference\n",
    "            disp    = list(map(lambda x: np.c_[self.disp[x[1]][cols]-self.disp[x[0]][cols]].flatten(),zip(time_keys,time_keys[shift:])))\n",
    "            if shift == 1:\n",
    "                tr_mat=np.c_[dt_real,disp]\n",
    "            else:    \n",
    "                tr_mat = np.concatenate([tr_mat,np.c_[dt_real,disp]],axis=0)\n",
    "\n",
    "        print('1st: t=%s'%(time.time()-t0))\n",
    "\n",
    "        #--- remove dt == 0\n",
    "        filtr = tr_mat[:,0] > 0\n",
    "        tr_mat = tr_mat[filtr]\n",
    "        \n",
    "        return self.Binning(tr_mat,bins_per_decade,nmin=nmin)\n",
    "\n",
    "\n",
    "    def WindowAverage2ndMethod(self,ttime,bins_per_decade=4,LOG=False):\n",
    "        '''\n",
    "        returnd msd (include temporal windows)\n",
    "        '''\n",
    "\n",
    "        time_keys = np.arange(0,len(self.times),2) #--- ignore half step\n",
    "        assert len(ttime) == len(time_keys), 'must be of the same size!'\n",
    "        \n",
    "        tij = MsDisp.GetTijMatrix(ttime)\n",
    "        t0 = time.time()\n",
    "        xsq = self.GetXsqMatrix(time_keys,0)\n",
    "        ysq = self.GetXsqMatrix(time_keys,1)\n",
    "        zsq = self.GetXsqMatrix(time_keys,2)\n",
    "#        print(xsq)\n",
    "        print('2nd: t=%s'%(time.time()-t0))\n",
    "\n",
    "                \n",
    "        #--- remove dt == 0\n",
    "        tij_flat = tij.flatten()\n",
    "        filtr = tij_flat > 0.0\n",
    "        usq = (xsq + ysq + zsq).flatten()\n",
    "#         tr_mat = tr_mat[filtr]\n",
    "# #        print('dt_min=',tr_mat[:,0].min())\n",
    "# #        pdb.set_trace()\n",
    "#        print('t,u=',tij_flat[filtr],usq[filtr])\n",
    "\n",
    "        return MsDisp.Binning2nd(tij_flat[filtr],usq[filtr],bins_per_decade),\\\n",
    "               MsDisp.Binning2nd(tij_flat[filtr],usq[filtr],bins_per_decade, LogScale = False)\n",
    "\n",
    "    def GetXsqMatrix(self,tlist, dim):\n",
    "        n = len(tlist)\n",
    "        xijsqMatrix = np.zeros(n*n).reshape((n,n))\n",
    "        atom_indices = self.FiltrdAtoms(tlist) #--- rows corresponding to filtered frame\n",
    "        key = ['DisplacementX','DisplacementY','DisplacementZ'][dim]\n",
    "        for irow in range(n):\n",
    "            for iatom in atom_indices: \n",
    "                x_peratom_timeseries = self.GetTimeSeriesPerAtom(iatom, tlist, key ) \n",
    "                xijsqMatrix[ irow ] +=  (x_peratom_timeseries - x_peratom_timeseries[ irow ])**2\n",
    "        return xijsqMatrix / len(atom_indices)\n",
    "\n",
    "    def GetTimeSeriesPerAtom(self, atomIndx, tlist, key, vacancy = False ):\n",
    "        return list(map(lambda x:self.disp[x][key].iloc[atomIndx], tlist))\n",
    "\n",
    "\n",
    "    def FiltrdAtoms(self,tlist):\n",
    "        time0 = tlist[0]\n",
    "        return self.disp[time0][self.filtr].index\n",
    "\n",
    "    @staticmethod\n",
    "    def GetTijMatrix(tlist):\n",
    "        tlist = np.array(list(tlist))\n",
    "        n = len(tlist)\n",
    "        tijMatrix = np.zeros(n*n).reshape((n,n))\n",
    "        t0 = time.time()\n",
    "        for irow in range(n):\n",
    "            tijMatrix[ irow ] = tlist - tlist[ irow ]\n",
    "        return tijMatrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def Binning2nd(tlist,usq,bins_per_decade, LogScale = True):\n",
    "        #--- binning\n",
    "        xmin = 0.99*tlist.min()\n",
    "        xmax = 1.01*tlist.max()\n",
    "        if LogScale:\n",
    "            n_decades = int(np.ceil(np.log10(xmax/xmin)))\n",
    "            bins = np.logspace(np.log10(xmin),np.log10(xmax),n_decades*bins_per_decade)\n",
    "        else:\n",
    "            bins = np.linspace(xmin,xmax,32)\n",
    "        #\n",
    "        ysum, edges = np.histogram(tlist,bins=bins,weights=usq)\n",
    "        ysum_sq, edges = np.histogram(tlist,bins=bins,weights=usq*usq)\n",
    "        xsum, edges = np.histogram(tlist,bins=bins,weights=tlist)\n",
    "        count, edges = np.histogram(tlist,bins=bins)\n",
    "        #\n",
    "#        filtr = count > 1\n",
    "        filtr = count > 0\n",
    "        ysum = ysum[filtr]\n",
    "        ysum_sq = ysum_sq[filtr]\n",
    "        xsum = xsum[filtr]\n",
    "        count = count[filtr]\n",
    "        assert not np.any(count == 0), 'incerease bin size!'\n",
    "        #\n",
    "        ysum_sq /= count\n",
    "        ysum /= count\n",
    "        xsum /= count\n",
    "        ysum_sq -= (ysum * ysum)\n",
    "#        assert not np.any(ysum_sq < 0.0), 'print %s'%ysum_sq\n",
    "        \n",
    "        return np.c_[xsum,ysum,(ysum_sq/count)**0.5]\n",
    "    \n",
    "    def VacancyDynamics(self, title='void.xyz',\n",
    "                       **kwargs):\n",
    "        '''\n",
    "        return xyz coordinates associated with vacancy \n",
    "        '''\n",
    "        \n",
    "        #--- unwrapped coordinates\n",
    "        times            = self.times[1:]\n",
    "        times_ref        = self.times[:-1]\n",
    "            \n",
    "\n",
    "        cols             = ['DisplacementX','DisplacementY','DisplacementZ']\n",
    "        xsum_concat=np.array([0,0,0])\n",
    "        for itime, itime_ref in zip(times,times_ref):\n",
    "            df           = self.disp[itime]\n",
    "            df0          = self.disp[itime_ref]\n",
    "            veloc        = pd.DataFrame(np.c_[df0['id'],df[cols]-df0[cols]],columns=['id']+cols)\n",
    "            #\n",
    "#            filtr = self.cna[itime_ref]['StructureType'] == 0.0 #--- neighboring atoms\n",
    "        #--- filter atom type\n",
    "            if 'filtr_type' in kwargs:\n",
    "                filtr = self.cna[itime_ref].type == eval(kwargs['filtr_type'])\n",
    "                defect_atoms = self.cna[itime_ref][filtr].id\n",
    "            else:\n",
    "#                defect_atoms = self.cna[itime_ref].id\n",
    "                defect_atoms_ref = self.cna[itime_ref].id\n",
    "                defect_atoms_current = self.cna[itime].id\n",
    "                defect_atoms = list(set(list(defect_atoms_ref)+list(defect_atoms_current)))\n",
    "\n",
    "            veloc        = utl.FilterDataFrame(veloc,key='id',val=defect_atoms)\n",
    "            #\n",
    "            #indx_max     = np.argmax(list(map(lambda x:np.sum(x*x),np.c_[veloc[cols]])))\n",
    "\n",
    "            xsum         = -np.array(veloc[cols].sum()) #---disp\n",
    "            xsum_concat  = np.c_[xsum_concat,xsum]\n",
    "        xsum_concat      = xsum_concat.T\n",
    "        xv               = xsum_concat.cumsum(axis=0) #--- integrate\n",
    "        #--- add initial position\n",
    "        itime            = times_ref[0]\n",
    "        if 'filtr_type' in kwargs:\n",
    "            filtr = self.cna[itime].type == eval(kwargs['filtr_type'])\n",
    "            defect_atoms = self.cna[itime][filtr].id\n",
    "        else:\n",
    "            defect_atoms     = self.cna[itime].id\n",
    "        disps            = utl.FilterDataFrame(self.disp[itime],key='id',val=defect_atoms)\n",
    "        rc               = np.array(disps[['x','y','z']].iloc[0]) #mean())\n",
    "        #--- print\n",
    "        try:\n",
    "            os.system('rm msd/%s'%title)\n",
    "        except:\n",
    "            pass\n",
    "        for itime in range(xv.shape[0]):\n",
    "            sfile        = open('msd/%s'%title,'a')\n",
    "            utl.PrintOvito(pd.DataFrame(np.c_[xv[itime,:]+rc].reshape(1,3),columns=['x','y','z']), \n",
    "                       sfile, 'itime=%s'%itime, attr_list=['x', 'y', 'z'])\n",
    "            sfile.close()\n",
    "        self.xv          = xv\n",
    "        self.dxv         = xsum_concat\n",
    "        \n",
    "    def msdVacancy(self,ttime,bins_per_decade=4,LOG=False,nmin=1):\n",
    "        '''\n",
    "        returnd msd(t) associated with motion of the vacancy\n",
    "        '''\n",
    "        time_keys        =  np.arange(0,len(self.times),2) #--- ignore half step\n",
    "        assert len(ttime)== len(time_keys), 'must be of the same size!'\n",
    "        time_indices     = np.arange(len(time_keys))\n",
    "        for shift in range(1,len(time_keys)):\n",
    "            dt      = zip(time_keys,time_keys[shift:]) #--- time tuples\n",
    "            dt_real = list(map(lambda x: x[1]-x[0], zip(ttime,ttime[shift:]))) #--- real time difference\n",
    "            disp    = list(map(lambda x: self.xv[x[1]]-self.xv[x[0]],zip(time_indices,time_indices[shift:])))\n",
    "            if shift== 1:\n",
    "                tr_mat=np.c_[dt_real,disp]\n",
    "            else:    \n",
    "                tr_mat = np.concatenate([tr_mat,np.c_[dt_real,disp]],axis=0)\n",
    "                \n",
    "        #--- remove dt == 0\n",
    "        filtr = tr_mat[:,0] > 0\n",
    "        tr_mat = tr_mat[filtr]\n",
    "        return self.Binning(tr_mat,bins_per_decade,nmin=nmin)\n",
    "\n",
    "\n",
    "    def Binning(self,tr_mat,bins_per_decade, nmin=1):\n",
    "        #--- binning\n",
    "        xmin       = 0.99*tr_mat[:,0].min()\n",
    "        xmax       = 1.01*tr_mat[:,0].max()\n",
    "        n_decades  = int(np.ceil(np.log10(xmax/xmin)))\n",
    "        bins       = np.logspace(np.log10(xmin),np.log10(xmax),n_decades*bins_per_decade)\n",
    "        \n",
    "        #\n",
    "        count, _   = np.histogram(tr_mat[:,0],bins=bins)\n",
    "        tsum,  _   = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,0])\n",
    "        filtr      = count >= nmin\n",
    "        #  \n",
    "        xsum, _    = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,1])\n",
    "        ysum, _    = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,2])\n",
    "        zsum, _    = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,3])\n",
    "\n",
    "        xsum_sq, _ = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,1]*tr_mat[:,1])\n",
    "        ysum_sq, _ = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,2]*tr_mat[:,2])\n",
    "        zsum_sq, _ = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,3]*tr_mat[:,3])\n",
    "        #\n",
    "        xsum       = xsum[filtr]\n",
    "        ysum       = ysum[filtr]\n",
    "        zsum       = zsum[filtr]\n",
    "        #\n",
    "        xsum_sq    = xsum_sq[filtr]\n",
    "        ysum_sq    = ysum_sq[filtr]\n",
    "        zsum_sq    = zsum_sq[filtr]\n",
    "        #\n",
    "        tsum       = tsum[filtr]\n",
    "        count      = count[filtr]\n",
    "        assert not np.any(count < nmin), 'incerease bin size!'\n",
    "        #\n",
    "        xsum_sq   /= count\n",
    "        ysum_sq   /= count\n",
    "        zsum_sq   /= count\n",
    "        #\n",
    "        xsum      /= count\n",
    "        ysum      /= count\n",
    "        zsum      /= count\n",
    "        #     \n",
    "        tsum      /= count\n",
    "        #\n",
    "        xsum_sq   -= (xsum * xsum)\n",
    "        ysum_sq   -= (ysum * ysum)\n",
    "        zsum_sq   -= (zsum * zsum)\n",
    "        assert np.all(xsum_sq >= 0) and np.all(ysum_sq >= 0) and np.all(zsum_sq >= 0)\n",
    "        #\n",
    "        var        = ( xsum_sq + ysum_sq + zsum_sq ) / 3.0\n",
    "#        assert not np.any(ysum_sq < 0.0), 'print %s'%ysum_sq\n",
    "        \n",
    "        return np.c_[tsum,var, var * np.sqrt(2.0/count) ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def junk(**kwargs):\n",
    "#     print(kwargs)\n",
    "\n",
    "# junk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomChoice(lmpDisp):\n",
    "    natom = lmpDisp.coord_atoms_broken[0].shape[0]\n",
    "    size=np.min([natom,eval(confParser['MsdAnalysis']['natom'])])\n",
    "    indices = np.random.choice(range(natom),replace=False,\n",
    "                               size=size)\n",
    "    assert indices.shape[ 0 ] == size\n",
    "    filtr = np.zeros(natom,dtype=bool)\n",
    "    filtr[ indices ] = True\n",
    "    assert np.sum(filtr) == indices.shape[0], '%s %s' %(np.sum(filtr), indices.shape[0])\n",
    "    \n",
    "    return filtr\n",
    "\n",
    "def main(data):\n",
    "    \n",
    "    if not eval(confParser['MsdAnalysis']['MsdAnalysis']):\n",
    "        return\n",
    "    \n",
    "    \n",
    "    !mkdir msd\n",
    "    \n",
    "    #----------------------------------\n",
    "    #--- msd: dynamics of vacant site \n",
    "    #--- based on the cna analysis\n",
    "    #----------------------------------\n",
    "    msd          = MsDisp(data.lmpDisp, \n",
    "                         RandomChoice(data.lmpDisp), #--- filter \n",
    "                         data_defect.lmpData,\n",
    "                        )\n",
    "    #---  vacancy\n",
    "    if eval(confParser['MsdAnalysis']['vacancy']):\n",
    "        msd.VacancyDynamics(title='void2.xyz', \n",
    "                            **confParser['MsdAnalysis'])\n",
    "        vac_data     = msd.msdVacancy(data.lmpData.headers['Time'][::2],\n",
    "                                      bins_per_decade=4,LOG=False,nmin=10)\n",
    "        #\n",
    "        with open('msd/msd_vac_cna.txt','w') as fp:\n",
    "#             np.savetxt(fp,vac_data,header='t\\tmsd\\terr')\n",
    "             np.savetxt(fp,vac_data,header='t dx dy dz')\n",
    "\n",
    "#    msd.GetPdfJumps() #--- jump distributions\n",
    "\n",
    "     #--- msd\n",
    "    if eval(confParser['MsdAnalysis']['total']):\n",
    "        ans, ans_lin = msd.WindowAverage2ndMethod(data.lmpData.headers['Time'][::2],\n",
    "                                                  bins_per_decade=4,LOG=False) #---msd\n",
    "    \n",
    "        with open('msd/msd.txt','w') as fp:\n",
    "            np.savetxt(fp,ans,header='t\\tmsd\\terr')\n",
    "        with open('msd/msd_lin.txt','w') as fp:\n",
    "            np.savetxt(fp,ans_lin,header='t\\tmsd\\terr')\n",
    "    #\n",
    "\n",
    "        #--- correlated noise\n",
    "    #     xvv = np.c_[list(map(lambda x:msd.dxv[x]+msd.dxv[x+1],range(1,msd.dxv.shape[0],2)))] #--- include half steps\n",
    "    #     with open('msd/noise.txt','w') as fp:\n",
    "    #         np.savetxt(fp,np.c_[lmpData.headers['Time'][1:-1:2],xvv],header='time dx dy dz')\n",
    "\n",
    "        #---  filter based on atom types\n",
    "        types      = list(set(data.lmpDisp.coord_atoms_broken[0]['type']))\n",
    "        for itype in types:\n",
    "            filtr  = data.lmpDisp.coord_atoms_broken[0]['type'] == itype\n",
    "            msd    = MsDisp( data.lmpDisp,\n",
    "                             filtr, #--- filter \n",
    "                             data_defect.lmpData\n",
    "                           )\n",
    "            ans, _ = msd.WindowAverage2ndMethod(data.lmpData.headers['Time'][::2],\n",
    "                                               bins_per_decade=4,LOG=False)\n",
    "            #--- print\n",
    "            with open('msd/msd_type%s.txt'%itype,'w') as fp:\n",
    "                np.savetxt(fp,ans,header='t\\tmsd\\terr')\n",
    "\n",
    "\n",
    "    #--- correlated noise\n",
    "#    xvv = np.c_[list(map(lambda x:msd.dxv[x]+msd.dxv[x+1],range(1,msd.dxv.shape[0],2)))] #--- include half steps\n",
    "#    with open('msd/noise.txt','w') as fp:\n",
    "#        np.savetxt(fp,np.c_[lmpData.headers['Time'][1:-1:2],xvv],header='time dx dy dz')\n",
    "\n",
    "#     with open('msd/msd_logAveraged.txt','w') as fp:\n",
    "#         np.savetxt(fp,ans_logAveraged,header='t\\tmsd\\terr')\n",
    "\n",
    "\n",
    "\n",
    "    #----------------------------------\n",
    "    #--- msd: dynamics of vacant site \n",
    "    #--- based on the ws analysis\n",
    "    #----------------------------------\n",
    "    if eval(confParser['MsdAnalysis']['WignerSeitz']):\n",
    "        start_frame  = 0\n",
    "        msd          = MsDisp( data.lmpDisp_defect, \n",
    "                              np.ones(data.lmpDisp_defect.coord_atoms_broken[start_frame].shape[0],dtype=bool) #--- filter \n",
    "                            )\n",
    "        ans          = msd.WindowAverage(data.lmpData.headers['Time'][start_frame::2],\n",
    "                                         bins_per_decade= 4,\n",
    "                                         LOG            = False,\n",
    "                                         nmin           = 10,\n",
    "                                                 ) #---msd\n",
    "        !mkdir msd\n",
    "        with open('msd/msd_vac_ws.txt','w') as fp:\n",
    "             np.savetxt(fp,ans,header='t\\tmsd\\terr')\n",
    "\n",
    "\n",
    "\n",
    "main(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy barriers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnergyBarrier:\n",
    "    '''\n",
    "    return energy barriers corresponding to diffusional hopping\n",
    "    '''\n",
    "    def __init__(self,events_directory,evlist_directory,lmpData):\n",
    "        self.events_dir = events_directory\n",
    "        self.evlist_dir = evlist_directory\n",
    "        self.lmpData = lmpData.coord_atoms_broken[0]\n",
    "        \n",
    "    def Parse(self):\n",
    "        '''\n",
    "        parse event files\n",
    "        '''\n",
    "        self.events_id_energy = self.ParseEvents_dir()\n",
    "        self.catalog = self.ParseEvList_dir()\n",
    "        \n",
    "        \n",
    "    def ParseEvents_dir(self):\n",
    "        files = os.listdir(self.events_dir)\n",
    "        d=[]\n",
    "        for sfile in files:\n",
    "            if not '.xyz' in sfile: #--- skip .xyz files \n",
    "                try:\n",
    "                    filee=open('%s/%s'%(self.events_dir,sfile)) #--- open file\n",
    "                    xstrs = filee.readlines()\n",
    "                    event_id = int(xstrs[0].split()[-1]) #--- event id\n",
    "                    barrier = float(xstrs[2].split()[-1]) #--- energy\n",
    "                    ncluster =  int(xstrs[15].split()[-1])                 \n",
    "                    shape_cluster_atoms =  int(xstrs[16].split()[-1])\n",
    "                    atom_id = int(xstrs[17+ncluster].split()[0])\n",
    "                    #print(atom_id)\n",
    "                    d = np.c_[event_id,atom_id,barrier] if len(d) == 0 else\\\n",
    "                    np.concatenate([d,np.c_[event_id,atom_id,barrier]])\n",
    "#                    d.setdefault(event_id,[]).append(barrier) #--- store\n",
    "                except:\n",
    "        #            traceback.print_exc()\n",
    "                    continue\n",
    "            \n",
    "        #--- extract types\n",
    "        df=self.lmpData\n",
    "        atom_ids = d[:,1]\n",
    "        types = utl.FilterDataFrame(df, \n",
    "                    key='id', \n",
    "                    val=atom_ids\n",
    "                   )['type']\n",
    "\n",
    "        return pd.DataFrame(np.c_[types,d],columns=['atom_type','event_id','atom_id','barrier'])\n",
    "\n",
    "    def ParseEvList_dir(self):\n",
    "        files = os.listdir(self.evlist_dir)\n",
    "        events={}\n",
    "        for sfile in files:\n",
    "            try:\n",
    "                kmc_step = int(sfile.split('_')[-1])\n",
    "        #        print(kmc_step)\n",
    "                filee=open('%s/%s'%(self.evlist_dir,sfile)) #--- open file\n",
    "                events[kmc_step] = pd.read_csv(filee,delim_whitespace=True).iloc[1:]#delimiter='')\n",
    "            except:\n",
    "                continue\n",
    "        return events\n",
    "        \n",
    "    def SplitByType(self):\n",
    "        '''\n",
    "        return energies (parsed from catalogs) slipt by atom types\n",
    "        '''\n",
    "        kmc_steps = list(self.catalog.keys())\n",
    "        kmc_steps.sort()\n",
    "\n",
    "\n",
    "        #--- dict based on types\n",
    "        df_concat = {}\n",
    "        types = list(set(self.lmpData.type))\n",
    "        for itype in types:\n",
    "            df_concat[str(itype)] = {}\n",
    "\n",
    "        for kmc_step in kmc_steps: #--- kmc loop\n",
    "            df = self.catalog[kmc_step]\n",
    "            sdict=df.groupby(by='#TypeId').groups #--- group by type\n",
    "            for itype in sdict:\n",
    "                indices = sdict[itype] #--- row index: atoms with  '#TypeId' == itype\n",
    "                cond = len(df_concat[itype]) == 0 #--- empty key?\n",
    "                df_concat[itype] = np.c_[df.loc[indices]] if cond else\\\n",
    "                np.concatenate([df_concat[itype],np.c_[df.loc[indices]]],axis=0)\n",
    "\n",
    "        self.energyByType = {}\n",
    "        for itype in df_concat:\n",
    "             self.energyByType[ itype ] = pd.DataFrame(df_concat[itype],columns=list(df.keys()))        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data):\n",
    "    if not eval(confParser['EnergyBarrier']['EnergyBarrier']):\n",
    "        return\n",
    "    \n",
    "    eb = EnergyBarrier('%s/EVENTS_DIR'%confParser['input files']['input_path'],\n",
    "                       '%s/EVLIST_DIR'%confParser['input files']['input_path'],\n",
    "                       data.lmpData\n",
    "\n",
    "                      )\n",
    "    eb.Parse()\n",
    "    eb.SplitByType()\n",
    "\n",
    "    #eb.events_id_energy extract from Events_dir\n",
    "    #self.energyByType extract from catalogs\n",
    "\n",
    "    #--- write to file\n",
    "    !mkdir msd\n",
    "    with open('msd/eventID_barrier.txt','w') as fp:\n",
    "        np.savetxt(fp,\n",
    "                   np.c_[eb.events_id_energy],\n",
    "                   header='atom_type event_id atom_id barrier')\n",
    "\n",
    "    #--- write to file: energy from catalogs\n",
    "    for itype in eb.energyByType.keys():\n",
    "        with open('msd/eventID_barrier_catalog_type%s.txt'%itype,'w') as fp:\n",
    "        #--- concat different types\n",
    "            sarr = np.c_[eb.energyByType[itype][['AtomId','eventId','barrier']]].astype(float)\n",
    "            np.savetxt(fp,\n",
    "                       sarr,\n",
    "                       header='AtomId eventId barrier'\n",
    "                      )\n",
    "main(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## arrhenius law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Temperature:\n",
    "    def __init__(self,temp_range,nrun,verbose=False):\n",
    "        self.temps =  temp_range\n",
    "        self.nrun = nrun\n",
    "        self.verbose = verbose\n",
    "#         pdb.set_trace()\n",
    "#        self.temps_runs = np.concatenate(list(map(lambda x:self.BuildTempRealizationPair([x[0]],np.arange(x[1])),\n",
    "#            zip(self.temps,self.nrun))))\n",
    "\n",
    "        self.temps_runs = np.concatenate(list(map(lambda x:self.BuildTempRealizationPair([x[0]],x[1]),\n",
    "             zip(self.temps,self.nrun))))\n",
    "        \n",
    "    \n",
    "    def BuildTempRealizationPair(self,temps,nrun):\n",
    "        t,r=np.meshgrid(temps,nrun,indexing='ij')\n",
    "        return np.array(list(zip(t.flatten(),r.flatten())))\n",
    "        \n",
    "    def ModifyNrun(self,dirs):\n",
    "        #--- modify dirs\n",
    "        count = -1\n",
    "        dirs_copy = dirs[:]\n",
    "        for _, indx in zip(self.temps,range(len(self.temps))):\n",
    "            nrun_mod = self.nrun[indx][:]\n",
    "            for y in self.nrun[indx]:\n",
    "                count += 1\n",
    "                x = dirs[count]\n",
    "                if not os.path.isfile(x): #--- if false: remove file from \"dirs\"\n",
    "                    dirs_copy.remove(x)\n",
    "                    nrun_mod.remove(y)\n",
    "            self.nrun[indx] = nrun_mod[:]\n",
    "\n",
    "            assert len(self.nrun[indx]) > 0, 'temp = %s has no data!'%(self.temps[indx])\n",
    "                \n",
    "        self.temps_runs = np.concatenate(list(map(lambda x:self.BuildTempRealizationPair([x[0]],x[1]),\n",
    "             zip(self.temps,self.nrun))))\n",
    "        return dirs_copy\n",
    "        \n",
    "    def Parse(self,dirs):\n",
    "            \n",
    "        dirs = self.ModifyNrun(dirs)\n",
    "#         print('dirs:',dirs)\n",
    "        self.data=list(map(lambda x:np.loadtxt(x,ndmin=2),dirs))\n",
    "        if self.verbose:\n",
    "            n = np.array(self.nrun).flatten()\n",
    "            list(map(lambda x:print('Parsing: %s data.shape is: %s'%(x[1],x[0].shape)),zip(self.data,n)))\n",
    "#        print('np.array(self.data):',np.array(self.data))\n",
    "\n",
    "        \n",
    "    def Plot(self,**kwargs):\n",
    "#        print(list(self.temps_runs))\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs\n",
    "                    else (1.0,0.5,0.5,0.5)\n",
    "                   )\n",
    "        for data, temp_run, count in zip(self.data,self.temps_runs,range(len(self.data))): \n",
    "            temp = temp_run[0]\n",
    "            try:\n",
    "                utl.PltErr(data[:,0],data[:,1],\n",
    "                       yerr=data[:,2],\n",
    "                       ax = self.ax,\n",
    "                       attrs=symbols.GetAttrs(count=count%7,label=r'$%s$'%temp),\n",
    "                       Plot=False,\n",
    "                      )\n",
    "            except:\n",
    "                continue\n",
    "        #\n",
    "        utl.PltErr(None,\n",
    "                   None,\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "#                 legend=legends.Get(),\n",
    "                   **kwargs\n",
    "                  )\n",
    "\n",
    "\n",
    "\n",
    "    def Binning(self,tr_mat,bins_per_decade, nmin=1):\n",
    "        #--- binning\n",
    "        xmin       = 0.99*tr_mat[:,0].min()\n",
    "        xmax       = 1.01*tr_mat[:,0].max()\n",
    "        n_decades  = int(np.ceil(np.log10(xmax/xmin)))\n",
    "        bins       = np.logspace(np.log10(xmin),np.log10(xmax),n_decades*bins_per_decade)\n",
    "        \n",
    "        #\n",
    "        count, _   = np.histogram(tr_mat[:,0],bins=bins)\n",
    "        tsum,  _   = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,0])\n",
    "        filtr      = count >= nmin\n",
    "        #  \n",
    "        xsum, _    = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,1])\n",
    "        ysum, _    = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,2])\n",
    "        zsum, _    = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,3])\n",
    "\n",
    "        xsum_sq, _ = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,1]*tr_mat[:,1])\n",
    "        ysum_sq, _ = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,2]*tr_mat[:,2])\n",
    "        zsum_sq, _ = np.histogram(tr_mat[:,0],bins=bins,weights=tr_mat[:,3]*tr_mat[:,3])\n",
    "        #\n",
    "        xsum       = xsum[filtr]\n",
    "        ysum       = ysum[filtr]\n",
    "        zsum       = zsum[filtr]\n",
    "        #\n",
    "        xsum_sq    = xsum_sq[filtr]\n",
    "        ysum_sq    = ysum_sq[filtr]\n",
    "        zsum_sq    = zsum_sq[filtr]\n",
    "        #\n",
    "        tsum       = tsum[filtr]\n",
    "        count      = count[filtr]\n",
    "        print('count=',count)\n",
    "        assert not np.any(count < nmin), 'incerease bin size!'\n",
    "        #\n",
    "        xsum_sq   /= count\n",
    "        ysum_sq   /= count\n",
    "        zsum_sq   /= count\n",
    "        #\n",
    "        xsum      /= count\n",
    "        ysum      /= count\n",
    "        zsum      /= count\n",
    "        #     \n",
    "        tsum      /= count\n",
    "        #\n",
    "        xsum_sq   -= (xsum * xsum)\n",
    "        ysum_sq   -= (ysum * ysum)\n",
    "        zsum_sq   -= (zsum * zsum)\n",
    "        assert np.all(xsum_sq >= 0) and np.all(ysum_sq >= 0) and np.all(zsum_sq >= 0)\n",
    "        #\n",
    "        var        = ( xsum_sq + ysum_sq + zsum_sq ) / 3.0\n",
    "#        assert not np.any(ysum_sq < 0.0), 'print %s'%ysum_sq\n",
    "        \n",
    "        return np.c_[tsum,var,np.zeros( len( tsum ) ) ] \n",
    "\n",
    "\n",
    "    def EnsAverage2nd(self,\n",
    "                   log_scale_x=False,log_scale_y=False,\n",
    "                   col_x=0,col_y=1,\n",
    "                   n_bins_per_decade=6,\n",
    "                  n_thresh=0,\n",
    "                   ymin=-sys.maxsize,ymax=sys.maxsize\n",
    "                  ):\n",
    "        kount = 0\n",
    "        self.data_averaged = {} \n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp\n",
    "            nruns = len(self.nrun[indx])\n",
    "            data = self.data[kount:kount+nruns]\n",
    "#             if self.verbose:\n",
    "#                 print('data.shape:',np.array(data).shape)\n",
    "    \n",
    "            filtr = list(map(lambda x:x.shape[0] > 0,data)) #--- filter empty arrays\n",
    "    \n",
    "            data = np.concatenate(np.array(data)[filtr]) #,axis=0)\n",
    "            if self.verbose:\n",
    "                print('data.shape:',np.array(data).shape)\n",
    "#             pdb.set_trace()\n",
    "        \n",
    "            self.data_averaged[ temp ] = self.Binning(data,n_bins_per_decade,nmin=n_thresh)\n",
    "\n",
    "            kount += nruns #self.nrun\n",
    "            \n",
    "    def EnsAverage(self,\n",
    "                   log_scale_x=False,log_scale_y=False,\n",
    "                   col_x=0,col_y=1,\n",
    "                   n_bins_per_decade=6,\n",
    "                  n_thresh=0,\n",
    "                   ymin=-sys.maxsize,ymax=sys.maxsize\n",
    "                  ):\n",
    "        kount = 0\n",
    "        self.data_averaged = {} #np.zeros(len(self.temps))\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp\n",
    "            nruns = len(self.nrun[indx])\n",
    "            data = self.data[kount:kount+nruns]\n",
    "            if self.verbose:\n",
    "                print('data.shape:',np.array(data).shape)\n",
    "#             print('np.array(data):',np.array(data))\n",
    "#             pdb.set_trace()\n",
    "    \n",
    "            filtr = list(map(lambda x:x.shape[0] > 0,data)) #--- filter empty arrays\n",
    "    \n",
    "            data = np.concatenate(np.array(data)[filtr]) #,axis=0)\n",
    "            self.data_averaged[ temp ] = self.hist(data,\n",
    "                                                   log_scale_x,log_scale_y,\n",
    "                                                   n_bins_per_decade=n_bins_per_decade,\n",
    "                                                   col_x = col_x, col_y = col_y,\n",
    "                                                   n_thresh=n_thresh,\n",
    "                                                   ymin=ymin,ymax=ymax\n",
    "                                                  )\n",
    "            kount += nruns #self.nrun\n",
    "\n",
    "    def hist(self,data,\n",
    "             log_scale_x,log_scale_y,\n",
    "             n_bins_per_decade=6,\n",
    "             col_x = 0, col_y = 1,\n",
    "             n_thresh=0,\n",
    "                   ymin=-sys.maxsize,ymax=sys.maxsize\n",
    "            ):\n",
    "        n_thresh = n_thresh\n",
    "#         pdb.set_trace()\n",
    "            #--- average\n",
    "        xdata = data[:,col_x]\n",
    "        ydata = data[:,col_y]\n",
    "        filtr = np.all([ydata>=ymin,ydata<ymax],axis=0)\n",
    "        xdata = xdata[filtr]\n",
    "        ydata = ydata[filtr]\n",
    "        if log_scale_x:\n",
    "            xmin = np.floor(np.log10(xdata).min())\n",
    "            xmax = np.ceil(np.log10(xdata).max())\n",
    "            n_decades = int((xmax - xmin))\n",
    "            bins = np.logspace(xmin,xmax,n_decades*n_bins_per_decade)\n",
    "        else:\n",
    "            xmin = xdata.min()*0.999\n",
    "            xmax = xdata.max()*1.001\n",
    "            bins = np.linspace(xmin,xmax,n_bins_per_decade)\n",
    "            \n",
    "        #\n",
    "        count, _    = np.histogram(xdata,bins=bins)\n",
    "        xsum, _     = np.histogram(xdata,bins=bins,weights=xdata)\n",
    "        weights     = ydata if not log_scale_y else np.log10(ydata)\n",
    "        if log_scale_y and np.any(ydata == 0.0):\n",
    "            print('data has a zero component!')\n",
    "            return\n",
    "        ysum, _     = np.histogram(xdata,bins=bins,weights=weights)\n",
    "        ysum_sq, _  = np.histogram(xdata,bins=bins,weights=weights*weights)\n",
    "        #\n",
    "        xsum = xsum[count>n_thresh]\n",
    "        ysum = ysum[count>n_thresh]\n",
    "        ysum_sq = ysum_sq[count>n_thresh]\n",
    "        count = count[count>n_thresh]\n",
    "        #\n",
    "        xsum /= count\n",
    "        ysum /= count\n",
    "        ysum_sq /= count\n",
    "        assert np.all(ysum_sq - ysum * ysum >= 0.0), 'variance < 0.0!'\n",
    "        std = np.sqrt((ysum_sq - ysum * ysum)/count)\n",
    "        if log_scale_y:\n",
    "            ysum = 10 ** ysum\n",
    "            std = 0.5 * ysum * (1+2*std*np.log(10))\n",
    "        return np.c_[xsum,ysum,std]\n",
    "        \n",
    "        \n",
    "#            utl.PltErr(xsum,ysum,ax=self.ax)\n",
    "            \n",
    "\n",
    "    def PlotAverage(self,rescale=False,**kwargs):\n",
    "#        print(list(self.temps_runs))\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "        for temp, count in zip(self.temps,range(len(self.temps))): \n",
    "            data = self.data_averaged[ temp ]\n",
    "            xdata = data[:,0]\n",
    "            ydata = data[:,1]\n",
    "            yerr = data[:,2]\n",
    "            if rescale:\n",
    "                ydata /= xdata\n",
    "                yerr /= xdata\n",
    "            utl.PltErr(xdata,ydata,\n",
    "                   yerr=yerr,\n",
    "                   ax = self.ax,\n",
    "                   attrs=symbols.GetAttrs(count=count%7 if not 'count' in kwargs else kwargs['count'],label=r'$%s$'%temp,nevery=1),\n",
    "                   Plot=False,\n",
    "                  )\n",
    "\n",
    "        utl.PltErr(None,\n",
    "                   None, \n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "#                    legend=legends.Get(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "        \n",
    "        \n",
    "    def func2nd(self,x,y0,c0,alpha):\n",
    "#        return y0+c0*(x/x0)**alpha\n",
    "        return y0*y0+c0*x**alpha\n",
    "\n",
    "    def func3rd(self,x,c0,alpha):\n",
    "         return c0*x**alpha\n",
    "\n",
    "    def Fit(self,Plot=None,\n",
    "            shift = False,\n",
    "#             SIGMA=False,\n",
    "            plotAttrs=None,\n",
    "            bounds=(-np.inf, np.inf),\n",
    "            xlo=float('-inf'),xhi=float('inf'),\n",
    "            **kwargs):\n",
    "        self.Diffusion = {}\n",
    "        self.exponent = {}\n",
    "        pref=1e-10*1e-10 #--- ang^2 to m^2\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=plotAttrs['bbox_to_anchor'] if 'bbox_to_anchor' in plotAttrs\n",
    "                    else (1.0,0.5,0.5,0.5),\n",
    "                   fontsize=18,\n",
    "                   )\n",
    "\n",
    "        if Plot:\n",
    "            ax = utl.PltErr(None,None,\n",
    "                            Plot=False)\n",
    "        #\n",
    "        for temp, count in zip(self.temps,range(len(self.temps))): \n",
    "            nruns = len(self.nrun[count])\n",
    "\n",
    "            self.smat = smat = self.data_averaged[ temp ] if nruns > 1 else self.data[count]\n",
    "\n",
    "            xdata=smat[:,0]\n",
    "            ydata=smat[:,1]\n",
    "            yerr = smat[:,2]\n",
    "#             print(smat)\n",
    "\n",
    "        \n",
    "            #--- set limits:\n",
    "            if self.verbose:\n",
    "                print('limits:',xlo,xhi)\n",
    "\n",
    "            filtr = np.ones(xdata.shape[0],dtype=bool)\n",
    "            filtr = np.all([filtr,xdata > xlo],axis=0)\n",
    "            filtr = np.all([filtr,xdata <= xhi],axis=0)\n",
    "            assert np.any(filtr), 'empty arrays!'\n",
    "            if self.verbose:\n",
    "                print('filtr=',filtr)\n",
    "            \n",
    "            #--- error in y\n",
    "            if 'sigma' in kwargs:\n",
    "                kwargs['sigma'] = 2*yerr[filtr]\n",
    "\n",
    "            #--- fit\n",
    "#             print(kwargs)\n",
    "            popt, pcov = curve_fit(self.func2nd, xdata[filtr], ydata[filtr],\n",
    "                                   bounds=bounds, #([1e-1, 1e5,0.5], [1e0, 1e7,2.0]), #[(4e-3, 1e5,0.5), (1e-2, 1e7,2.0)],#bounds,\n",
    "                                    **kwargs\n",
    "                                    )\n",
    "            self.popt = popt\n",
    "            self.pcov = pcov\n",
    "            self.filtr = filtr\n",
    "            #--- uncertainties\n",
    "            if self.verbose:\n",
    "                print('Temp=%s,y0,c0,alpha'%temp,list(popt),pcov)\n",
    "                print('alpha=%s'%popt[2])\n",
    "            y0=popt[0]\n",
    "            alpha=popt[2]\n",
    "            err_alpha = pcov[2,2]**0.5\n",
    "            c0=popt[1]\n",
    "            dc = pcov[1,1]**0.5\n",
    "            tau=1#popt[0]\n",
    "            dtau=0#pcov[0,0]**0.5\n",
    "            self.time_scale = tau * (y0/c0)**(1/alpha)\n",
    "            if self.verbose:\n",
    "                print('Temp=%s,tau=%s'%(temp,self.time_scale))\n",
    "                print('err_alpha=%s'%err_alpha)\n",
    "#             self.Diffusion[temp] = [pref*c0/tau,pref*c0/tau,pref*c0/tau]\n",
    "            self.Diffusion[temp] = [pref*c0/(tau)**alpha, pref*(c0+dc)/(tau-dtau)**alpha, \n",
    "                                    pref*(c0-dc)/(tau+dtau)**alpha]\n",
    "            self.exponent[temp] = [alpha,alpha+err_alpha,alpha-err_alpha]\n",
    "            if Plot:\n",
    "                #---fit\n",
    "                y0=0 #kam\n",
    "                xdata_shift = xdata*20**count if shift else xdata\n",
    "                utl.PltErr(xdata_shift,\n",
    "                                (self.func2nd(xdata,*popt)-y0),#-y0)/xdata_shift,\n",
    "                                attrs={'fmt':'-.','color':symbols.colors[count%7],\\\n",
    "                                       'label':r'$\\alpha=%3.2f$'%popt[2]},\n",
    "                           Plot=False,ax=ax)\n",
    "                #--- points\n",
    "#                temp= [1000,1200,1400,1600,1800,2000][count]\n",
    "                utl.PltErr(xdata_shift,\n",
    "                           (ydata-y0),#-y0)/xdata_shift,\n",
    "                           yerr=(yerr),#-y0),#/xdata_shift,\n",
    "#                           attrs=symbols.GetAttrs(count=count%7,label=r'$%s$'%temp,fmt='.'),\n",
    "                           attrs=symbols.GetAttrs(count=count%7,fmt='.'),\n",
    "                           ax=ax,\n",
    "                           Plot=False,\n",
    "                          )\n",
    "        if Plot:\n",
    "            utl.PltErr(None,\n",
    "                       None, \n",
    "                       ax=ax,\n",
    "                       Plot=False,\n",
    "                         legend=legends.Get(),\n",
    "                       DrawFrame=DRAW_FRAME,\n",
    "                       **plotAttrs\n",
    "                      )\n",
    "\n",
    "    def FitLinear(self,Plot=None,\n",
    "            shift = False,\n",
    "#             SIGMA=False,\n",
    "            plotAttrs=None,\n",
    "            y0=0.0,\n",
    "            bounds=(-np.inf, np.inf),\n",
    "            xlo=float('-inf'),xhi=float('inf'),\n",
    "            **kwargs):\n",
    "        self.Diffusion = {}\n",
    "        self.exponent = {}\n",
    "        pref=1e-10*1e-10 #--- ang^2 to m^2\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=plotAttrs['bbox_to_anchor'] if 'bbox_to_anchor' in plotAttrs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "\n",
    "        if Plot:\n",
    "            ax = utl.PltErr(None,None,\n",
    "                            Plot=False)\n",
    "        #\n",
    "        for temp, count in zip(self.temps,range(len(self.temps))): \n",
    "            nruns = len(self.nrun[count])\n",
    "            self.smat = smat = self.data_averaged[ temp ] if nruns > 1 else self.data[count]\n",
    "\n",
    "            xdata=smat[:,0]\n",
    "            ydata=smat[:,1] - y0*y0\n",
    "            yerr = smat[:,2]\n",
    "#             print(smat)\n",
    "\n",
    "        \n",
    "            #--- set limits:\n",
    "            if self.verbose:\n",
    "                print('limits:',xlo,xhi)\n",
    "\n",
    "            filtr = np.ones(xdata.shape[0],dtype=bool)\n",
    "            filtr = np.all([filtr,xdata > xlo],axis=0)\n",
    "            filtr = np.all([filtr,xdata <= xhi],axis=0)\n",
    "            assert np.any(filtr), 'empty arrays!'\n",
    "            if self.verbose:\n",
    "                print('filtr=',filtr)\n",
    "            \n",
    "            #--- error in y\n",
    "            if 'sigma' in kwargs:\n",
    "                kwargs['sigma'] = 2*yerr[filtr]\n",
    "\n",
    "            #--- fit\n",
    "#             print(kwargs)\n",
    "            popt, pcov = curve_fit(self.func3rd, xdata[filtr], ydata[filtr],\n",
    "                                   bounds=bounds, #([1e-1, 1e5,0.5], [1e0, 1e7,2.0]), #[(4e-3, 1e5,0.5), (1e-2, 1e7,2.0)],#bounds,\n",
    "                                    **kwargs\n",
    "                                    )\n",
    "            self.popt = popt\n",
    "            self.filtr = filtr\n",
    "            #--- uncertainties\n",
    "            if self.verbose:\n",
    "                print('Temp=%s,y0,c0,alpha'%temp,list(popt),pcov)\n",
    "#            y0=popt[0]\n",
    "            alpha=popt[1]\n",
    "            err_alpha = pcov[1,1]**0.5\n",
    "            c0=popt[0]\n",
    "            dc = pcov[0,0]**0.5\n",
    "            tau=1#popt[0]\n",
    "            dtau=0#pcov[0,0]**0.5\n",
    "#            self.time_scale = tau * (y0/c0)**(1/alpha)\n",
    "#            if self.verbose:\n",
    "#                print('Temp=%s,tau=%s'%(temp,self.time_scale))\n",
    "#             self.Diffusion[temp] = [pref*c0/tau,pref*c0/tau,pref*c0/tau]\n",
    "            self.Diffusion[temp] = [pref*c0/(tau)**alpha, pref*(c0+dc)/(tau-dtau)**alpha, \n",
    "                                    pref*(c0-dc)/(tau+dtau)**alpha]\n",
    "            self.exponent[temp] = [alpha,alpha+err_alpha,alpha-err_alpha]\n",
    "            if Plot:\n",
    "                #---fit\n",
    "#                y0=0 #kam\n",
    "                xdata_shift = xdata*20**count if shift else xdata\n",
    "                utl.PltErr(xdata_shift,\n",
    "                                self.func3rd(xdata,*popt),\n",
    "                                attrs={'fmt':'-.','color':symbols.colors[count%7]},\n",
    "                           Plot=False,ax=ax)\n",
    "                #--- points\n",
    "#                temp= [1000,1200,1400,1600,1800,2000][count]\n",
    "                utl.PltErr(xdata_shift,\n",
    "                           ydata,\n",
    "                           yerr=yerr,\n",
    "                           attrs=symbols.GetAttrs(count=count%7,label=r'$%s$'%temp,fmt='.'),\n",
    "                           ax=ax,\n",
    "                           Plot=False,\n",
    "                          )\n",
    "        if Plot:\n",
    "            utl.PltErr(None,\n",
    "                       None, \n",
    "                       ax=ax,\n",
    "                       Plot=False,\n",
    "#                       legend=legends.Get(),\n",
    "                       DrawFrame=DRAW_FRAME,\n",
    "                       **plotAttrs\n",
    "                      )\n",
    "            \n",
    "    def PlotDiff(self,**kwargs):\n",
    "        symbols=utl.Symbols()\n",
    "        utl.PltErr(1.0/np.array(self.temps),\n",
    "                   list(map(lambda x:self.Diffusion[x][0],self.temps)),\n",
    "                   yerr=list(map(lambda x:(self.Diffusion[x][1]-self.Diffusion[x][2])/2,self.temps)),\n",
    "                   attrs=symbols.GetAttrs(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "\n",
    "    def PlotExponent(self,**kwargs):\n",
    "        symbols=utl.Symbols()\n",
    "        ax=utl.PltErr([0.5e-3,1e-3],[1,1],attrs={'fmt':'-.r'},Plot=False)\n",
    "        utl.PltErr(1.0/np.array(self.temps),\n",
    "                   list(map(lambda x:self.exponent[x][0],self.temps)),\n",
    "                   yerr=list(map(lambda x:1.0*(self.exponent[x][1]-self.exponent[x][2]),self.temps)),\n",
    "                   attrs=symbols.GetAttrs(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   ax=ax,\n",
    "                   **kwargs\n",
    "                  )\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    if eval(confParser['flags']['RemoteMachine']):\n",
    "        return\n",
    "    !mkdir png\n",
    "    #--- temp object\n",
    "    temp = Temperature(\n",
    "        [1000],[list(range(8))]*10,\n",
    "#          verbose = True,\n",
    "                     )\n",
    "    #\n",
    "    #--- parse data\n",
    "#    temp.Parse(['./msd/msd.txt']) \n",
    "#    temp.Parse( list(map(lambda x:'ni/void5th/Run%s/msd/msd.txt'%(x[1]),\n",
    "    temp.Parse( list(map(lambda x:'ni/kmc/void_2d/Run%s/msd/msd_vac_cna.txt'%(x[1]),\n",
    "#    temp.Parse( list(map(lambda x:'ni/pure/Run%s/msd/msd_vac_cna.txt'%(x[1]),\n",
    "#    temp.Parse( list(map(lambda x:'ni/mlmc/latest_void5th/Run%s/msd/msd_vac_cna.txt'%(x[1]),\n",
    "                         temp.temps_runs ))\n",
    "             )\n",
    "    #\n",
    "    #--- plot\n",
    "    xlim = (1e0,1e6)\n",
    "#     xlim = (1e-10,1e-6)\n",
    "    ylim = (1e-1,1e3)\n",
    "    print('single realizations')\n",
    "    temp.Plot(**{\n",
    "                  'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "                   'attrs':{'fmt':'-'},\n",
    "                  'xlim':xlim,\n",
    "                     'ylim':ylim,\n",
    "                   'title':'png/msd_temp_ni.png',\n",
    "                    'xstr':r'$t(\\mathrm{s})$','ystr':r'$\\mathrm{msd}(\\r{A}^2)$',\n",
    "        'bbox_to_anchor':(0.01,0.3,0.5,0.5)\n",
    "    })\n",
    "    \n",
    "    #\n",
    "    #--- plot average\n",
    "    #\n",
    "    print('ensemble average')\n",
    "    temp.EnsAverage(log_scale_x=True,log_scale_y=True,\n",
    "                   n_thresh=2,\n",
    "                    n_bins_per_decade=4,#32,\n",
    "#                     ymin=1e-3,\n",
    "                   )\n",
    "    temp.PlotAverage(**{\n",
    "                  'yscale':'log',\n",
    "                  'xscale':'log',\n",
    "#                   'count':0,\n",
    "                   'xlim':xlim,\n",
    "                     'ylim':ylim,\n",
    "                    'xstr':r'$t(\\mathrm{s})$','ystr':r'$\\mathrm{msd}(\\r{A}^2)$',\n",
    "                    'title':'png/msd_temp_ni_T%sK.png'%temp.temps[0],\n",
    "         })\n",
    "\n",
    "    #\n",
    "    #--- fit\n",
    "    #\n",
    "    temp.Fit(Plot=True,\n",
    "#              shift=True,\n",
    "#             bounds=([4e-3, 1e5,0.5], [1e-2, 1e7,2.0]),\n",
    "#            p0=[[1e-4, 1e6, 1.0]],\n",
    "            p0=[[1e-1, 1e6, 1.5]],\n",
    "               sigma=True, #--- comment for ni\n",
    "              xlo=xlim[0],\n",
    "             plotAttrs={'yscale':'log',\n",
    "                  'xscale':'log',\n",
    "                   'xlim':xlim,\n",
    "                      'ylim':ylim,\n",
    "                        'ndecade_x':1,\n",
    "                    'bbox_to_anchor':(-0.05,0.33,0.5,0.5),\n",
    "                   'title':'png/msd_temp_ni_fit_inset.png',\n",
    "                    'xstr':r'$t(\\mathrm{s})$','ystr':r'$\\mathrm{msd}(\\r{A}^2)$',\n",
    "#                         'fontsize':24,\n",
    "#              'halfopen':True\n",
    "                       }\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "    temp.PlotExponent(**{\n",
    "                    'title':'png/alpha_temp_ni.png',\n",
    "                    'ylim':(0.5,1.5),\n",
    "                    }\n",
    "                )\n",
    "    \n",
    "    return temp\n",
    "temp = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vacancy dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: png: File exists\n",
      "Parsing: 2 data.shape is: (19, 3)\n",
      "single realizations\n",
      "ensemble average\n",
      "data.shape: (1, 19, 3)\n",
      "data has a zero component!\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    #--- temp object\n",
    "    temp_vac = Temperature(\n",
    "#        [1000,1200,1400,1600,1800,2000],[[8,7,6,5,4,1,0],list(range(8)),list(range(8)),list(range(8)),list(range(8)),list(range(8))],\n",
    "        [1000],[list(range(2,3))]*100,\n",
    "         verbose = True,\n",
    "                     )\n",
    "    #\n",
    "    #--- parse data\n",
    "#    temp_vac.Parse(['./msd/msd_vac.txt'])\n",
    "#    temp_vac.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/msd_vac.txt'%(x[0],x[1]),\n",
    "#    temp_vac.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/msd_vac.txt'%(x[0],x[1]),\n",
    "#    temp_vac.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/msd_vac.txt'%(x[0],x[1]),\n",
    "#    temp_vac.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/msd_vac_cna.txt'%(x[0],x[1]),\n",
    "    temp_vac.Parse( list(map(lambda x:'msd_definition/ni/temp0/Run%s/msd/msd_vac_ws.txt'%(x[1]),\n",
    "                          temp_vac.temps_runs ))\n",
    "              )\n",
    "    #\n",
    "    #--- plot\n",
    "    print('single realizations')\n",
    "    temp_vac.Plot(**{\n",
    "                  'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "                   'attrs':{'fmt':'-'},\n",
    "#                   'xlim':(1e-10,1e-3),\n",
    "#                    'ylim':(1e-5,1e-1),\n",
    "#                   'xstr':r'$t\\mathrm{(s)}$',\n",
    "#                   'ystr':r'msd(A$^2$)',\n",
    "#                   'title':'png/msd_temp_ni.png',\n",
    "        'bbox_to_anchor':(0.01,0.3,0.5,0.5)\n",
    "    })\n",
    "    #\n",
    "    #--- plot average\n",
    "    #\n",
    "#    if len(temp_vac.nrun[0]) > 1:\n",
    "    print('ensemble average')\n",
    "#     pdb.set_trace()\n",
    "    temp_vac.EnsAverage(log_scale_x=True,log_scale_y=True,n_bins_per_decade=4)#,n_thresh=1)\n",
    "    #\n",
    "    print(temp_vac.data_averaged[1000])\n",
    "    #--- fit\n",
    "#     n=len(temp_vac.data_averaged[1000][:,2])\n",
    "#     temp_vac.data_averaged[1000][:,2] = np.random.normal(size=n)\n",
    "#     temp_vac.Fit(Plot=True,\n",
    "#              shift=False,\n",
    "# #             bounds=(np.array([-np.inf, -np.inf,0]), np.array([np.inf, np.inf,np.inf])),\n",
    "# #            p0=[[1e0, 1e6, 1.0]],\n",
    "#              p0=[[0.4, 1e6, 1.1]],\n",
    "# #             p0=[[-1, 1e6, 1.0]],\n",
    "#              sigma=True, #--- comment for ni\n",
    "# #               xlo=1e-10,\n",
    "#              plotAttrs={'yscale':'log',\n",
    "#                   'xscale':'log',\n",
    "# #                   'xlim':(4e-13,8e-4),\n",
    "# #                    'ylim':(1e-1,1e4),\n",
    "# #                     'xstr':r'$t\\mathrm{(s)}$',\n",
    "# #                   'ystr':r'msd(A$^2$)',\n",
    "#                         'ndecade_x':1,\n",
    "#                     'bbox_to_anchor':(-0.05,0.4,0.5,0.5),\n",
    "#                    'title':'png/msd_temp_ni_fit_vac_cna.png'},\n",
    "#             )\n",
    "    \n",
    "#     temp_vac.FitLinear(Plot=True,\n",
    "#              shift=True,\n",
    "# #             bounds=([4e-3, 1e5,0.5], [1e-2, 1e7,2.0]),\n",
    "#             p0=[[1e6, 1.0]],\n",
    "# #             sigma=True, #--- comment for ni\n",
    "# #             xlo=1e-12,\n",
    "#              y0 = 0.7,\n",
    "#              plotAttrs={'yscale':'log',\n",
    "#                   'xscale':'log',\n",
    "# #                   'xlim':(4e-13,8e-4),\n",
    "# #                   'ylim':(1e-6,1e-2),\n",
    "# #                     'xstr':r'$t\\mathrm{(s)}$',\n",
    "# #                   'ystr':r'msd(A$^2$)',\n",
    "#                         'ndecade_x':2,\n",
    "#                     'bbox_to_anchor':(-0.05,0.23,0.5,0.5),\n",
    "#                    'title':'png/msd_temp_cantor_fit.png'},\n",
    "#             )\n",
    "\n",
    "\n",
    "#     temp.PlotDiff(**{\n",
    "#                   'yscale':'log',\n",
    "# #                   'xlim':(1e-12,1e-3),\n",
    "# #                   'ylim':(1e-4,1e-1),\n",
    "# #                   xstr=r'$1/T(K^{-1})$',\n",
    "# #                   ystr=r'$D(m^2/s)$',\n",
    "#                     'title':'png/D_temp_cantor.png',\n",
    "#                     }\n",
    "#                 )\n",
    "\n",
    "#     temp_vac.PlotExponent(**{\n",
    "# #                  'yscale':'log',\n",
    "# #                   'xlim':(1e-10,1e-3),\n",
    "# #                   'ylim':(.9,1.6),\n",
    "# #                   xstr=r'$1/T(K^{-1})$',\n",
    "# #                   ystr=r'$D(m^2/s)$',\n",
    "#                     'title':'png/alpha_temp_ni_vac_cna.png',\n",
    "#                     }\n",
    "#                 )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing: 0 data.shape is: (500404, 4)\n",
      "Parsing: 1 data.shape is: (500395, 4)\n",
      "Parsing: 2 data.shape is: (500400, 4)\n",
      "Parsing: 3 data.shape is: (500393, 4)\n",
      "Parsing: 4 data.shape is: (500395, 4)\n",
      "Parsing: 5 data.shape is: (500408, 4)\n",
      "Parsing: 6 data.shape is: (500388, 4)\n",
      "Parsing: 7 data.shape is: (500387, 4)\n",
      "ensemble average\n",
      "data.shape: (4003170, 4)\n",
      "count= [     32      37      59     124    1853    2031    5644    7545   13382\n",
      "   23326   43881   74796  129898  223353  382742  625406  932991 1102916\n",
      "  433154]\n",
      "16\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.22466465e-04  2.89192802e+09  9.86590352e-01]\n"
     ]
    }
   ],
   "source": [
    "# temp_vac = Temperature(\n",
    "#     [1000],[[0,1,2,3,4,5,6,7]]*100,\n",
    "#      verbose = True,\n",
    "#                  )\n",
    "#     #\n",
    "#     #--- parse data\n",
    "# temp_vac.Parse( list(map(lambda x:'msd_definition/ni/temp0/Run%s/msd/msd_vac_cna.txt'%(x[1]),\n",
    "#                           temp_vac.temps_runs ))\n",
    "#               )\n",
    "#     #\n",
    "#     #\n",
    "#     #--- plot average\n",
    "#     #\n",
    "# #    if len(temp_vac.nrun[0]) > 1:\n",
    "# print('ensemble average')\n",
    "# temp_vac.EnsAverage2nd(log_scale_x=True,log_scale_y=True,n_bins_per_decade=4,n_thresh=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.07659371e-01 3.90878188e+07 7.50675593e-01]\n"
     ]
    }
   ],
   "source": [
    "xdata = temp_vac.data[0][:,0]\n",
    "ydata = temp_vac.data[0][:,1]\n",
    "filtr = xdata < 1e-7\n",
    "xdata = xdata[filtr]\n",
    "ydata = ydata[filtr]\n",
    "print(len(xdata))\n",
    "ax = utl.PltErr(None,None,Plot=False)\n",
    "utl.PltErr(xdata,ydata,\n",
    "           attrs={'fmt':'o','color':'black'},\n",
    "          xscale='log',yscale='log',\n",
    "           ax=ax,\n",
    "           Plot=False\n",
    "          )\n",
    "\n",
    "popt, pcov = curve_fit(temp_vac.func2nd, xdata, ydata,\n",
    "             p0=[[0.4, 1e5, 1.1]],\n",
    "                       ftol=1e-10, xtol=1e-10, gtol=1e-10,\n",
    "                       maxfev=10000,\n",
    "                        )\n",
    "\n",
    "utl.PltErr(xdata,temp_vac.func2nd(xdata,*popt),\n",
    "           attrs={'fmt':'-.','color':'red'},\n",
    "          xscale='log',yscale='log',\n",
    "           ax=ax\n",
    "          )\n",
    "\n",
    "print(popt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.00000000e-11, 0.00000000e+00, 0.00000000e+00],\n",
       "        [2.85000000e-11, 2.04931192e+00, 0.00000000e+00],\n",
       "        [4.00000000e-11, 0.00000000e+00, 0.00000000e+00],\n",
       "        [7.50000000e-11, 1.92122909e+00, 0.00000000e+00],\n",
       "        [1.00575221e-10, 2.39031482e+00, 0.00000000e+00],\n",
       "        [2.02163265e-10, 3.01946083e+00, 0.00000000e+00],\n",
       "        [4.01056748e-10, 3.71151316e+00, 0.00000000e+00],\n",
       "        [7.44284582e-10, 5.60760383e+00, 0.00000000e+00],\n",
       "        [1.29029072e-09, 7.92977762e+00, 0.00000000e+00],\n",
       "        [2.25345808e-09, 1.24852060e+01, 0.00000000e+00],\n",
       "        [3.94251008e-09, 1.82158734e+01, 0.00000000e+00],\n",
       "        [6.93401101e-09, 2.93748489e+01, 0.00000000e+00],\n",
       "        [1.22452632e-08, 4.31953322e+01, 0.00000000e+00],\n",
       "        [2.15753004e-08, 6.95641679e+01, 0.00000000e+00],\n",
       "        [3.80103118e-08, 1.09020908e+02, 0.00000000e+00],\n",
       "        [6.67490546e-08, 1.58993667e+02, 0.00000000e+00],\n",
       "        [1.16817108e-07, 2.57563848e+02, 0.00000000e+00],\n",
       "        [2.02287979e-07, 2.92316096e+02, 0.00000000e+00],\n",
       "        [3.22748015e-07, 1.78426135e+02, 0.00000000e+00]])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_vac.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('msd/msd_cna.txt',np.c_[temp_vac.data_averaged[1000]])\n",
    "# np.savetxt('msd/msd_cna_opt.txt',np.c_[temp_vac.popt])\n",
    "# np.savetxt('msd/msd_cna_cov.txt',np.c_[temp_vac.pcov])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    symbols=utl.Symbols()\n",
    "    legends = Legends()\n",
    "    legends.Set(bbox_to_anchor=(0.1,0.5,0.5,0.5))\n",
    "    #\n",
    "    ax=utl.PltErr([0.5e-3,1e-3],[1,1],attrs={'fmt':'-.r'},Plot=False)\n",
    "    utl.PltErr(1.0/np.array(temp.temps),\n",
    "               list(map(lambda x:temp.exponent[x][0],temp.temps)),\n",
    "               yerr=list(map(lambda x:1.0*(temp.exponent[x][1]-temp.exponent[x][2]),temp.temps)),\n",
    "               attrs=symbols.GetAttrs(count=0,label=r'$\\mathrm{Total}$'),\n",
    "               ax=ax,\n",
    "               Plot=False,\n",
    "    #           **kwargs\n",
    "              )\n",
    "\n",
    "    utl.PltErr(1.0/np.array(temp_vac.temps),\n",
    "               list(map(lambda x:temp_vac.exponent[x][0],temp_vac.temps)),\n",
    "               yerr=list(map(lambda x:1.0*(temp_vac.exponent[x][1]-temp_vac.exponent[x][2]),temp_vac.temps)),\n",
    "               attrs=symbols.GetAttrs(count=1,label=r'$\\mathrm{Vacancy}$'),\n",
    "               DrawFrame=DRAW_FRAME,\n",
    "               ax=ax,\n",
    "                       ylim=(.5,1.5),\n",
    "#               halfopen=True,\n",
    "#               legend=legends.Get(),\n",
    "                        title='png/alpha_temp_cantor.png',\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Robustness(Temperature):\n",
    "    \n",
    "    def __init__(self,temp_range,nrun,verbose=False):\n",
    "        Temperature.__init__(self,temp_range,nrun,verbose=verbose)\n",
    "\n",
    "    def FitRange(self,decades=9):\n",
    "        self.Fit(Plot=False,shift=False,\n",
    "                    p0=[[1e-2, 1e6, 1.0]],\n",
    "                 sigma=True, #--- comment for ni\n",
    "                     plotAttrs={'bbox_to_anchor':(-0.05,0.23,0.5,0.5)}\n",
    "                )\n",
    "\n",
    "        self.xlo = np.floor(np.log2(self.smat[:,0].min()))\n",
    "        xhii = np.ceil(np.log2(self.smat[:,0].max()))\n",
    "        self.xrange = 2**np.arange(xhii+1,xhii-decades,-1)\n",
    "        \n",
    "    def Fitting(self):\n",
    "        #--- bounds\n",
    "        self.exponents = np.zeros(len(self.xrange))\n",
    "        self.error = np.zeros(len(self.xrange))\n",
    "        self.npoin = np.zeros(len(self.xrange))\n",
    "        \n",
    "        npoint_filtrd0 = self.smat.shape[0]\n",
    "        for xhi, indx in zip(self.xrange,range(len(self.xrange))):\n",
    "            self.Fit(Plot=True,\n",
    "                     shift=False,\n",
    "        #             bounds=([0, 0, 0,0.999], [1e-2, 1e-3, 1,1.001]),\n",
    "                        p0=[[1e-2, 1e6, 1.0]],\n",
    "                     sigma=True, #--- comment for ni\n",
    "                     xlo=2**self.xlo,xhi=xhi,\n",
    "                     plotAttrs={'yscale':'log',\n",
    "                          'xscale':'log',\n",
    "        #                   'xlim':(4e-13,8e-4),\n",
    "        #                   'ylim':(1e-4,1e-1),\n",
    "        #                     'xstr':r'$t\\mathrm{(s)}$',\n",
    "        #                   'ystr':r'msd(A$^2$)',\n",
    "                                'ndecade_x':2,\n",
    "                            'bbox_to_anchor':(-0.05,0.23,0.5,0.5),\n",
    "    #                       'title':'png/msd_temp_nicocr_fit.png'\n",
    "                               },\n",
    "                    )\n",
    "            \n",
    "            #--- check if decrease in tc leads to fewere points\n",
    "#             npoint_filtrd = np.sum(self.filtr)\n",
    "#             if self.verbose:\n",
    "#                 print('npoint_filtrd=',npoint_filtrd)\n",
    "#             #if indx > 0:\n",
    "#             if npoint_filtrd == npoint_filtrd0 and indx > 0:\n",
    "#                 continue\n",
    "# #                    , '%s >= %sdecrease ndecades!'%(npoint_filtrd,npoint_filtrd0)\n",
    "#             npoint_filtrd0 = npoint_filtrd\n",
    "            \n",
    "            #--- assign\n",
    "            self.npoin[indx] = np.sum(self.filtr)\n",
    "            if self.npoin[indx] == self.npoin[indx-1] and indx > 0:\n",
    "                continue\n",
    "            self.exponents[indx] = self.popt[-1]\n",
    "            x = self.temps[ 0 ]\n",
    "            self.error[indx] = 0.5*(self.exponent[x][1]-self.exponent[x][2])\n",
    "        \n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "\n",
    "    symbols = utl.Symbols()\n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "\n",
    "    temps = [1200] #[1000,1200,1400,1600,1800,2000]\n",
    "    indices = [1] #range(10)\n",
    "    for temperature, indx in zip(temps,indices):\n",
    "        try:\n",
    "            rb = Robustness([temperature],8,\n",
    "#                            verbose = True\n",
    "\n",
    "                            )\n",
    "\n",
    "            #--- parse data\n",
    "#            rb.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "            rb.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "#            rb.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "                                rb.temps_runs ))\n",
    "                     )\n",
    "\n",
    "            #--- plot average\n",
    "            if rb.nrun > 1:\n",
    "                print('ensemble average')\n",
    "                rb.EnsAverage(log_scale=False,n_bins_per_decade=4)\n",
    "#                 rb.PlotAverage(**{\n",
    "#                           'yscale':'log',\n",
    "#                           'xscale':'log',\n",
    "#         #                   'xlim':(1e-10,1e-3),\n",
    "#         #                   'ylim':(1e-4,1e-1),\n",
    "#         #                     'xstr':r'$t\\mathrm{(s)}$',\n",
    "#         #                   'ystr':r'msd(A$^2$)',\n",
    "# #                            'title':'png/msd_temp_cantor.png',\n",
    "#                 })\n",
    "            #\n",
    "            #--- fit\n",
    "            #\n",
    "            rb.FitRange(decades=10)\n",
    "            rb.Fitting()\n",
    "\n",
    "\n",
    "            #--- get data\n",
    "            filtr = np.all([rb.exponents>0,rb.exponents<2],axis=0)\n",
    "            utl.PltErr(rb.xrange[filtr],rb.exponents[filtr],yerr=rb.error[filtr],\n",
    "                       attrs=symbols.GetAttrs(count=indx%7),\n",
    "                       ax=ax,\n",
    "                        Plot=False,\n",
    "                      )\n",
    "        except:\n",
    "            print('increase fit range!')\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "\n",
    "    utl.PltErr(ax.axis()[:2],[1,1],Plot=False,ax=ax,\n",
    "                attrs={'fmt':'-.','color':'red'},\n",
    "                       ylim=(0,2),\n",
    "                      xscale='log',\n",
    "                       DrawFrame=DRAW_FRAME,\n",
    "                       title='png/exponentH_ni_T%sK.png'%temperature,\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### per type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "    symbols=utl.Symbols()\n",
    "    legends = Legends()\n",
    "    legends.Set(bbox_to_anchor=(1.0,0.5,0.5,0.5))\n",
    " \n",
    "                       \n",
    "    ntype = 5\n",
    "    for itype in range(1,ntype+1):\n",
    "        temp = Temperature(#[1000],3\n",
    "                           list(map(int,np.linspace(1000,1400,11))),3\n",
    "                          )\n",
    "        temp.Parse( list(map(lambda x:'CantorNatom16KTemp%sK_ensemble/Run%s/msd/msd_type%s.txt'%(x[0],x[1],itype),\n",
    "                            temp.temps_runs ))\n",
    "                  )\n",
    "        #\n",
    "  #      print('single realizations')\n",
    "  #      temp.Plot()\n",
    "        #\n",
    "        print('ensemble average: type %s'%itype)\n",
    "        temp.EnsAverage()\n",
    "#         temp.PlotAverage()\n",
    "#         #\n",
    "        temp.Fit(#Plot=True,\n",
    "        #         verbose=True\n",
    "        )\n",
    "#         temp.PlotDiff()\n",
    "        \n",
    "        #--- plot\n",
    "        utl.PltErr(1/np.array(list(temp.Diffusion.keys())),\n",
    "                   list(map(lambda x:temp.Diffusion[x],list(temp.Diffusion.keys()))),\n",
    "                       Plot=False,\n",
    "                   ax=ax,\n",
    "                   attrs=symbols.GetAttrs(count=(itype-1)%7,label=r'$%s$'%temp),\n",
    "                 )\n",
    "    utl.PltErr(None,None,\n",
    "               ax=ax,\n",
    "               yscale='log',\n",
    "               ylim=(1e-15,1e-11),\n",
    "              xstr=r'$1/T(K^{-1})$',\n",
    "              ystr=r'$D(m^2/s)$',\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tauu = temp.time_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## correlated noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Noise(Temperature):\n",
    "    def __init__(self,temp_range,nrun,verbose=False):\n",
    "        Temperature.__init__(self,temp_range,nrun)\n",
    "        self.verbose = verbose\n",
    "    #\n",
    "    def PlotNoise(self, col_a = 1, col_b=1,\n",
    "                  **kwargs):\n",
    "        #\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=(1.0,0.5,0.5,0.5))\n",
    "        #\n",
    "        self.crltns_mean_ab = {}\n",
    "        self.crltns_mean_ba = {}\n",
    "        self.crltns_err_ab = {}\n",
    "        self.crltns_err_ba = {}\n",
    "        kount = 0\n",
    "        #\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp\n",
    "            data = self.data[kount:kount+self.nrun]\n",
    "            if self.verbose:\n",
    "                print('data.shape (per temperature):',np.array(data).shape)\n",
    "                \n",
    "            #--- correlations\n",
    "            crltns_ab = np.c_[list(map(lambda x: Noise.Crltns(x[:,col_a],x[:,col_b]),data))]\n",
    "            crltns_ba = np.c_[list(map(lambda x: Noise.Crltns(x[:,col_b],x[:,col_a]),data))]\n",
    "            self.crltns_mean_ab[temp] = np.mean(crltns_ab,axis=0)\n",
    "            self.crltns_mean_ba[temp] = np.mean(crltns_ba,axis=0)\n",
    "            self.crltns_err_ab[temp] = np.std(crltns_ab,axis=0)/self.nrun**0.5\n",
    "            self.crltns_err_ba[temp] = np.std(crltns_ba,axis=0)/self.nrun**0.5\n",
    "            kount += self.nrun\n",
    "        #--- plot\n",
    "        irun = 0\n",
    "        smat=data[irun]\n",
    "        for i,j in zip(smat[:,0],smat[:,col_a]):\n",
    "            utl.PltErr([i,i],[0,j],\n",
    "                       attrs={'fmt':'-','color':'C0'},\n",
    "                       ax=self.ax,\n",
    "                       Plot=False,\n",
    "#                       **kwargs\n",
    "                      )\n",
    "        utl.PltErr(self.ax.axis()[:2],[0,0],\n",
    "                        ax=self.ax,\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                       **kwargs\n",
    "                       )\n",
    "\n",
    "            \n",
    "        \n",
    "    def PlotSum(self, col_a = 1, col_b=1,\n",
    "                  **kwargs):\n",
    "        #\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=(1.0,0.5,0.5,0.5))\n",
    "        #\n",
    "        kount = 0\n",
    "        #\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp\n",
    "            data = self.data[kount:kount+self.nrun]\n",
    "            if self.verbose:\n",
    "                print('data.shape (per temperature):',np.array(data).shape)\n",
    "                \n",
    "            #--- correlations\n",
    "            #--- plot\n",
    "            irun = 0\n",
    "            smat=data[irun]\n",
    "            utl.PltErr(smat[:,0],np.cumsum(smat[:,col_a]),\n",
    "                       attrs={'drawstyle':'steps-post'},\n",
    "                       ax=self.ax,\n",
    "                       Plot=False,\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                       **kwargs\n",
    "                      )\n",
    "\n",
    "#             utl.PltErr(lmpData.headers['Time'][1:-1:2],np.cumsum(xvv[:,2]),\n",
    "#                       attrs={'drawstyle':'steps-post'},\n",
    "#                       )\n",
    "\n",
    "            \n",
    "            kount += self.nrun\n",
    "        \n",
    "    @staticmethod        \n",
    "    def Crltns(a,b,n=10):\n",
    "        cr,err=Noise.CrossCr(a,b)\n",
    "        return cr[:n] #np.c_[cr,err]\n",
    "    \n",
    "    def zscore(slist):\n",
    "        slist -= np.mean(slist)\n",
    "        slist /= np.std( slist )\n",
    "        return slist\n",
    "\n",
    "    def CrossCr(x,y, ZSCORE = True):\n",
    "        if ZSCORE:\n",
    "            x -= np.mean( x )\n",
    "            y -= np.mean( y )\n",
    "\n",
    "            x /= np.std( x )\n",
    "            y /= np.std( y )\n",
    "        assert len(x) == len(y), 'len(x)=%s,len(y)=%s'%(len(x),len(y))\n",
    "        n = len(x)\n",
    "        x=np.concatenate([x,np.zeros(n)],axis=0)\n",
    "        y=np.concatenate([y,np.zeros(n)],axis=0)\n",
    "        ones = np.concatenate([np.ones(n),np.zeros(n)],axis=0)\n",
    "\n",
    "        X=np.fft.fft(x)\n",
    "        Y=np.fft.fft(y)\n",
    "        Z=X.conjugate()*Y\n",
    "\n",
    "        cq = np.fft.fft( ones )\n",
    "        count = np.fft.ifft( cq.conjugate()*cq ).real[:n]\n",
    "\n",
    "        z=np.fft.ifft(Z)[:n] / count\n",
    "\n",
    "        return z, 1.0/np.sqrt(count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def PlotCrltns(self,**kwargs):\n",
    "\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=(1.0,0.5,0.5,0.5))\n",
    "        \n",
    "        ax = utl.PltErr(None,None,Plot=False)\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            n=noise.crltns_mean_ba[temp].shape[0]\n",
    "            x=np.concatenate([-np.arange(n-1,-1,-1),np.arange(n)])\n",
    "            indices=np.arange(n-1,-1,-1)\n",
    "            y=np.concatenate([noise.crltns_mean_ba[temp][indices],\n",
    "                              noise.crltns_mean_ab[temp]])\n",
    "            yerr=np.concatenate([noise.crltns_err_ba[temp][indices],\n",
    "                              noise.crltns_err_ab[temp]])\n",
    "\n",
    "\n",
    "            utl.PltErr(x,\n",
    "                       y,\n",
    "                       yerr=2*yerr,\n",
    "                       attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp),\n",
    "                       Plot=False,\n",
    "                       ax=ax,\n",
    "                      )\n",
    "            \n",
    "        utl.PltErr(ax.axis()[:2],[0,0],\n",
    "                   attrs={'fmt':'-.r'},\n",
    "                   Plot=False,\n",
    "            DrawFrame=DRAW_FRAME,\n",
    "                   ax=ax,\n",
    "                       **kwargs\n",
    "                  )\n",
    "    \n",
    "\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    #--- temp object\n",
    "    noise = Noise(\n",
    "#        [1000,1200,1400,1600,1800,2000],8,\n",
    "        [2000],8,\n",
    "#         verbose = True,\n",
    "                     )\n",
    "    #\n",
    "    #--- parse data\n",
    "#    noise.Parse(['./msd/noise.txt'])\n",
    "#    temp.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "    noise.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/noise.txt'%(x[0],x[1]),\n",
    "#    temp.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "#    temp.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/msd.txt'%(x[0],x[1]),\n",
    "                        noise.temps_runs ))\n",
    "             )\n",
    "    #\n",
    "    #--- plot\n",
    "    noise.PlotNoise(col_a=1,col_b=1,**{\n",
    "#                   'attrs':{'fmt':'-','color':'C0'},\n",
    "#                   'xlim':(0,0.5e-09),\n",
    "#                    'ylim':(-2,2),\n",
    "#                     'xticks':([r'$0$',r'$2$',r'$4$'],[0,2e-10,4e-10]),\n",
    "#                   'title':'png/noise_z_nicocr.png',\n",
    "#                   'bbox_to_anchor':(0.01,0.3,0.5,0.5)\n",
    "    })\n",
    "    #\n",
    "    #--- plot sum\n",
    "#     noise.PlotSum(col_a=1,col_b=1,**{\n",
    "# #                  'xscale':'log',\n",
    "# #                  'yscale':'log',\n",
    "#                    'xlim':(0,1e-09),\n",
    "# #                    'ylim':(1e-5,1e-1),\n",
    "# #                   'xstr':r'$t\\mathrm{(s)}$',\n",
    "# #                   'ystr':r'msd(A$^2$)',\n",
    "# #                   'title':'png/msd_temp_ni.png',\n",
    "#         'bbox_to_anchor':(0.01,0.3,0.5,0.5)\n",
    "#     })\n",
    "\n",
    "    \n",
    "    #\n",
    "    noise.PlotCrltns(\n",
    "        **{\n",
    "#                   'yscale':'log',\n",
    "#                   'xscale':'log',\n",
    "#                   'xlim':(1e-10,1e-3),\n",
    "#                    'ylim':(1e-4,1e-1),\n",
    "#                     'xstr':r'$t\\mathrm{(s)}$',\n",
    "#                   'ystr':r'msd(A$^2$)',\n",
    "                   'title':'png/noiseCrltn_yz_nicocr.png',\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wait times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stats(Temperature):\n",
    "    def __init__(self,temp_range,nrun,verbose=False):\n",
    "        Temperature.__init__(self,temp_range,nrun)\n",
    "        self.verbose = verbose\n",
    "    #\n",
    "    def PlotWaitTimes(self,scale=False,\n",
    "                      scalePowerLaw=False,\n",
    "                      shift=False,\n",
    "                      n_per_decade=6,\n",
    "                      **kwargs):\n",
    "        #\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=(1.0,0.5,0.5,0.5))\n",
    "        #\n",
    "        self.mean_rate = {}\n",
    "        kount = 0\n",
    "        #\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            nruns = len(self.nrun[indx])\n",
    "            #--- concat. data for each temp\n",
    "            data = self.data[kount:kount+nruns]\n",
    "            data = list(map(lambda x:self.GetWaitTimes(x),data))\n",
    "            if self.verbose:\n",
    "                print('data.shape (per temperature):',np.array(data).shape)\n",
    "            data = np.concatenate(data) #,axis=0)\n",
    "            rate = 1.0 / data.mean()\n",
    "            self.mean_rate[temp] = [ rate, rate*(1/len(data)**0.5)]\n",
    "            if scale:\n",
    "                data /= data.mean() \n",
    "            if self.verbose:\n",
    "                print('data.shape (concatenated):',data.shape)\n",
    "            #--- histogram\n",
    "            hist, bin_edges, err = utl.GetPDF(data,n_per_decade=n_per_decade)\n",
    "            if scalePowerLaw:\n",
    "                alpha = 2 #1.5\n",
    "                hist *= bin_edges ** alpha \n",
    "                err *= bin_edges ** alpha \n",
    "            #--- plot\n",
    "            if shift:\n",
    "                hist *= 10 ** indx \n",
    "                err *= 10 ** indx \n",
    "            utl.PltErr(bin_edges,hist,\n",
    "                          yerr=err,\n",
    "                   attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp,fmt='.'),\n",
    "                   ax = self.ax,\n",
    "                   Plot=False,\n",
    "                          )\n",
    "            kount += nruns\n",
    "        self.data_regr = np.c_[bin_edges,hist,err]\n",
    "        #\n",
    "        xhi=self.ax.axis()[1]\n",
    "        xarr = np.logspace(np.log10(xhi)-5.0,np.log10(xhi),32)\n",
    "        utl.PltErr( xarr if scale else None,\n",
    "                   np.exp(-xarr) if scale else None,\n",
    "                   attrs={'fmt':'-.r','lw':2},\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "                   \n",
    "#                    legend=legends.Get(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "            \n",
    "    def PlotAverageRate(self,**kwargs):\n",
    "#        print(list(self.temps_runs))\n",
    "#         self.ax = utl.PltErr(None,#ans[:,0],\n",
    "#                         None,#1e8*ans[:,0],\n",
    "#                         attrs={'fmt':'-.r'},Plot=False)\n",
    "\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=(1.0,0.5,0.5,0.5))\n",
    "        data = list(map(lambda x:self.mean_rate[ x ][0], self.temps))\n",
    "        err = list(map(lambda x:self.mean_rate[ x ][1], self.temps))\n",
    "#             utl.PltErr(data[:,0],data[:,1],\n",
    "#                    yerr=data[:,2],\n",
    "#                    ax = self.ax,\n",
    "#                    attrs=symbols.GetAttrs(count=count%7,label=r'$%s$'%temp),\n",
    "#                    Plot=False,\n",
    "#                   )\n",
    "\n",
    "        utl.PltErr(1.0/np.array(self.temps),\n",
    "                   data,\n",
    "                   yerr=err,\n",
    "                   attrs=symbols.GetAttrs(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "            \n",
    "    \n",
    "    def GetWaitTimes(self,times):\n",
    "#         times = np.array(np.c_[self.lmpData.headers['Time'].iloc[0::2]].flatten())\n",
    "        dtt = times[1:]-times[:-1]\n",
    "        assert not np.any(dtt<0.0)\n",
    "        filtr = dtt > 0.0\n",
    "        return dtt[filtr]\n",
    "\n",
    "    #\n",
    "    def Barries(self):\n",
    "        Barrier = self.lmpData.headers['Barrier'].iloc[1::2]        \n",
    "        hist, bin_edges, err = utl.GetPDF(Barrier,linscale=True,n_per_decade=16)\n",
    "        utl.PltErr(bin_edges,hist,\n",
    "                  yerr=err,\n",
    "                   attrs=symbols.GetAttrs(),\n",
    "                   #yscale='log',\n",
    "                   #xscale='log',\n",
    "                   xstr=r'$\\Delta E$',\n",
    "                   ystr=r'$P(\\Delta E)$'\n",
    "                  )\n",
    "\n",
    "    def func(self,x,k,alpha,beta,t0):\n",
    "        return k*(x/t0)**(-alpha)/(1+(x/t0)**(beta-alpha))\n",
    "    \n",
    "    \n",
    "    def fit(self,edge,hist,err):\n",
    "        xdata=edge\n",
    "        ydata=hist\n",
    "        yerr=err\n",
    "        popt, pcov = curve_fit(self.func,xdata,ydata,\n",
    "                              p0=(1.0,0.4,2,1.0),\n",
    "                               sigma=yerr,\n",
    "                              )\n",
    "\n",
    "        ax=utl.PltErr(edge,hist,yerr=err,\n",
    "                   yscale='log',xscale='log',\n",
    "                      Plot=False\n",
    "                  )\n",
    "        utl.PltErr(edge,self.func(edge,*popt),attrs={'fmt':'-.r'},\n",
    "                   yscale='log',xscale='log',\n",
    "                   ax=ax,\n",
    "                   ylim=(1e-5,1000),\n",
    "                  )\n",
    "#        assert popt[-1]>0\n",
    "        print('k,alpha,beta,t0',popt)\n",
    "        return popt[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    if eval(confParser['flags']['RemoteMachine']):\n",
    "        return \n",
    "    \n",
    "    !mkdir png\n",
    "\n",
    "    stats = Stats(\n",
    "#         [1000,1200,1400,1600,1800,2000],8,\n",
    "        [1000], [list(range(8))]*10,\n",
    "#        [0,1],[list(range(8))]*10,\n",
    "#        np.arange(1000,1440,80),1,\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse(['msd/event_times.txt'])\n",
    "    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/event_times.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/event_times.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/event_times.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/event_times.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'flickers/nicocr/temp0/thresh%s/Run%s/msd/event_times.txt'%(x[0],x[1]),\n",
    "                        stats.temps_runs ))\n",
    "              )\n",
    "    stats.PlotWaitTimes(scale=True,shift=False,scalePowerLaw=False,\n",
    "                        n_per_decade=6,\n",
    "                        **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "#                     'xlim':(1e-3,100),\n",
    "                      'ylim':(1e-5,1e2),#(1e-8,1e6), #,\n",
    "#                    'ndecade_y':2,\n",
    "#                            'xstr':r'$t_w$',\n",
    "#                            'ystr':r'$P(\\lambda t_w)$',\n",
    "                   'title':'png/waitTimes_unscaled_ni.png'},\n",
    "\n",
    "                       )\n",
    "#     stats.PlotWaitTimes(scale=True,scalePowerLaw=True,\n",
    "#                         **{'xscale':'log',\n",
    "#                   'yscale':'log',\n",
    "# #                   'xlim':(1e-9,1e-3),\n",
    "#                    'ylim':(1e-5,1e0), #(1e-5,1e2),\n",
    "# #                           'xstr':r'$\\Delta t$',\n",
    "# #                           'ystr':r'$P(\\Delta t)$',\n",
    "#                    'title':'png/waitTimes_rescaled_ni.png'},\n",
    "#                       )\n",
    "#     stats.PlotAverageRate(\n",
    "#                 **{\n",
    "# #                    'fontsize':36,\n",
    "# #                  'xscale':'log',\n",
    "#                   'yscale':'log',\n",
    "# #                   'xlim':(1e-9,1e-3),\n",
    "# #                   'ylim':(1e9,1e13), #(1e-5,1e2),\n",
    "# #                           'xstr':r'$1/T$',\n",
    "# #                           'ystr':r'$\\lambda$',\n",
    "#                    'title':'png/eventRate_nicocr.png'},\n",
    "\n",
    "#     )\n",
    "    #\n",
    "#    stats.fit(stats.data_regr[:,0],stats.data_regr[:,1],stats.data_regr[:,2])\n",
    "    #stats.Barries()\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### effective E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x,a,b):\n",
    "    return a*np.exp(-b*x)\n",
    "\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    kb=8.61732814974056e-05\n",
    "    xdata = 1/(kb*np.array(stats.temps))\n",
    "    ydata = list(map(lambda x:stats.mean_rate[x][0],stats.temps))\n",
    "    yerr = list(map(lambda x:stats.mean_rate[x][1],stats.temps))\n",
    "    popt,pcov=curve_fit(func,xdata,ydata,\n",
    "             p0=[1e12,1],\n",
    "             sigma=yerr\n",
    "             )\n",
    "    #\n",
    "    ax=utl.PltErr(xdata,ydata,yerr=yerr,\n",
    "               fmt='.',\n",
    "               Plot=False\n",
    "\n",
    "              )\n",
    "    utl.PltErr(xdata,func(xdata,*popt),\n",
    "               yscale='log',\n",
    "               attrs={'fmt':'-.r'},\n",
    "               ax=ax,\n",
    "               xstr=r'$1/k_BT$',ystr=r'$\\lambda$'\n",
    "\n",
    "              )\n",
    "    Tm=[1650,2100][0]\n",
    "    print('energy=%s eV'%popt[1])\n",
    "    print('scaled energy=',popt[1]/kb/Tm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reduced temperature scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    #Tm = 1650\n",
    "    xdata = np.array(stats.temps)\n",
    "    ydata = list(map(lambda x:stats.mean_rate[x][0],stats.temps))\n",
    "    yerr = list(map(lambda x:stats.mean_rate[x][1],stats.temps))\n",
    "    np.savetxt('ni2nd.txt',np.c_[xdata,ydata,yerr],header='T lambda err')\n",
    "\n",
    "    symbols=utl.Symbols()\n",
    "    legends = Legends()\n",
    "    legends.Set(bbox_to_anchor=(1.0,0.5,0.5,0.5))\n",
    "\n",
    "\n",
    "\n",
    "    Tm = 1650\n",
    "    data_nicocr = np.loadtxt('nicocr.txt')\n",
    "    xdata = Tm/data_nicocr[:,0]\n",
    "    ydata = data_nicocr[:,1]\n",
    "    yerr = data_nicocr[:,2]\n",
    "\n",
    "    ax=utl.PltErr(xdata,ydata,yerr=yerr,\n",
    "                    attrs=symbols.GetAttrs(count=1,label=r'nicocr'),\n",
    "              Plot=False,\n",
    "             yscale='log'\n",
    "             )\n",
    "\n",
    "    Tm = 2100\n",
    "    data_ni = np.loadtxt('ni.txt')\n",
    "    xdata = Tm/data_ni[:,0]\n",
    "    ydata = data_ni[:,1]\n",
    "    yerr = data_ni[:,2]\n",
    "\n",
    "    utl.PltErr(xdata,ydata,yerr=yerr,\n",
    "                    attrs=symbols.GetAttrs(count=0,label=r'ni'),\n",
    "            ax=ax,\n",
    "              Plot=False,\n",
    "             yscale='log',\n",
    "                     legend=legends.Get(),\n",
    "               xstr=r'$T_m/T$',ystr=r'$\\lambda$'\n",
    "             )\n",
    "\n",
    "    # Tm = 1607\n",
    "    # data_ni = np.loadtxt('cantor.txt')\n",
    "    # xdata = Tm/data_ni[:,0]\n",
    "    # ydata = data_ni[:,1]\n",
    "    # yerr = data_ni[:,2]\n",
    "\n",
    "    # utl.PltErr(xdata,ydata,yerr=yerr,\n",
    "    # #          fmt='.',\n",
    "    #         ax=ax,\n",
    "    #           Plot=False,\n",
    "    #          yscale='log'\n",
    "    #          )\n",
    "\n",
    "    # Tm = 2100\n",
    "    # data_ni = np.loadtxt('ni2nd.txt')\n",
    "    # xdata = Tm/data_ni[:,0]\n",
    "    # ydata = data_ni[:,1]\n",
    "    # yerr = data_ni[:,2]\n",
    "\n",
    "    # utl.PltErr(xdata,ydata,yerr=yerr,\n",
    "    # #          fmt='.',\n",
    "    #         ax=ax,\n",
    "    #           Plot=False,\n",
    "    #          yscale='log',\n",
    "    #                  legend=legends.Get(),\n",
    "\n",
    "    #          )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    path = '../simulations/NiMultTemp/Temp2000K/Run0'\n",
    "\n",
    "    #--- parse\n",
    "    data = pd.read_csv('%s/thermo.txt'%path,delimiter=' ')\n",
    "\n",
    "    #--- plot\n",
    "    utl.PltErr(data.time,data.vol,ystr='vol')\n",
    "    utl.PltErr(data.time,data.temp,ystr='temp')\n",
    "\n",
    "    #--- mean \n",
    "    filtr = data.time > 100.0\n",
    "    n = np.sum(filtr)\n",
    "    mean_vol = data.vol[filtr].mean()\n",
    "    err_vol = data.vol[filtr].std()/n**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    mean_vol = {}\n",
    "    err_vol = {}\n",
    "    temps = np.linspace(2000,3000,16)\n",
    "    for temp in temps:\n",
    "        path = '../simulations/NiMultTemp/Temp%sK/Run0'%int(temp)\n",
    "\n",
    "        #--- parse\n",
    "        data = pd.read_csv('%s/thermo.txt'%path,delimiter=' ')\n",
    "\n",
    "        #--- plot\n",
    "    #    utl.PltErr(data.time,data.vol,ystr='vol')\n",
    "    #    utl.PltErr(data.time,data.temp,ystr='temp')\n",
    "\n",
    "        #--- mean \n",
    "        filtr = data.time > 100.0\n",
    "        n = np.sum(filtr)\n",
    "        mean_vol[temp] = data.vol[filtr].mean()\n",
    "        err_vol[temp] = data.vol[filtr].std()/n**0.5\n",
    "    \n",
    "    filtr = temps>0\n",
    "    utl.PltErr(temps[filtr],\n",
    "               np.array(list(map(lambda x:mean_vol[x],temps)))[filtr],\n",
    "\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JumpStats(Temperature):\n",
    "    def __init__(self,temp_range,nrun,verbose=False):\n",
    "        Temperature.__init__(self,temp_range,nrun)\n",
    "        self.verbose = verbose\n",
    "    #\n",
    "    def PlotPdf(self,scale=False,**kwargs):\n",
    "        #\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "        #\n",
    "        self.mean_rate = {}\n",
    "        kount = 0\n",
    "        #\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp\n",
    "            data = self.data[kount:kount+self.nrun][0]\n",
    "            if self.verbose:\n",
    "                print('data.shape (per temperature):',np.array(data).shape)\n",
    "            if self.verbose:\n",
    "                print('data.shape (concatenated):',data.shape)\n",
    "            #--- histogram\n",
    "#            data = np.array(data).flatten()\n",
    "            hist = data[:,1]\n",
    "            bin_edges = data[:,0]\n",
    "            err = data[:,2]\n",
    "            \n",
    "            #--- remove count == 1\n",
    "            filtr = err == hist\n",
    "            hist = hist[~filtr]\n",
    "            bin_edges = bin_edges[~filtr]\n",
    "            err = err[~filtr]\n",
    "            \n",
    "            self.data_regr = np.c_[bin_edges,hist,err]\n",
    "            if scale:\n",
    "                hist *= bin_edges ** self.alpha\n",
    "                err  *= bin_edges ** self.alpha\n",
    "        #--- plot\n",
    "#            temp= [1000,1200,1400,1600,1800,2000][indx]\n",
    "            utl.PltErr(bin_edges,hist,\n",
    "                          yerr=err,\n",
    "                   attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp,fmt='.'),\n",
    "                   ax = self.ax,\n",
    "                   Plot=False,\n",
    "                          )\n",
    "            kount+=self.nrun\n",
    "        #\n",
    "        utl.PltErr(None,\n",
    "                   None,\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "#                      legend=legends.Get(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "            \n",
    "    def func(self,x,k,alpha):\n",
    "        return k*x**alpha\n",
    "    \n",
    "    \n",
    "    def fit(self,edge,hist,err):\n",
    "        xdata=edge\n",
    "        ydata=hist\n",
    "        yerr=err\n",
    "        popt, pcov = curve_fit(self.func,xdata,ydata,\n",
    "                               p0=(1.0e-4,-2.0),\n",
    "                               sigma=2*yerr,\n",
    "                              )\n",
    "\n",
    "        ax=utl.PltErr(edge,hist,yerr=2*err,fmt='.',\n",
    "                   yscale='log',xscale='log',\n",
    "                      Plot=False\n",
    "                  )\n",
    "        utl.PltErr(edge,self.func(edge,*popt),attrs={'fmt':'-.r'},\n",
    "                   yscale='log',xscale='log',\n",
    "                   ax=ax,\n",
    "#                   ylim=(1e-5,1000),\n",
    "                  )\n",
    "#        assert popt[-1]>0\n",
    "        print('k,alpha',popt)\n",
    "        return popt[0]\n",
    "    \n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    \n",
    "    stats = JumpStats(\n",
    "        [1000,1200,1400,1600,1800,2000],\n",
    "#        [1000,1200,1400,1600,1800,2000],\n",
    "#        np.arange(1000,1440,80),\n",
    "        1,\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/event_jumps.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/event_jumps.txt'%(x[0],x[1]),\n",
    "    stats.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/event_jumps.txt'%(x[0],x[1]),\n",
    "                         stats.temps_runs ))\n",
    "               )\n",
    "    stats.PlotPdf(scale=False,\n",
    "                        **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "                   'xlim':(1e-8,4e0),\n",
    "#                   'ylim':(1e-3,1e1), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "                        'ndecade_x':2,'ndecade_y':2,\n",
    "                    'bbox_to_anchor':(0.56,0.27,0.5,0.5),\n",
    "                   'title':'png/jumpsPdf_nicocr.png'},\n",
    "\n",
    "                       )\n",
    "    \n",
    "    #--- rescale\n",
    "    stats.alpha = 2.5 #2.8 #3.0#2.5\n",
    "    stats.PlotPdf(scale=True,\n",
    "                **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "                   'fontsize':32,\n",
    "#                   'xlim':(1e-8,2e0),\n",
    "#                   'ylim':(1e-3,1e1), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "                        'ndecade_x':2,'ndecade_y':4,\n",
    "                   'title':'png/jumpsPdf_rescaled_ni.png'},\n",
    "\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "\n",
    "    stats = JumpStats(\n",
    "        [2000],1,\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/event_jumps.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/event_jumps.txt'%(x[0],x[1]),\n",
    "    stats.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/event_jumps.txt'%(x[0],x[1]),\n",
    "                         stats.temps_runs ))\n",
    "               )\n",
    "    stats.PlotPdf(scale=False,\n",
    "                        **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "                   'xlim':(1e-8,4e0),\n",
    "#                   'ylim':(1e-3,1e1), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "                        'ndecade_x':2,'ndecade_y':2,\n",
    "                    'bbox_to_anchor':(0.56,0.27,0.5,0.5),\n",
    "#                    'title':'png/jumpsPdf_nicocr.png'\n",
    "                          },\n",
    "\n",
    "                       )\n",
    "    filtr = np.all([stats.data_regr[:,0]>1e-3,stats.data_regr[:,0]<1e-1],axis=0)\n",
    "    stats.fit(stats.data_regr[:,0][filtr],stats.data_regr[:,1][filtr],stats.data_regr[:,2][filtr])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Energy = lmpData.headers['Energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not eval(confParser['flags']['RemoteMachine']):\n",
    "#             data = self.data[kount:kount+self.nrun]\n",
    "#             if self.verbose:\n",
    "#                 print('data.shape:',np.array(data).shape)\n",
    "# #             print('np.array(data):',np.array(data))\n",
    "# #             pdb.set_trace()\n",
    "    \n",
    "#             filtr = list(map(lambda x:x.shape[0] > 0,data)) #--- filter empty arrays\n",
    "    \n",
    "#             data = np.concatenate(np.array(data)[filtr]) #,axis=0)\n",
    "#             self.data_averaged[ temp ] = self.hist(data,log_scale)\n",
    "#             kount += self.nrun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sampled energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class EnergyStats(Temperature):\n",
    "    def __init__(self,temp_range,nrun,verbose=False):\n",
    "        Temperature.__init__(self,temp_range,nrun)\n",
    "        self.verbose = verbose\n",
    "    #\n",
    "    def GetWaitTimes(self,times):\n",
    "        times = times[0::2]\n",
    "        dtt = times[1:]-times[:-1]\n",
    "        assert not np.any(dtt<0.0)\n",
    "#        filtr = dtt > 0.0\n",
    "        return dtt#[filtr]\n",
    "    #\n",
    "    def PlotPdf(self,shift=False,column_energy = 0,n_per_decade=8,\n",
    "                linscale = False,\n",
    "                **kwargs):\n",
    "        #\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs #plotAttrs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "        #\n",
    "        self.mean_rate = {}\n",
    "        #\n",
    "        kount = 0\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            nruns = len(self.nrun[indx])\n",
    "\n",
    "            #--- concat. data for each temp            \n",
    "            data = np.concatenate(list(map(lambda x: self.data[x][:,column_energy],range(kount,kount+nruns))))\n",
    "            #--- remove zeros\n",
    "            data = data[data > 0.0]\n",
    "            if self.verbose:\n",
    "                print('data.shape (per temperature):',np.array(data).shape)\n",
    "            if self.verbose:\n",
    "                print('data.shape (concatenated):',data.shape)\n",
    "            #--- histogram\n",
    "#            data = np.array(data).flatten()\n",
    "            #--- histogram\n",
    "            hist, bin_edges, err = utl.GetPDF(data,n_per_decade=n_per_decade,linscale=linscale)\n",
    "        \n",
    "            #--- filtr\n",
    "            filtr = hist == err\n",
    "            hist = hist[~filtr]\n",
    "            bin_edges = bin_edges[~filtr]\n",
    "            err = err[~filtr]\n",
    "        #--- plot\n",
    "            if shift:\n",
    "                hist *= 100**indx if shift else 1\n",
    "                err *= 100**indx if shift else 1\n",
    "\n",
    "            utl.PltErr(bin_edges,hist,\n",
    "#                           yerr=err,\n",
    "                    attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp), #,fmt='.'),\n",
    "#                   attrs={'fmt':'-','color':'C0'},\n",
    "                   ax = self.ax,\n",
    "                   Plot=False,\n",
    "                          )\n",
    "            \n",
    "#            self.ax.fill_between(bin_edges, hist)\n",
    "            \n",
    "            kount += nruns #self.nrun\n",
    "        #\n",
    "        utl.PltErr(None,\n",
    "                   None,\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "                   \n",
    "#                    legend=legends.Get(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "        \n",
    "    def PlotPdfConcat(self,scale=False,\n",
    "                      column_energy = 0,\n",
    "                      type_column=0,\n",
    "                      splitByType=True,\n",
    "                      n_per_decade = 8,\n",
    "                      **kwargs):\n",
    "        #\n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs #plotAttrs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "        #\n",
    "        self.mean_rate = {}\n",
    "        kount = 0\n",
    "        #\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp            \n",
    "#            data = np.concatenate(list(map(lambda x: self.data[x][:,column_energy],range(indx,indx+self.nrun))))\n",
    "            data = np.concatenate(list(map(lambda x: self.data[x],range(kount,kount+self.nrun))))\n",
    "#             types = np.concatenate(list(map(lambda x: self.data[x][:,type_column],range(indx,indx+self.nrun))))\n",
    "            #--- remove zeros\n",
    "#            data = data[data > 0.0]\n",
    "            if self.verbose:\n",
    "                print('data.shape (per temperature):',np.array(data).shape)\n",
    "            if self.verbose:\n",
    "                print('data.shape (concatenated):',data.shape)\n",
    "            #--- histogram\n",
    "#            data = np.array(data).flatten()\n",
    "            #--- histogram\n",
    "            data_concat = data.copy() if indx ==0 else np.concatenate([data_concat,data]) #np.c_[types,data] if indx ==0 else\\\n",
    "                        #np.concatenate([data_concat,np.c_[types,data]])\n",
    "            kount += self.nrun\n",
    "        if self.verbose:\n",
    "            print('type.shape (concatenated):',data_concat.shape)\n",
    "        \n",
    "        #--- split by type\n",
    "        if splitByType:\n",
    "            df=pd.DataFrame(np.c_[data_concat[:,type_column],data_concat[:,column_energy]],\n",
    "                            columns=['type','dE'])\n",
    "            types=df.groupby(by='type').groups\n",
    "            for itype in types:\n",
    "                indices = types[itype]\n",
    "                elist = np.array(df['dE'].iloc[indices])\n",
    "                if self.verbose:\n",
    "                    print('elist.shape:',elist.shape)\n",
    "\n",
    "                #--- histogram\n",
    "                hist, bin_edges, err = utl.GetPDF(elist,n_per_decade=n_per_decade)\n",
    "\n",
    "                #--- filtr\n",
    "                filtr = hist == err\n",
    "                hist = hist[~filtr]\n",
    "                bin_edges = bin_edges[~filtr]\n",
    "                err = err[~filtr]\n",
    "                #--- plot\n",
    "                if scale:\n",
    "                    hist *= 1000**int(itype)\n",
    "                    err *= 1000**int(itype)\n",
    "                utl.PltErr(bin_edges,hist,\n",
    "                              yerr=err,\n",
    "                       attrs=symbols.GetAttrs(count=int(itype-1)%7,label=r'$%s$'%itype), #,fmt='.'),\n",
    "                       ax = self.ax,\n",
    "                       Plot=False,\n",
    "                              )\n",
    "        else:\n",
    "                data = data_concat[:,column_energy]\n",
    "                data = data[data > 0.0]\n",
    "\n",
    "                #--- histogram\n",
    "                hist, bin_edges, err = utl.GetPDF(data,n_per_decade=n_per_decade)\n",
    "\n",
    "                #--- filtr\n",
    "                filtr = hist == err\n",
    "                hist = hist[~filtr]\n",
    "                bin_edges = bin_edges[~filtr]\n",
    "                err = err[~filtr]\n",
    "                #--- plot\n",
    "#                 if scale:\n",
    "#                     hist *= 100**int(itype)\n",
    "#                     err *= 100**int(itype)\n",
    "                utl.PltErr(bin_edges,hist,\n",
    "                              yerr=err,\n",
    "                       attrs=symbols.GetAttrs(count=0), #,label=r'$%s$'%itype),#,fmt='.'),\n",
    "                       ax = self.ax,\n",
    "                       Plot=False,\n",
    "                              )\n",
    "        #\n",
    "        utl.PltErr(None,\n",
    "                   None,\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "\n",
    "#                        legend=legends.Get(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "\n",
    "    def Scatter(self,shift=False,nevery=1,**kwargs):\n",
    "        kb_inv=8.61732814974056e05\n",
    "        \n",
    "        self.ax = utl.PltErr(None,#ans[:,0],\n",
    "                        None,#1e8*ans[:,0],\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "        symbols=Symbols(markersizes=np.array([10,10,10,12,12,12,10])*8)\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs #plotAttrs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "\n",
    "        #\n",
    "        column_energy = 0\n",
    "        column_time = 3\n",
    "        kount = 0\n",
    "        for indx in range(0,len(self.temps),nevery):\n",
    "            temp = self.temps[indx]\n",
    "            #--- concat. data for each temp            \n",
    "            data_energy = np.concatenate(list(map(lambda x: self.GetEnergy(self.data[x][:,column_energy]),\n",
    "                                                  range(kount,kount+self.nrun))))\n",
    "            #--- wait_times\n",
    "            data = self.data[indx:indx+self.nrun]\n",
    "            data_waitTimes = np.concatenate(list(map(lambda x: self.GetWaitTimes(self.data[x][:,column_time]),\n",
    "                                                     range(kount,kount+self.nrun))))\n",
    "\n",
    "            if self.verbose:\n",
    "                print('data_energy.shape (per temperature):',np.array(data_energy).shape)\n",
    "                print('data_waitTimes.shape (per temperature):',np.array(data_waitTimes).shape)\n",
    "            #--- plot scatter\n",
    "            scale = 1e2 ** indx if shift else 1\n",
    "            filtr = data_waitTimes > 0\n",
    "#             utl.PltErr(data_energy[filtr]*kb_inv/temp,scale*data_waitTimes[filtr],\n",
    "#                         attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp,fmt='.',alpha=1.0),\n",
    "#                         ax = self.ax,\n",
    "#                         Plot=False,\n",
    "#                         )\n",
    "            self.ax.scatter(data_energy[filtr]*kb_inv/temp,scale*data_waitTimes[filtr],\n",
    "                        **symbols.GetAttrsScatter(count=indx%7,label=r'$%s$'%temp,fmt='.',alpha=0.1/2),\n",
    "                       )\n",
    "            kount += self.nrun\n",
    "            #--- plot average\n",
    "#             nbins = 8\n",
    "#             count, _=np.histogram(data_energy[filtr],bins=nbins)\n",
    "#             xsum, _=np.histogram(data_energy[filtr],weights=data_energy[filtr],bins=nbins)\n",
    "#             ysum, _=np.histogram(data_energy[filtr],weights=data_waitTimes[filtr],bins=nbins)\n",
    "#             ysum /= count\n",
    "# #            ysum =10 ** ysum \n",
    "#             xsum /= count\n",
    "#             #---\n",
    "#             utl.PltErr(xsum,ysum,\n",
    "#                         attrs=symbols.GetAttrs(count=(indx)%7,label=r'$%s$'%temp,fmt='.'),\n",
    "#                         ax = self.ax,\n",
    "#                         Plot=False,\n",
    "#                         )\n",
    "        \n",
    "        \n",
    "        utl.PltErr(None,\n",
    "                   None,\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "#                     legend=legends.Get(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "\n",
    "    def GetEnergy(self,slist):\n",
    "        n=len(slist)\n",
    "        return slist[1:n:2]\n",
    "            \n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    \n",
    "    stats = EnergyStats(\n",
    "        [1000,1200,1400,1600,1800,2000],8,\n",
    "#        [1000,1400,1800,2000],8,\n",
    "#        [1000, 1400,1800],8,\n",
    "        #        np.arange(1000,1440,40),1,\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "                         stats.temps_runs ))\n",
    "               )\n",
    "    stats.PlotPdf(shift=True,n_per_decade=10,\n",
    "                        **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "#                   'xlim':(1e-3,1e0),\n",
    "#                   'ylim':(1e-2,1e2), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "                        'ndecade_y':2,\n",
    "                   'title':'png/BarrierPdf_cantor.png'},\n",
    "\n",
    "                       )\n",
    "    \n",
    "#     stats.PlotPdfConcat(scale=False,\n",
    "#                         splitByType = False,\n",
    "#                         **{'xscale':'log',\n",
    "#                       'yscale':'log',\n",
    "#     #                   'xlim':(1e-3,1e0),\n",
    "# #                        'ylim':(1e-2,1e2), #(1e-5,1e2),\n",
    "#     #                           'xstr':r'$\\Delta t$',\n",
    "#     #                           'ystr':r'$P(\\Delta t)$',\n",
    "#     #                        'ndecade_x':2,'ndecade_y':2,\n",
    "#     #                   'title':'png/BarrierPdf_cantor.png'\n",
    "#                           },\n",
    "#                        )\n",
    "\n",
    "    stats.Scatter(nevery=2, shift = True,                        \n",
    "                **{'xscale':'linear',\n",
    "                  'yscale':'log',\n",
    "#                   'xlim':(1e-3,1),\n",
    "#                   'ylim':(1e-3,1e1), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "#                     'bbox_to_anchor':(0.56,0.27,0.5,0.5),\n",
    "                        'ndecade_y':2,\n",
    "                   'title':'png/twVsEnergy_nicocr.png',\n",
    "                  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# class EnergyStats(Temperature):\n",
    "#     def __init__(self,temp_range,nrun,verbose=False):\n",
    "#         Temperature.__init__(self,temp_range,nrun)\n",
    "#         self.verbose = verbose\n",
    "#     #\n",
    "#     def GetWaitTimes(self,times):\n",
    "#         times = times[0::2]\n",
    "#         dtt = times[1:]-times[:-1]\n",
    "#         assert not np.any(dtt<0.0)\n",
    "# #        filtr = dtt > 0.0\n",
    "#         return dtt#[filtr]\n",
    "#     #\n",
    "#     def PlotPdf(self,shift=False,column_energy = 0,n_per_decade=8,\n",
    "#                 **kwargs):\n",
    "#         #\n",
    "#         self.ax = utl.PltErr(None,#ans[:,0],\n",
    "#                         None,#1e8*ans[:,0],\n",
    "#                         attrs={'fmt':'-.r'},Plot=False)\n",
    "#         symbols=utl.Symbols()\n",
    "#         legends = Legends()\n",
    "#         legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs #plotAttrs\n",
    "#                     else (1.0,0.5,0.5,0.5))\n",
    "#         #\n",
    "#         self.mean_rate = {}\n",
    "#         #\n",
    "#         kount = 0\n",
    "#         for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "#             #--- concat. data for each temp            \n",
    "#             data = np.concatenate(list(map(lambda x: self.data[x][:,column_energy],range(kount,kount+self.nrun))))\n",
    "#             #--- remove zeros\n",
    "#             data = data[data > 0.0]\n",
    "#             if self.verbose:\n",
    "#                 print('data.shape (per temperature):',np.array(data).shape)\n",
    "#             if self.verbose:\n",
    "#                 print('data.shape (concatenated):',data.shape)\n",
    "#             #--- histogram\n",
    "# #            data = np.array(data).flatten()\n",
    "#             #--- histogram\n",
    "#             hist, bin_edges, err = utl.GetPDF(data,n_per_decade=n_per_decade)\n",
    "        \n",
    "#             #--- filtr\n",
    "#             filtr = hist == err\n",
    "#             hist = hist[~filtr]\n",
    "#             bin_edges = bin_edges[~filtr]\n",
    "#             err = err[~filtr]\n",
    "#         #--- plot\n",
    "#             if shift:\n",
    "#                 hist *= 100**indx if shift else 1\n",
    "#                 err *= 100**indx if shift else 1\n",
    "\n",
    "#             utl.PltErr(bin_edges,hist,\n",
    "#                           yerr=err,\n",
    "#                    attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp), #,fmt='.'),\n",
    "#                    ax = self.ax,\n",
    "#                    Plot=False,\n",
    "#                           )\n",
    "#             kount += self.nrun\n",
    "#         #\n",
    "#         utl.PltErr(None,\n",
    "#                    None,\n",
    "#                    ax=self.ax,\n",
    "#                    Plot=False,\n",
    "                   \n",
    "# #                    legend=legends.Get(),\n",
    "#                    DrawFrame=DRAW_FRAME,\n",
    "#                    **kwargs\n",
    "#                   )\n",
    "        \n",
    "#     def PlotPdfConcat(self,scale=False,\n",
    "#                       column_energy = 0,\n",
    "#                       type_column=0,\n",
    "#                       splitByType=True,\n",
    "#                       n_per_decade = 8,\n",
    "#                       **kwargs):\n",
    "#         #\n",
    "#         self.ax = utl.PltErr(None,#ans[:,0],\n",
    "#                         None,#1e8*ans[:,0],\n",
    "#                         attrs={'fmt':'-.r'},Plot=False)\n",
    "#         symbols=utl.Symbols()\n",
    "#         legends = Legends()\n",
    "#         legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs #plotAttrs\n",
    "#                     else (1.0,0.5,0.5,0.5))\n",
    "#         #\n",
    "#         self.mean_rate = {}\n",
    "#         kount = 0\n",
    "#         #\n",
    "#         for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "#             #--- concat. data for each temp            \n",
    "# #            data = np.concatenate(list(map(lambda x: self.data[x][:,column_energy],range(indx,indx+self.nrun))))\n",
    "#             data = np.concatenate(list(map(lambda x: self.data[x],range(kount,kount+self.nrun))))\n",
    "# #             types = np.concatenate(list(map(lambda x: self.data[x][:,type_column],range(indx,indx+self.nrun))))\n",
    "#             #--- remove zeros\n",
    "# #            data = data[data > 0.0]\n",
    "#             if self.verbose:\n",
    "#                 print('data.shape (per temperature):',np.array(data).shape)\n",
    "#             if self.verbose:\n",
    "#                 print('data.shape (concatenated):',data.shape)\n",
    "#             #--- histogram\n",
    "# #            data = np.array(data).flatten()\n",
    "#             #--- histogram\n",
    "#             data_concat = data.copy() if indx ==0 else np.concatenate([data_concat,data]) #np.c_[types,data] if indx ==0 else\\\n",
    "#                         #np.concatenate([data_concat,np.c_[types,data]])\n",
    "#             kount += self.nrun\n",
    "#         if self.verbose:\n",
    "#             print('type.shape (concatenated):',data_concat.shape)\n",
    "        \n",
    "#         #--- split by type\n",
    "#         if splitByType:\n",
    "#             df=pd.DataFrame(np.c_[data_concat[:,type_column],data_concat[:,column_energy]],\n",
    "#                             columns=['type','dE'])\n",
    "#             types=df.groupby(by='type').groups\n",
    "#             for itype in types:\n",
    "#                 indices = types[itype]\n",
    "#                 elist = np.array(df['dE'].iloc[indices])\n",
    "#                 if self.verbose:\n",
    "#                     print('elist.shape:',elist.shape)\n",
    "\n",
    "#                 #--- histogram\n",
    "#                 hist, bin_edges, err = utl.GetPDF(elist,n_per_decade=n_per_decade)\n",
    "\n",
    "#                 #--- filtr\n",
    "#                 filtr = hist == err\n",
    "#                 hist = hist[~filtr]\n",
    "#                 bin_edges = bin_edges[~filtr]\n",
    "#                 err = err[~filtr]\n",
    "#                 #--- plot\n",
    "#                 if scale:\n",
    "#                     hist *= 1000**int(itype)\n",
    "#                     err *= 1000**int(itype)\n",
    "#                 utl.PltErr(bin_edges,hist,\n",
    "#                               yerr=err,\n",
    "#                        attrs=symbols.GetAttrs(count=int(itype-1)%7,label=r'$%s$'%itype), #,fmt='.'),\n",
    "#                        ax = self.ax,\n",
    "#                        Plot=False,\n",
    "#                               )\n",
    "#         else:\n",
    "#                 data = data_concat[:,column_energy]\n",
    "#                 data = data[data > 0.0]\n",
    "\n",
    "#                 #--- histogram\n",
    "#                 hist, bin_edges, err = utl.GetPDF(data,n_per_decade=n_per_decade)\n",
    "\n",
    "#                 #--- filtr\n",
    "#                 filtr = hist == err\n",
    "#                 hist = hist[~filtr]\n",
    "#                 bin_edges = bin_edges[~filtr]\n",
    "#                 err = err[~filtr]\n",
    "#                 #--- plot\n",
    "# #                 if scale:\n",
    "# #                     hist *= 100**int(itype)\n",
    "# #                     err *= 100**int(itype)\n",
    "#                 utl.PltErr(bin_edges,hist,\n",
    "#                               yerr=err,\n",
    "#                        attrs=symbols.GetAttrs(count=0), #,label=r'$%s$'%itype),#,fmt='.'),\n",
    "#                        ax = self.ax,\n",
    "#                        Plot=False,\n",
    "#                               )\n",
    "#         #\n",
    "#         utl.PltErr(None,\n",
    "#                    None,\n",
    "#                    ax=self.ax,\n",
    "#                    Plot=False,\n",
    "\n",
    "# #                        legend=legends.Get(),\n",
    "#                    DrawFrame=DRAW_FRAME,\n",
    "#                    **kwargs\n",
    "#                   )\n",
    "\n",
    "#     def Scatter(self,shift=False,nevery=1,**kwargs):\n",
    "#         kb_inv=8.61732814974056e05\n",
    "        \n",
    "#         self.ax = utl.PltErr(None,#ans[:,0],\n",
    "#                         None,#1e8*ans[:,0],\n",
    "#                         attrs={'fmt':'-.r'},Plot=False)\n",
    "#         symbols=Symbols(markersizes=np.array([10,10,10,12,12,12,10])*8)\n",
    "#         legends = Legends()\n",
    "#         legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs #plotAttrs\n",
    "#                     else (1.0,0.5,0.5,0.5))\n",
    "\n",
    "#         #\n",
    "#         column_energy = 0\n",
    "#         column_time = 3\n",
    "#         kount = 0\n",
    "#         for indx in range(0,len(self.temps),nevery):\n",
    "#             temp = self.temps[indx]\n",
    "#             #--- concat. data for each temp            \n",
    "#             data_energy = np.concatenate(list(map(lambda x: self.GetEnergy(self.data[x][:,column_energy]),\n",
    "#                                                   range(kount,kount+self.nrun))))\n",
    "#             #--- wait_times\n",
    "#             data = self.data[indx:indx+self.nrun]\n",
    "#             data_waitTimes = np.concatenate(list(map(lambda x: self.GetWaitTimes(self.data[x][:,column_time]),\n",
    "#                                                      range(kount,kount+self.nrun))))\n",
    "\n",
    "#             if self.verbose:\n",
    "#                 print('data_energy.shape (per temperature):',np.array(data_energy).shape)\n",
    "#                 print('data_waitTimes.shape (per temperature):',np.array(data_waitTimes).shape)\n",
    "#             #--- plot scatter\n",
    "#             scale = 1e2 ** indx if shift else 1\n",
    "#             filtr = data_waitTimes > 0\n",
    "# #             utl.PltErr(data_energy[filtr]*kb_inv/temp,scale*data_waitTimes[filtr],\n",
    "# #                         attrs=symbols.GetAttrs(count=indx%7,label=r'$%s$'%temp,fmt='.',alpha=1.0),\n",
    "# #                         ax = self.ax,\n",
    "# #                         Plot=False,\n",
    "# #                         )\n",
    "#             self.ax.scatter(data_energy[filtr]*kb_inv/temp,scale*data_waitTimes[filtr],\n",
    "#                         **symbols.GetAttrsScatter(count=indx%7,label=r'$%s$'%temp,fmt='.',alpha=0.1/2),\n",
    "#                        )\n",
    "#             kount += self.nrun\n",
    "#             #--- plot average\n",
    "# #             nbins = 8\n",
    "# #             count, _=np.histogram(data_energy[filtr],bins=nbins)\n",
    "# #             xsum, _=np.histogram(data_energy[filtr],weights=data_energy[filtr],bins=nbins)\n",
    "# #             ysum, _=np.histogram(data_energy[filtr],weights=data_waitTimes[filtr],bins=nbins)\n",
    "# #             ysum /= count\n",
    "# # #            ysum =10 ** ysum \n",
    "# #             xsum /= count\n",
    "# #             #---\n",
    "# #             utl.PltErr(xsum,ysum,\n",
    "# #                         attrs=symbols.GetAttrs(count=(indx)%7,label=r'$%s$'%temp,fmt='.'),\n",
    "# #                         ax = self.ax,\n",
    "# #                         Plot=False,\n",
    "# #                         )\n",
    "        \n",
    "        \n",
    "#         utl.PltErr(None,\n",
    "#                    None,\n",
    "#                    ax=self.ax,\n",
    "#                    Plot=False,\n",
    "# #                     legend=legends.Get(),\n",
    "#                    DrawFrame=DRAW_FRAME,\n",
    "#                    **kwargs\n",
    "#                   )\n",
    "\n",
    "#     def GetEnergy(self,slist):\n",
    "#         n=len(slist)\n",
    "#         return slist[1:n:2]\n",
    "            \n",
    "# if not eval(confParser['flags']['RemoteMachine']):\n",
    "#     !mkdir png\n",
    "    \n",
    "#     stats = EnergyStats(\n",
    "#         [1000,1200,1400,1600,1800,2000],8,\n",
    "# #        [1000,1400,1800,2000],8,\n",
    "# #        [1000, 1400,1800],8,\n",
    "#         #        np.arange(1000,1440,40),1,\n",
    "# #        verbose=True\n",
    "#                      )\n",
    "# #    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "#     stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "# #    stats.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "#                          stats.temps_runs ))\n",
    "#                )\n",
    "#     stats.PlotPdf(shift=True,n_per_decade=10,\n",
    "#                         **{'xscale':'log',\n",
    "#                   'yscale':'log',\n",
    "# #                   'xlim':(1e-3,1e0),\n",
    "# #                   'ylim':(1e-2,1e2), #(1e-5,1e2),\n",
    "# #                           'xstr':r'$\\Delta t$',\n",
    "# #                           'ystr':r'$P(\\Delta t)$',\n",
    "#                         'ndecade_y':2,\n",
    "#                    'title':'png/BarrierPdf_cantor.png'},\n",
    "\n",
    "#                        )\n",
    "    \n",
    "# #     stats.PlotPdfConcat(scale=False,\n",
    "# #                         splitByType = False,\n",
    "# #                         **{'xscale':'log',\n",
    "# #                       'yscale':'log',\n",
    "# #     #                   'xlim':(1e-3,1e0),\n",
    "# # #                        'ylim':(1e-2,1e2), #(1e-5,1e2),\n",
    "# #     #                           'xstr':r'$\\Delta t$',\n",
    "# #     #                           'ystr':r'$P(\\Delta t)$',\n",
    "# #     #                        'ndecade_x':2,'ndecade_y':2,\n",
    "# #     #                   'title':'png/BarrierPdf_cantor.png'\n",
    "# #                           },\n",
    "# #                        )\n",
    "\n",
    "#     stats.Scatter(nevery=2, shift = True,                        \n",
    "#                 **{'xscale':'linear',\n",
    "#                   'yscale':'log',\n",
    "# #                   'xlim':(1e-3,1),\n",
    "# #                   'ylim':(1e-3,1e1), #(1e-5,1e2),\n",
    "# #                           'xstr':r'$\\Delta t$',\n",
    "# #                           'ystr':r'$P(\\Delta t)$',\n",
    "# #                     'bbox_to_anchor':(0.56,0.27,0.5,0.5),\n",
    "#                         'ndecade_y':2,\n",
    "#                    'title':'png/twVsEnergy_nicocr.png',\n",
    "#                   }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    \n",
    "    stats = EnergyStats(\n",
    "#        [1000,1200,1400,1600,1800,2000],[list(range(8))]*10,\n",
    "        [1000],[list(range(8))]*10,\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "    stats.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "                         stats.temps_runs ))\n",
    "               )\n",
    "    stats.PlotPdf(shift=False,column_energy=3,\n",
    "                  linscale=True, n_per_decade = 32,\n",
    "                        **{'xscale':'linear',\n",
    "                  'yscale':'log',\n",
    "                   'xlim':(0,4.8),\n",
    "                    'ylim':(1e-4,1e1), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "#                         'ndecade_x':1,'ndecade_y':2,\n",
    "                    'bbox_to_anchor':(0.4,0.13,0.5,0.5),\n",
    "                   'title':'png/BarrierPdf_nicocr.png'},\n",
    "\n",
    "                       )\n",
    "\n",
    "#     stats.PlotPdfConcat(scale=True, \n",
    "#                         column_energy=3,\n",
    "#                         splitByType = False,\n",
    "#                         n_per_decade=10,\n",
    "#                         **{'xscale':'log',\n",
    "#                   'yscale':'log',\n",
    "# #                   'xlim':(1e-3,1e-1),\n",
    "# #                   'ylim':(1e-2,1e0), #(1e-5,1e2),\n",
    "# #                           'xstr':r'$\\Delta t$',\n",
    "# #                           'ystr':r'$P(\\Delta t)$',\n",
    "# #                        'ndecade_x':2,'ndecade_y':2,\n",
    "# #                   'title':'png/BarrierPdf_cantor.png'\n",
    "#                           },\n",
    "\n",
    "#                        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    \n",
    "    stats = EnergyStats(\n",
    "        [2000],8,\n",
    "#        [2000],8,\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiNatom1KTemp%sK/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "                         stats.temps_runs ))\n",
    "               )\n",
    "    print(stats.data[0][:,3].mean())\n",
    "    stats.PlotPdf(shift=True,column_energy=3,\n",
    "                        **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "#                   'xlim':(1e-3,1e-1),\n",
    "#                    'ylim':(1e-2,1e0), #(1e-5,1e2),\n",
    "#                           'xstr':r'$\\Delta t$',\n",
    "#                           'ystr':r'$P(\\Delta t)$',\n",
    "                        'ndecade_x':1,'ndecade_y':2,\n",
    "                    'bbox_to_anchor':(0.4,0.13,0.5,0.5),\n",
    "                   'title':'png/BarrierPdf_nicocr.png'},\n",
    "\n",
    "                       )\n",
    "\n",
    "#     stats.PlotPdfConcat(scale=True, \n",
    "#                         column_energy=3,\n",
    "#                         splitByType = False,\n",
    "#                         n_per_decade=10,\n",
    "#                         **{'xscale':'log',\n",
    "#                   'yscale':'log',\n",
    "# #                   'xlim':(1e-3,1e-1),\n",
    "# #                   'ylim':(1e-2,1e0), #(1e-5,1e2),\n",
    "# #                           'xstr':r'$\\Delta t$',\n",
    "# #                           'ystr':r'$P(\\Delta t)$',\n",
    "# #                        'ndecade_x':2,'ndecade_y':2,\n",
    "# #                   'title':'png/BarrierPdf_cantor.png'\n",
    "#                           },\n",
    "\n",
    "#                        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kb=8.61732814974056e-05\n",
    "\n",
    "# 0.9/1650/kb,1.0/2100/kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    #alpha=-0.4\n",
    "\n",
    "    Emin=1e-2\n",
    "    Emax=1e1\n",
    "    n=100000\n",
    "    for alpha in [-1]:\n",
    "        xmax=1/Emin**alpha\n",
    "        xmin=1/Emax**alpha\n",
    "        x=np.random.uniform(low=xmin,high=xmax,size=n)\n",
    "        #E=np.exp(-E)\n",
    "        E=x**-(1/alpha)\n",
    "        hist, edge,err = utl.GetPDF(E,n_per_decade=4)\n",
    "        ax=utl.PltErr(edge,hist,yerr=err,\n",
    "                   yscale='log',xscale='log',Plot=False,\n",
    "                  )\n",
    "\n",
    "        utl.PltErr(edge,1/edge**(1+alpha),yerr=err,attrs={'fmt':'-.r'},\n",
    "                   yscale='log',xscale='log',\n",
    "                   ax=ax\n",
    "                  )\n",
    "\n",
    "        #\n",
    "        lambdaa=np.exp(-E)\n",
    "        lambdaa = lambdaa[lambdaa>0]\n",
    "        hist, edge,err = utl.GetPDF(lambdaa,n_per_decade=32)\n",
    "        utl.PltErr(edge,hist,yerr=err,\n",
    "                   yscale='log',xscale='log',\n",
    "                   xlim=(1e-10,1),\n",
    "                  )\n",
    "\n",
    "        sarr = np.c_[list(map(lambda x:np.random.exponential(1/x,size=1),lambdaa))].flatten()\n",
    "        hist, edge,err = utl.GetPDF(sarr,n_per_decade=4)\n",
    "        ax=utl.PltErr(edge,hist*edge**0,yerr=err*edge**0,\n",
    "                   yscale='log',xscale='log',\n",
    "                      Plot=False\n",
    "                  )\n",
    "        utl.PltErr(edge,1/edge**(1.5+alpha),attrs={'fmt':'-.r'},\n",
    "                   yscale='log',xscale='log',\n",
    "                   ax=ax\n",
    "                  )\n",
    "        beta=fit(edge,hist,err)\n",
    "        print(beta)\n",
    "        plt.scatter(alpha,beta)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x,beta,k,x0,x1):\n",
    "#    return k/(1+(x/x0)**beta)\n",
    "    return k*np.exp(-x/x1)/(1+(x/x0)**beta)\n",
    "    \n",
    "def fit(edge,hist,err):\n",
    "    xdata=edge\n",
    "    ydata=hist\n",
    "    yerr=err\n",
    "    popt, pcov = curve_fit(func,xdata,ydata,\n",
    "                          p0=(2,1,10,1e3),\n",
    "                           sigma=yerr,\n",
    "                          )\n",
    "\n",
    "    ax=utl.PltErr(edge,hist,yerr=err,\n",
    "               yscale='log',xscale='log',\n",
    "                  Plot=False\n",
    "              )\n",
    "    utl.PltErr(edge,func(edge,*popt),attrs={'fmt':'-.r'},\n",
    "               yscale='log',xscale='log',\n",
    "               ax=ax,\n",
    "               ndecade_x=4,\n",
    "              )\n",
    "    assert popt[-1]>0\n",
    "    return popt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kbt=1000*8.61732814974056e-05\n",
    "# E=5e-2\n",
    "# print('%e'%(1.0/(1e-13*np.exp(E/kbt))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    \n",
    "    stats = EnergyStats(\n",
    "#         [1000,1200,1400,1600,1800,2000],[list(range(8))]*10,\n",
    "        [0],[list(range(8))]\n",
    "#        verbose=True\n",
    "                     )\n",
    "#    stats.Parse( list(map(lambda x:'CantorNatom16KTemp%sKEnsemble8/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiNatom16KTemp%sK/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "#    stats.Parse( list(map(lambda x:'NiCoCrNatom1KTemp%sK/Run%s/msd/eventID_barrier.txt'%(x[0],x[1]),\n",
    "    stats.Parse( list(map(lambda x:'barrier/ni/kmc/void_2d/Run%s/msd/eventID_barrier_catalog_type1.txt'%(x[1]),\n",
    "                         stats.temps_runs ))\n",
    "               )\n",
    "\n",
    "    stats.PlotPdf( \n",
    "                        column_energy=2,\n",
    "                        splitByType = False,\n",
    "                        n_per_decade = 16,\n",
    "                        **{'xscale':'log',\n",
    "                  'yscale':'log',\n",
    "                   'xlim':(1e-1,1e1),\n",
    "#                   'ylim':(1e-3,1e2), #(1e-5,1e2),\n",
    "                           'xstr':r'$\\Delta E$',\n",
    "                           'ystr':r'$P(\\Delta E)$',\n",
    "#                        'ndecade_x':2,'ndecade_y':2,\n",
    "                   'title':'png/BarrierPdf_cantor.png'\n",
    "                          },\n",
    "\n",
    "                       )\n",
    "\n",
    "    \n",
    "\n",
    "#     stats.Scatter(nevery=2,                        \n",
    "#                 **{'xscale':'linear',\n",
    "#                   'yscale':'log',\n",
    "#                    'xlim':(0,1),\n",
    "# #                   'ylim':(1e-3,1e1), #(1e-5,1e2),\n",
    "# #                           'xstr':r'$\\Delta t$',\n",
    "# #                           'ystr':r'$P(\\Delta t)$',\n",
    "#                         'ndecade_y':2,\n",
    "#                    'title':'png/twVsEnergy_cantor.png',\n",
    "#                   }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    !mkdir png\n",
    "    pref = 1e6\n",
    "    \n",
    "    temp = Temperature(\n",
    "        [1000],[[7]],\n",
    "#        verbose=True\n",
    "                     )\n",
    "    #--- parse data\n",
    "#    temp.Parse(['./msd/msd.txt'])\n",
    "    temp.Parse( list(map(lambda x:'sro/cantor/kmc/cantorNatom1KTemp%sK/Run%s/msd/timeseries.txt'%(x[0],x[1]),\n",
    "                        temp.temps_runs ))\n",
    "              )\n",
    "\n",
    "#     temp.EnsAverage(n_bins_per_decade=100000,\n",
    "#                     col_x = 3, col_y = 1,\n",
    "#                     n_thresh=0,\n",
    "#                    )\n",
    "    \n",
    "    symbols = Symbols()\n",
    "    legend=Legends()\n",
    "    legend.Set(bbox_to_anchor=(0.92,0.48,0.5,0.5),labelspacing=.4)\n",
    "\n",
    "    count = 0\n",
    "#     ax = utl.PltErr(None,None,Plot=False)\n",
    "    for irun in temp.nrun[0]:\n",
    "        xdata=temp.data[count][::2,3]\n",
    "        ydata=temp.data[count][::2,1]\n",
    "\n",
    "#         utl.PltErr(xdata, ydata,\n",
    "#                   attrs={'fmt':'-'},\n",
    "#                    ax=ax,\n",
    "#                    Plot=False,\n",
    "#     #                xscale='log' ,\n",
    "# #                      ylim=(-6000,-5900),\n",
    "#                   )\n",
    "        count += 1\n",
    "        \n",
    "    \n",
    "#     timesteps = temp.data_averaged[1000][:,0]\n",
    "#     wc = temp.data_averaged[1000][:,1]\n",
    "#     yerr = temp.data_averaged[1000][:,2]\n",
    "\n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "    utl.PltErr(pref*xdata,ydata,#yerr=yerr,\n",
    "                 ylim=[(-5538,-5530),(-6000,-5920)][0],\n",
    "#                xlim=(0,0.1),\n",
    "                Plot=False,\n",
    "                ax=ax,\n",
    "                attrs={'fmt':'-','color':'C0'},#symbols.GetAttrs(count=0,nevery=8),\n",
    "               title='png/energy_timeseries_cantor.png',\n",
    "                 DrawFrame=DRAW_FRAME,\n",
    "               fontsize=16,\n",
    "             )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SroAnalysis:\n",
    "    \n",
    "    def __init__(self, lmpData, nevery=1, verbose = False ):\n",
    "        !mkdir sroAnalysis\n",
    "        self.lmpData = lmpData\n",
    "        self.verbose = verbose\n",
    "        self.timesteps = list(lmpData.coord_atoms_broken.keys())[::nevery]\n",
    "        self.timesteps.sort()\n",
    "        self.times = list(lmpData.headers['Time'])[::nevery]\n",
    "        self.times.sort()\n",
    "\n",
    "\n",
    "    \n",
    "    def GetNeighList(self):\n",
    "        itime0 = self.timesteps[0]\n",
    "        natoms = min(self.lmpData.coord_atoms_broken[itime0].shape[0],\\\n",
    "                     eval(confParser['SroAnalysis']['natom'])) #--- subset of atoms\n",
    "        atom_indices = range(natoms)\n",
    "        np.savetxt('atom_indices.txt',atom_indices,fmt='%d')\n",
    "        #\n",
    "        cutoff = eval(confParser['SroAnalysis']['cutoff'])\n",
    "        !rm sroAnalysis/neighList.xyz\n",
    "#         path = confParser['input files']['path']\n",
    "#         indx = confParser['input files']['fileIndex']\n",
    "        py_path=confParser['input files']['lib_path']\n",
    "        fileName = 'dumpFile/dump.xyz'\n",
    "        nevery = int(confParser['SroAnalysis']['nevery'])\n",
    "        if self.verbose:\n",
    "            print('get neighbor list ...')     \n",
    "        t0=time.time()\n",
    "        !ovitos $py_path/OvitosCna.py $fileName neighList.xyz $nevery 4 $cutoff atom_indices.txt\n",
    "        if self.verbose:\n",
    "            print('output neighbor list=%s s'%(time.time()-t0))     \n",
    "            \n",
    "        t0=time.time()\n",
    "        self.lmpNeigh = lp.ReadDumpFile( 'neighList.xyz' )\n",
    "        self.lmpNeigh.GetCords( ncount = sys.maxsize)\n",
    "        \n",
    "        #--- update timesteps\n",
    "        self.timesteps = list(self.lmpNeigh.coord_atoms_broken.keys())\n",
    "        self.timesteps.sort()\n",
    "        \n",
    "        #--- clean\n",
    "        !rm neighList.xyz atom_indices.txt\n",
    "\n",
    "        if self.verbose:\n",
    "            print('load neighbor list=%s s'%(time.time()-t0))\n",
    "            print('times=',self.timesteps)\n",
    "            display(self.lmpNeigh.coord_atoms_broken[self.timesteps[0]].head())\n",
    "            \n",
    "\n",
    "        \n",
    "    def WarrenCowleyOrderParameter(self, itime, **kwargs):        \n",
    "        box = lp.Box( BoxBounds = self.lmpData.BoxBounds[itime], AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "        atoms = lp.Atoms( **self.lmpData.coord_atoms_broken[itime].to_dict(orient='series') )\n",
    "        #--- neighbor list\n",
    "        neigh = self.lmpNeigh.coord_atoms_broken[itime]\n",
    "        \n",
    "        #--- radial dist. function\n",
    "        cutoff = eval(confParser['SroAnalysis']['cutoff'])\n",
    "        rdf = lp.ComputeRdf(  atoms, box )\n",
    "        bins = self.GetValleys(itime) if 'bins' not in kwargs else kwargs['bins']\n",
    "        rdf.PairCrltn(  \n",
    "                  bins=bins, \n",
    "                  rlist=neigh.DIST )\n",
    "        \n",
    "        types = list(set(self.lmpData.coord_atoms_broken[0].type))\n",
    "        sro = {}\n",
    "        count = 0\n",
    "        for pairi in types:\n",
    "            for pairj in types:\n",
    "                if pairi > pairj:\n",
    "                    continue\n",
    "                sro[count] = rdf.Sro(neigh,pairi,pairj,bins=bins)\n",
    "                count += 1\n",
    "        return sro\n",
    "\n",
    "    def MultiTimes(self,**kwargs):\n",
    "        bins = kwargs['bins'] if 'bins' in kwargs else self.GetValleys(self.timesteps[0])\n",
    "        self.data =list(map(lambda x:self.WarrenCowleyOrderParameter(x,bins=bins),self.timesteps))\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def quadratic_spline_roots(spl):\n",
    "        roots = []\n",
    "        knots = spl.get_knots()\n",
    "        for a, b in zip(knots[:-1], knots[1:]):\n",
    "            u, v, w = spl(a), spl((a+b)/2), spl(b)\n",
    "            t = np.roots([u+w-2*v, w-u, 2*v])\n",
    "            t = t[np.isreal(t) & (np.abs(t) <= 1)]\n",
    "            roots.extend(t*(b-a)/2 + (b+a)/2)\n",
    "        return np.array(roots)\n",
    "\n",
    "    @staticmethod\n",
    "    def GetExtrema(bin_edges1,hist1,r0,verbose=True):\n",
    "        y_axis=hist1\n",
    "        x_axis=bin_edges1\n",
    "        f = InterpolatedUnivariateSpline(x_axis, y_axis, k=4)\n",
    "\n",
    "        ext=f.derivative().roots() #--- roots\n",
    "        spl_dd=f.derivative().derivative()\n",
    "        valleys=ext[np.all([spl_dd(ext)>0,ext>r0],axis=0)]\n",
    "        peaks=ext[np.all([spl_dd(ext)<0,ext>r0],axis=0)]\n",
    "\n",
    "        if len(valleys) == 0:\n",
    "            cutoff = eval(confParser['SroAnalysis']['cutoff'])\n",
    "            valleys = [cutoff]\n",
    "\n",
    "        rpeak   = peaks[0]\n",
    "        rvalley = valleys[0]\n",
    "        if rvalley > rpeak:\n",
    "            valleys = np.concatenate([np.array([0]),valleys])\n",
    "#         if verbose:\n",
    "#             print('peaks of g(r) at:r=',peaks)\n",
    "#             print('valleys of g(r) at:r=',valleys)\n",
    "\n",
    "        return x_axis, f, valleys\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def GetValleys(self,itime):\n",
    "        bin_edges, hist,_  = self.PairCrltnFunction(itime)\n",
    "        self.bin_edges, self.hist,_  = self.PairCrltnFunction(itime)\n",
    "        x_axis, f, valleys = SroAnalysis.GetExtrema(bin_edges,hist,1.0)\n",
    "        #--- remove valleys that are too close!\n",
    "        filtr = np.diff(valleys,prepend=valleys[-1]) >0.25\n",
    "        valleys = np.append(0,valleys[filtr])\n",
    "        return valleys\n",
    "        \n",
    "    def PairCrltnFunction(self,itime):\n",
    "        box = lp.Box( BoxBounds = self.lmpData.BoxBounds[itime], AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "        atoms = lp.Atoms( **self.lmpData.coord_atoms_broken[itime].to_dict(orient='series') )\n",
    "        neigh = self.lmpNeigh.coord_atoms_broken[itime]\n",
    "\n",
    "\n",
    "        cutoff = eval(confParser['SroAnalysis']['cutoff'])\n",
    "        rdf = lp.ComputeRdf(  atoms, box )\n",
    "        rdf.PairCrltn(  \n",
    "                      bins=np.arange(0.99*neigh.DIST.min(),cutoff,0.01), \n",
    "                      rlist=neigh.DIST,\n",
    "                      regular_r = True,\n",
    "                      )\n",
    "        return rdf.Get()\n",
    "\n",
    "    @staticmethod\n",
    "    def Reshape(sdict):\n",
    "        keys = list(sdict.keys())\n",
    "        keys.sort()\n",
    "        concat = list(map(lambda x:list(np.concatenate([sdict[x][0],sdict[x][1],sdict[x][2]])),keys))\n",
    "        size = (3,len(sdict[keys[0]][0]))\n",
    "        return dict(zip(keys,concat)), size\n",
    "    \n",
    "                \n",
    "    def Print( self, fp ):\n",
    "        rwj = utl.ReadWriteJson()\n",
    "        rwj.Write(self.data, fp,\n",
    "                  timestep=self.timesteps,\n",
    "                  time=self.times\n",
    "                 # junk=sro.timesteps\n",
    "                 )\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['SroAnalysis']['SroAnalysis']):\n",
    "    sro = SroAnalysis( data.lmpData,\n",
    "                       nevery=eval(confParser['SroAnalysis']['nevery']),\n",
    "                        verbose = True,\n",
    "                     )\n",
    "    sro.GetNeighList()\n",
    "#    sro.WarrenCowleyOrderParameter(sro.timesteps[0])\n",
    "    sro.MultiTimes(\n",
    "                    bins=np.array(confParser['SroAnalysis']['sroBins'].split()).astype(float)\n",
    "                  )\n",
    "    sro.Print('sroAnalysis/sro.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not eval(confParser['flags']['RemoteMachine']):\n",
    "\n",
    "#     path = {0:'sro/CantorNatom16KTemp1000KEnsemble8',\n",
    "#             1:'sro/NiCoCrNatom1KTemp1000K',\n",
    "#            }[1]\n",
    "#     rwj = utl.ReadWriteJson()\n",
    "#     data = rwj.Read('%s/Run0/sroAnalysis/sro.json'%path)\n",
    "#     #\n",
    "#     pairIndx = '0'\n",
    "#     rss = 0.20\n",
    "#     #\n",
    "#     symbols = Symbols()\n",
    "# #    ax = utl.PltErr(None,None,Plot=False)\n",
    "#     for items in data:\n",
    "#         timestep = items['timestep']\n",
    "#         bin_edges, wc, err = items[pairIndx]\n",
    "\n",
    "    \n",
    "#     for pairIndx in range(6):\n",
    "#         ax = utl.PltErr(None,None,Plot=False)\n",
    "\n",
    "#         bin_edges, wc, err = items[str(pairIndx)]\n",
    "#         utl.PltErr(bin_edges,wc,yerr=2*np.array(err),\n",
    "#                     Plot=False,\n",
    "#                     ax=ax,\n",
    "#                     attrs=symbols.GetAttrs(count=0,zorder=2),      \n",
    "#                   )\n",
    "\n",
    "\n",
    "#         cutoff = 20.0 #eval(confParser['SroAnalysis']['cutoff'])\n",
    "#         utl.PltErr([0,cutoff],[rss,rss],\n",
    "#                     xlim=[0.0,cutoff],\n",
    "#     #                ylim=[0.1,.7],\n",
    "#                     ax=ax,\n",
    "#                     attrs={'fmt':'-.r'},\n",
    "#                     title='png/wc_nicocr_indx%s.png'%(pairIndx),\n",
    "#                     DrawFrame=DRAW_FRAME,\n",
    "#                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "\n",
    "    path = {0:'sro/CantorNatom16KTemp1000KEnsemble8',\n",
    "            1:'sro/NiCoCrNatom1KTemp1000K',\n",
    "            2:'sro/nicocr/kmc/NiCoCrNatom1KTemp1000K',\n",
    "            3:'.'\n",
    "           }[2]\n",
    "    alloy = 'nicocr'\n",
    "    runs = range(8) #[7] #range(8)\n",
    "    rss = 0.33 #0.2 #0.33\n",
    "    every_nrow = 1 #--- don't change\n",
    "    inn = 2 #--- 1st nearest neighbor\n",
    "    nneighbors = 3 #--- len(sroBins)-1\n",
    "    \n",
    "    indices = {'nicocr':'0 1 2 3 4 5'.split(),\n",
    "               'cantor':' '.join(list(map(str,range(15)))).split()}[alloy]\n",
    "    pairs = {'nicocr':'NiNi NiCo NiCr CoCo CoCr CrCr'.split(),\n",
    "              'cantor':' '.join(list(map(str,range(15)))).split()\n",
    "            }[alloy]\n",
    "    \n",
    "    rwj = utl.ReadWriteJson()\n",
    "    for irun in runs:\n",
    "        data = rwj.Read('%s/Run%s/sroAnalysis/sro.json'%(path,irun))\n",
    "        #\n",
    "        #--- parse\n",
    "        symbols = Symbols()\n",
    "        legend=Legends()\n",
    "        legend.Set(bbox_to_anchor=(0.92,0.48,0.5,0.5),labelspacing=.4)\n",
    "        ax = utl.PltErr(None,None,Plot=False)\n",
    "        for pairIndx, label in zip(indices,pairs):\n",
    "            sro_data = np.concatenate([list(map(lambda x:\n",
    "                                 np.concatenate([np.array([x['time']]),np.array(x[pairIndx]).flatten()]),\n",
    "                                 data))])\n",
    "            timesteps = sro_data[::every_nrow,0]\n",
    "            r = sro_data[::every_nrow,1:1+nneighbors]\n",
    "            wc = sro_data[::every_nrow,1+nneighbors:1+2*nneighbors]/rss-1.0\n",
    "            err = sro_data[::every_nrow,1+2*nneighbors:1+3*nneighbors]\n",
    "\n",
    "\n",
    "            #--- output\n",
    "            np.savetxt('sro/sro_irun%s_indx%s_nn%s.txt'%(irun,pairIndx,inn),np.c_[timesteps,wc[:,inn],err[:,inn]])\n",
    "\n",
    "            utl.PltErr(timesteps,-wc[:,inn],yerr=err[:,inn],\n",
    "                        Plot=False,\n",
    "                        ax=ax,\n",
    "                        attrs=symbols.GetAttrs(count=int(pairIndx)%7,zorder=2,nevery=1280,label=r'$\\mathrm{%s}$'%label),      \n",
    "                      )\n",
    "\n",
    "\n",
    "        utl.PltErr([0,timesteps[-1]],[0,0],\n",
    "                    ax=ax,\n",
    "                    attrs={'fmt':'-.r'},\n",
    "                    legend=legend.Get(),\n",
    "#                     title='png/wc_time_nicocr_nn%s.png'%inn,\n",
    "                    DrawFrame=DRAW_FRAME,\n",
    "                   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    pref = 1e6\n",
    "    indices = {'nicocr':'0 1 2 3 4 5'.split(),\n",
    "               'cantor':'0 5 9 12 14'.split()}[alloy]\n",
    "    pairs = {'nicocr':'NiNi NiCo NiCr CoCo CoCr CrCr'.split(),\n",
    "              'cantor':'NiNi CoCo CrCr FeFe MnMn '.split()\n",
    "            }[alloy]\n",
    "\n",
    "    \n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "    legend=Legends()\n",
    "    legend.Set(bbox_to_anchor=(-0.02,0.52,0.5,0.5),\n",
    "                 labelspacing=.2,\n",
    "                    fontsize=12,\n",
    "              )\n",
    "    count = 0\n",
    "    for sro_indx, label in zip(indices,pairs):\n",
    "        temp_vac = Temperature(\n",
    "                [int(sro_indx)],[runs],\n",
    "        #         verbose = True,\n",
    "                         )\n",
    "        #--- parse data\n",
    "        temp_vac.Parse( list(map(lambda x:'sro/sro_irun%s_indx%s_nn%s.txt'%(x[1],x[0],inn),\n",
    "                              temp_vac.temps_runs ))\n",
    "                  )\n",
    "\n",
    "        temp_vac.EnsAverage(n_bins_per_decade=32)\n",
    "\n",
    "\n",
    "        timesteps = temp_vac.data_averaged[int(sro_indx)][:,0]\n",
    "        wc = temp_vac.data_averaged[int(sro_indx)][:,1]\n",
    "        yerr = temp_vac.data_averaged[int(sro_indx)][:,2]\n",
    "\n",
    "        utl.PltErr(pref*timesteps,-wc,#yerr=yerr,\n",
    "                    Plot=False,\n",
    "                    ax=ax,\n",
    "                    attrs=symbols.GetAttrs(count=count%7,zorder=2,nevery=4,label=r'$\\mathrm{%s}$'%label),      \n",
    "                  )\n",
    "        count += 1\n",
    "\n",
    "    utl.PltErr([0,pref*timesteps[-1]],[0,0],\n",
    "#                        xlim=[0.0,0.1],\n",
    "                    ylim=[-0.3,0.3],\n",
    "                ax=ax,\n",
    "                attrs={'fmt':'-.r','color':'C0'},\n",
    "                  legend=legend.Get(),\n",
    "                title='png/wc_time_cantor_inn%s.png'%inn,\n",
    "                DrawFrame=DRAW_FRAME,\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnnEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "259.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
